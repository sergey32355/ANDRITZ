{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82fccc5d-087b-4fa4-8175-4583ed065a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b8ddf7e-d3a0-484e-bc14-4db872c2c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Navy10021/MDAutoEncoder/blob/main/notebooks/MDAutoEncoder.ipynb\n",
    "# CNN based Auto-Encoder model\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        # Encoder (Convolutional Layers) : Compressed into low-dimensional vectors.\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, kernel_size=7)  # [batch, 128, 1, 1]\n",
    "        )\n",
    "        # Decoder (Transpose Convolutional Layers) : Reconstruct low-dimensional vectors to original image dimensions.\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=7),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # [batch, 1, 28, 28]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4882bd64-4987-4f3e-8375-5a588999e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Navy10021/MDAutoEncoder/blob/main/notebooks/MDAutoEncoder.ipynb\n",
    "# CNN based Auto-Encoder model\n",
    "class CNNAutoencoder_Shallow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder_Shallow, self).__init__()\n",
    "        # Encoder (Convolutional Layers) : Compressed into low-dimensional vectors.\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, stride=2, padding=1),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(64, 128, kernel_size=7)  # [batch, 128, 1, 1]\n",
    "        )\n",
    "        # Decoder (Transpose Convolutional Layers) : Reconstruct low-dimensional vectors to original image dimensions.\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=7),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # [batch, 1, 28, 28]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dd3de32a-3fdc-4e20-a4a5-7b6188e0dd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.5\n"
     ]
    }
   ],
   "source": [
    "def CNNOutput(W,K,S,P):\n",
    "    #W is the input volume - in your case 128\n",
    "    #K is the Kernel size - in your case 5\n",
    "    #S is the stride - which you have not provided.    \n",
    "    #P is the padding - in your case 0 i believe    \n",
    "    return (W-K+2*P)/S+1\n",
    "\n",
    "print(CNNOutput(500,3,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f2546bce-ec5d-4e3f-8c88-9af7f4e33a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Navy10021/MDAutoEncoder/blob/main/notebooks/MDAutoEncoder.ipynb\n",
    "# CNN based Auto-Encoder model\n",
    "#optimized for input 500 sampling points\n",
    "class CNNAutoencoder_Shallow_498sp_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder_Shallow_500sp_1, self).__init__()\n",
    "        # Encoder (Convolutional Layers) : Compressed into low-dimensional vectors.\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=6, stride=2, padding=1),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(64, 128, kernel_size=6, stride=2, padding=1),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(128, 256, kernel_size=3,stride=2, padding=1),  # [batch, 128, 1, 1]                        \n",
    "        )\n",
    "        # Decoder (Transpose Convolutional Layers) : Reconstruct low-dimensional vectors to original image dimensions.\n",
    "        self.decoder = nn.Sequential(                       \n",
    "            nn.ConvTranspose1d(256,128, kernel_size=3,stride=2, padding=1,output_padding=0),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(128,64, kernel_size=6, stride=2, padding=1,output_padding=0),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(64, 1, kernel_size=6, stride=2, padding=1, output_padding=0),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84ba3bed-ae3b-46a6-aaa9-9fb1371ae868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUniqueElements_List(inputList):\n",
    "    list_out=[]\n",
    "    for k in range(0,len(inputList)):\n",
    "        if(inputList[k] not in list_out):\n",
    "            list_out.append(inputList[k])\n",
    "    return list_out\n",
    "        \n",
    "def SeparateFeat_Norm_Anom(CLASSIF_FEAT,CLASSIF_LABS):\n",
    "    unique_labels=GetUniqueElements_List(CLASSIF_LABS)\n",
    "    feat_norm=[]\n",
    "    labs_norm=[]\n",
    "    feat_anomaly=[]\n",
    "    labs_anomaly=[]\n",
    "    label_0=CLASSIF_LABS[0]\n",
    "    for k in range(0,len(CLASSIF_LABS)):\n",
    "        if(CLASSIF_LABS[k]==label_0):\n",
    "            feat_norm.append(np.asarray(CLASSIF_FEAT[k][:]))\n",
    "            labs_norm.append(0)\n",
    "        else:\n",
    "            feat_anomaly.append(np.asarray(CLASSIF_FEAT[k][:]))\n",
    "            labs_anomaly.append(1)\n",
    "    return feat_norm,labs_norm,feat_anomaly,labs_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "173971e5-7047-4f6f-b98c-515a0aef9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Blcok\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet based Auto-Encoder model\n",
    "class ResNetAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetAutoencoder, self).__init__()\n",
    "        # Encoder (Convolutional Layers with Residual Blocks)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=False),  # Avoid inplace operation\n",
    "            ResidualBlock(64, 128, stride=2),\n",
    "            ResidualBlock(128, 256, stride=2),\n",
    "            nn.ReLU(inplace=False)  # Avoid inplace operation\n",
    "        )\n",
    "\n",
    "        # Decoder (Transpose Convolutional Layers)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=False),  # Avoid inplace operation\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=False),  # Avoid inplace operation\n",
    "            nn.Conv1d(64, 1, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df1f17b7-0140-4ea8-911f-c29c502803d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainAE_1(feat,labels,\n",
    "                  AE_type=\"ResNetCNN\",#\"CNN_shallow\",\n",
    "                  lr=0.001,\n",
    "                  num_epochs=10,\n",
    "                  visualize=True,\n",
    "            ):\n",
    "    \n",
    "    norm,norm_l,non_norm,non_norm_l = SeparateFeat_Norm_Anom(feat,labels)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #train\n",
    "    norm = torch.Tensor(np.asarray(norm)).to(device) \n",
    "    norm_l = torch.Tensor(np.asarray(norm_l)).to(device) \n",
    "    norm_dataset = torch.utils.data.TensorDataset(norm,norm_l)\n",
    "    train_loader = torch.utils.data.DataLoader(norm_dataset)\n",
    "    \n",
    "    if(len(norm.shape)<=2): \n",
    "        norm=norm[:,None,:]\n",
    "        print(\"Features shape is corrected. Cur. shape - \"+str(norm.shape))\n",
    "    \n",
    "    #test\n",
    "    non_norm = torch.Tensor(np.asarray(non_norm)).to(device) \n",
    "    non_norm_l = torch.Tensor(np.asarray(non_norm_l)).to(device) \n",
    "    non_norm_dataset = torch.utils.data.TensorDataset(non_norm,non_norm_l)\n",
    "    test_loader = torch.utils.data.DataLoader(non_norm_dataset)\n",
    "\n",
    "    if(len(norm.shape)<=2): \n",
    "        non_norm=non_norm[:,None,:]\n",
    "        print(\"Features shape is corrected. Cur. shape - \"+str(non_norm.shape))\n",
    "            \n",
    "    #https://github.com/Navy10021/MDAutoEncoder/blob/main/notebooks/MDAutoEncoder.ipynb    \n",
    "    # model 1 : CNN based model\n",
    "    model=None\n",
    "    if(AE_type==\"CNN_shallow\"):\n",
    "        model = CNNAutoencoder_Shallow_500sp_1().to(device)#CNNAutoencoder_Shallow_500sp().to(device) #CNNAutoencoder_Shallow().to(device)\n",
    "    if(AE_type==\"ResNetCNN\"):\n",
    "        model = WideResNet(depth=6, width_multiplier=1, num_classes=1).to(device)#ResNetAutoencoder().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    num_epochs = num_epochs\n",
    "\n",
    "    # Training\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):        \n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "            for data, _ in train_loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, data)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "    \n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    if(visualize==True):\n",
    "        # Plotting the training loss curve\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Curve')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a070498a-e162-4074-994a-d0757af6818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape is corrected. Cur. shape - torch.Size([400, 1, 8])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "WideResNet.__init__() missing 1 required positional argument: 'output_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m non_norm_dataset = torch.utils.data.TensorDataset(torch.tensor(non_norm,dtype=torch.float32).to(device),torch.tensor(non_norm_l,dtype=torch.float32).to(device))\n\u001b[32m      9\u001b[39m test_loader = torch.utils.data.DataLoader(non_norm_dataset)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model=TrainAE_1(norm,norm_l,num_epochs=\u001b[32m10\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mTrainAE_1\u001b[39m\u001b[34m(feat, labels, AE_type, lr, num_epochs, visualize)\u001b[39m\n\u001b[32m     34\u001b[39m     model = CNNAutoencoder_Shallow_500sp_1().to(device)\u001b[38;5;66;03m#CNNAutoencoder_Shallow_500sp().to(device) #CNNAutoencoder_Shallow().to(device)\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(AE_type==\u001b[33m\"\u001b[39m\u001b[33mResNetCNN\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     model = WideResNet(depth=\u001b[32m6\u001b[39m, width_multiplier=\u001b[32m1\u001b[39m, num_classes=\u001b[32m1\u001b[39m).to(device)\u001b[38;5;66;03m#ResNetAutoencoder().to(device)\u001b[39;00m\n\u001b[32m     37\u001b[39m criterion = nn.MSELoss()\n\u001b[32m     38\u001b[39m optimizer = optim.Adam(model.parameters(), lr=lr)\n",
      "\u001b[31mTypeError\u001b[39m: WideResNet.__init__() missing 1 required positional argument: 'output_indices'"
     ]
    }
   ],
   "source": [
    "norm=np.random.random((400,8))\n",
    "norm_l=np.zeros((np.shape(norm)[0]))\n",
    "non_norm=np.random.random((400,8))\n",
    "non_norm_l=np.ones((np.shape(non_norm)[0]))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "norm_dataset = torch.utils.data.TensorDataset(torch.tensor(norm,dtype=torch.float32).to(device),torch.tensor(norm_l,dtype=torch.float32).to(device))\n",
    "train_loader = torch.utils.data.DataLoader(norm_dataset)\n",
    "non_norm_dataset = torch.utils.data.TensorDataset(torch.tensor(non_norm,dtype=torch.float32).to(device),torch.tensor(non_norm_l,dtype=torch.float32).to(device))\n",
    "test_loader = torch.utils.data.DataLoader(non_norm_dataset)\n",
    "model=TrainAE_1(norm,norm_l,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a9cf8519-def9-4993-b23c-473ff188b4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(27, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(29, device='cuda:0')\n",
      "tensor(27, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(25, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(30, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(25, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(27, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(27, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(25, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(29, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(28, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(31, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(25, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(27, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "threshold_factor=1.5\n",
    "proximity=20\n",
    "\n",
    "non_norm_torch=torch.tensor(non_norm,dtype=torch.float32).to(device)\n",
    "non_norm_torch=non_norm_torch[:,None,:]\n",
    "preds=model.forward(non_norm_torch)\n",
    "losses = torch.mean((preds - non_norm_torch)**2, dim=1)\n",
    "labels=[]\n",
    "\"\"\"\n",
    "lk=int(losses.shape[1]/2)\n",
    "for l in range(0,losses.shape[0]):\n",
    "    cur_loss=losses[l]\n",
    "    mean_loss=cur_loss.mean()    \n",
    "    print(cur_loss)\n",
    "    cur_lab=0\n",
    "    anom_len=losses.shape[1]\n",
    "    while(True):\n",
    "        threshold_down = mean_loss + factor*cur_lab\n",
    "        threshold_up   = threshold_down + factor*(cur_lab+1)\n",
    "        anomalies = (cur_loss > threshold_down) & (cur_loss < threshold_up)        \n",
    "        if(anom_len>lk): \n",
    "            labels.append(cur_lab)\n",
    "            break\n",
    "        else: cur_lab+=1    \n",
    "    print(anom_len)\n",
    "\"\"\"\n",
    "threshold =losses.mean() + factor * losses.std()\n",
    "anomalies = losses > threshold\n",
    "labels=[]\n",
    "lk=int(anomalies.shape[1]/20)\n",
    "for l in range(0,anomalies.shape[0]):\n",
    "    count=torch.sum(anomalies[l]==True)\n",
    "    #count=0\n",
    "    #for k in range(0,anomalies.shape[1]):\n",
    "    #    if(anomalies.data[l,k]==True):count+=1            \n",
    "    #tr=[1 for x in anomalies[l] if x]#anomalies[l].count(True)\n",
    "    print(count)\n",
    "    if(count>lk):labels.append(1)\n",
    "    else: labels.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d167ae05-422e-4ce8-acef-84b91147f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d642e13-a248-4fde-92f5-f5afbc044482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf473fc-f108-462b-9e88-67989d971aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feca4d-107c-46ab-8ef6-4c41dbbe2c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169368b-e83c-4baf-a6ad-b307e7eb1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Blcok\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet based Auto-Encoder model\n",
    "class ResNetAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetAutoencoder, self).__init__()\n",
    "        # Encoder (Convolutional Layers with Residual Blocks)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=False),  # Avoid inplace operation\n",
    "            ResidualBlock(16, 32, stride=2),\n",
    "            ResidualBlock(32, 64, stride=2),\n",
    "            nn.ReLU(inplace=False)  # Avoid inplace operation\n",
    "        )\n",
    "\n",
    "        # Decoder (Transpose Convolutional Layers)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=False),  # Avoid inplace operation\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=False),  # Avoid inplace operation\n",
    "            nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa68539-c5bf-4aa7-8d5d-f7b364bda2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Navy10021/MDAutoEncoder/blob/main/notebooks/MDAutoEncoder.ipynb\n",
    "# CNN based Auto-Encoder model\n",
    "class CNNAutoencoder_Shallow1(nn.Module):\n",
    "    def __init__(self,input_size=32):\n",
    "        super(CNNAutoencoder_Shallow, self).__init__()\n",
    "        # Encoder (Convolutional Layers) : Compressed into low-dimensional vectors.\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1,32, kernel_size=3, stride=2, padding=1),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(64, 128, kernel_size=7)  # [batch, 128, 1, 1]\n",
    "        )\n",
    "        # Decoder (Transpose Convolutional Layers) : Reconstruct low-dimensional vectors to original image dimensions.\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=7),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # [batch, 1, 28, 28]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ffe1d3-2797-413a-8175-1c0e3598dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Navy10021/MDAutoEncoder/blob/main/notebooks/MDAutoEncoder.ipynb\n",
    "# CNN based Auto-Encoder model\n",
    "#optimized for input 500 sampling points\n",
    "class CNNAutoencoder_Shallow_500sp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder_Shallow_500sp, self).__init__()\n",
    "        # Encoder (Convolutional Layers) : Compressed into low-dimensional vectors.\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 248, kernel_size=6, stride=2, padding=0),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(248, 122, kernel_size=6, stride=2, padding=0),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(122, 59, kernel_size=6,stride=2, padding=0),  # [batch, 128, 1, 1]            \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(59, 29, kernel_size=3,stride=2, padding=0),  # [batch, 128, 1, 1]                \n",
    "        )\n",
    "        # Decoder (Transpose Convolutional Layers) : Reconstruct low-dimensional vectors to original image dimensions.\n",
    "        self.decoder = nn.Sequential(            \n",
    "            nn.ConvTranspose1d(29, 59, kernel_size=3,stride=2, padding=0,output_padding=0),  # [batch, 128, 1, 1]    \n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(59,122, kernel_size=6,stride=2, padding=0,output_padding=0),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(122,248, kernel_size=6, stride=2, padding=0,output_padding=0),  # [batch, 64, 7, 7]\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(248, 1, kernel_size=6, stride=2, padding=1, output_padding=0),  # [batch, 32, 14, 14]\n",
    "            nn.ReLU(True),            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b28de4-58ef-42f7-8c7b-789c08c12c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/400 [00:02<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 32, 3], expected input[1, 250, 125] to have 32 channels, but got 250 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m data = data.to(device)\n\u001b[32m     20\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m output = model(data)\n\u001b[32m     22\u001b[39m loss = criterion(output, data)\n\u001b[32m     23\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mCNNAutoencoder_Shallow.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.encoder(x)\n\u001b[32m     26\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.decoder(x)\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:371\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:366\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    356\u001b[39m         F.pad(\n\u001b[32m    357\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    365\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m.stride, \u001b[38;5;28mself\u001b[39m.padding, \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups\n\u001b[32m    368\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [64, 32, 3], expected input[1, 250, 125] to have 32 channels, but got 250 channels instead"
     ]
    }
   ],
   "source": [
    "#https://github.com/Navy10021/MDAutoEncoder/blob/main/notebooks/MDAutoEncoder.ipynb\n",
    "in_sz=np.shape(norm)[1]\n",
    "# model 1 : CNN based model\n",
    "model = CNNAutoencoder_Shallow(input_size=in_sz).to(device)\n",
    "# model 2 : ResNet based model\n",
    "#model = ResNetAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "# Training\n",
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for data, _ in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "# Plotting the training loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e06ce2c7-a1e2-47ec-8578-d1e53b17a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 3], expected input[1, 400, 32] to have 1 channels, but got 400 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m data=data[\u001b[38;5;28;01mNone\u001b[39;00m, :,:]\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.shape)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m normal_recon_error = compute_reconstruction_error(data, model)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 1. Calculate reconstruction error for normal data\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03mnormal_data = next(iter(train_loader))[0]\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03mnormal_recon_error = compute_reconstruction_error(normal_data, model)\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03mmean_normal_error = np.mean(normal_recon_error)\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcompute_reconstruction_error\u001b[39m\u001b[34m(data, model)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      5\u001b[39m     data = data.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     output = model(data)\n\u001b[32m      7\u001b[39m     recon_error = torch.mean((data - output) ** \u001b[32m2\u001b[39m, dim=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m])\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m recon_error.cpu().detach().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mCNNAutoencoder1.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.encoder(x)\n\u001b[32m     26\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.decoder(x)\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:371\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:366\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    356\u001b[39m         F.pad(\n\u001b[32m    357\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    365\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m.stride, \u001b[38;5;28mself\u001b[39m.padding, \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups\n\u001b[32m    368\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [32, 1, 3], expected input[1, 400, 32] to have 1 channels, but got 400 channels instead"
     ]
    }
   ],
   "source": [
    "# Reconstruction error : mean + 3 * standard deviation\n",
    "def compute_reconstruction_error(data, model):\n",
    "    model.eval() # using trained model\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        recon_error = torch.mean((data - output) ** 2, dim=[1, 2, 3])\n",
    "    return recon_error.cpu().detach().numpy()\n",
    "\n",
    "normal_recon_error = compute_reconstruction_error(data, model)\n",
    "# 1. Calculate reconstruction error for normal data\n",
    "\"\"\"\n",
    "normal_data = next(iter(train_loader))[0]\n",
    "normal_recon_error = compute_reconstruction_error(normal_data, model)\n",
    "mean_normal_error = np.mean(normal_recon_error)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 2. Generate random anomalous data (e.g. noise)\n",
    "anomalous_data = torch.randn_like(normal_data) * 0.25\n",
    "anomalous_recon_error = compute_reconstruction_error(anomalous_data, model)\n",
    "mean_anomalous_error = np.mean(anomalous_recon_error)\n",
    "\n",
    "# 3. Plotting histograms\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "plt.hist(normal_recon_error, bins=50, alpha=0.95, color='salmon', label='Normal data')\n",
    "plt.hist(anomalous_recon_error, bins=50, alpha=0.95, color='skyblue', label='Anomaly')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 4. Calculate and print mean error rates\n",
    "mean_normal_error = np.mean(normal_recon_error)\n",
    "mean_anomalous_error = np.mean(anomalous_recon_error)\n",
    "print(\"==========================================================\")\n",
    "print(f\">> Mean Normal data Reconstruction Error Rate: {mean_normal_error:.4f}\")\n",
    "print(f\">> Mean Anomalous data Reconstruction Error Rate: {mean_anomalous_error:.4f}\")\n",
    "print(\"==========================================================\\n\")\n",
    "\n",
    "# Generate labels (0 for normal, 1 for anomalous)\n",
    "labels = np.concatenate([np.zeros(len(normal_recon_error)), np.ones(len(anomalous_recon_error))])\n",
    "scores = np.concatenate([normal_recon_error, anomalous_recon_error])\n",
    "\n",
    "# 5. Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(labels, scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "def plot_reconstructed_images(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "\n",
    "    # Visualization of original and reconstructed images (recovered by the model)\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "    for i in range(10):\n",
    "        axes[0, i].imshow(data[i].cpu().numpy().squeeze(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title('Original', fontsize=8, pad=2)\n",
    "\n",
    "        axes[1, i].imshow(output[i].cpu().numpy().squeeze(), cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title('Reconstructed', fontsize=8, pad=2)\n",
    "\n",
    "    plt.suptitle('Original and Reconstructed Malware Images', fontsize=13, y=1.15)\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# Visualization of Reconstructed IMG\n",
    "plot_reconstructed_images(model, normal_data[:10])\n",
    "\n",
    "# 7. Latent space visualization\n",
    "def plot_latent_space(data, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        latent = model.encoder(data)  # Assuming the encoder part of the autoencoder is accessible\n",
    "        latent = latent.view(latent.size(0), -1).cpu().numpy()\n",
    "\n",
    "    tsne = TSNE(n_components=2)\n",
    "    latent_2d = tsne.fit_transform(latent)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c='blue', alpha=0.5)\n",
    "    plt.xlabel('TSNE Component 1')\n",
    "    plt.ylabel('TSNE Component 2')\n",
    "    plt.title('Latent Space Visualization using TSNE')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# Example usage\n",
    "plot_latent_space(next(iter(train_loader))[0], model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c49981-a0ee-4782-a7b1-b63c7580db92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
