{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04a2dc5-400a-4ef6-8138-a3bc98795490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import walk\n",
    "import sys\n",
    "from time import sleep\n",
    "import traceback\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import uuid \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import preprocessing\n",
    "import distinctipy as dc\n",
    "import time\n",
    "import logging\n",
    "import threading\n",
    "import sys\n",
    "import trace\n",
    "import glob\n",
    "from barbar import Bar\n",
    "\n",
    "from PySide6.QtWidgets import QApplication, QMainWindow, QTextEdit,QFileDialog\n",
    "from PySide6.QtCore import QThread, Signal, QObject\n",
    "from gui_files.empa_gui import Ui_EmpaGUI\n",
    "from mod.mod_gui_data_loader_bpp_lines import DataLoaderBPPLines\n",
    "from mod.mod_gui_feature_extractor_bpp_lines import FeatureExtractorBPPLines\n",
    "from mod.mod_gui_model_selector_bpp_lines import ModelSelectorBPPLines, PredictorScorerBPPLines\n",
    "from PySide6.QtWidgets import QMessageBox\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg\n",
    "from matplotlib.figure import Figure\n",
    "from PySide6.QtWidgets import QDialog, QVBoxLayout\n",
    "from PySide6.QtWidgets import QMessageBox\n",
    "\n",
    "#additional libs\n",
    "import librosa\n",
    "import spcm #the DAQ card library\n",
    "from spcm import units # spcm uses the pint library for unit handling (units is a UnitRegistry object)\n",
    "import datetime\n",
    "\n",
    "#classifiers\n",
    "from xgboost import XGBClassifier\n",
    "import pywt\n",
    "import ptwt\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import SHelpers as shlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aceeb0b-4d6e-41ef-a7b1-c8f4ab61d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyside6-designer - call designer\n",
    "#LINKS\n",
    "##https://github.com/EnsiyeTahaei/DeepAnT-Time-Series-Anomaly-Detection/blob/main/deepant/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c653bf8-6b78-40df-83e8-0587dc93897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = False\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ui = Ui_EmpaGUI()\n",
    "        self.ui.setupUi(self)\n",
    "        # Make output text boxes read-only\n",
    "        # Connect button click\n",
    "        self.ui.load_data_button.clicked.connect(self.load_data)\n",
    "        self.ui.load_model_button.clicked.connect(self.load_model)\n",
    "        #self.ui.train_button.clicked.connect(self.train_model)\n",
    "        self.ui.List_segments_names_button.clicked.connect(self.List_segment_names_click)\n",
    "        #self.ui.plot_button.clicked.connect(self.plot_signal)\n",
    "        #self.ui.predict_button.clicked.connect(self.predict)\n",
    "        #SSH ADD-ON\n",
    "        self.ui.Brows_data_folder_button.clicked.connect(self.browse_data_folder_click)\n",
    "        self.ui.load_data_plate_type_dropdown.currentIndexChanged.connect(self.PlateLayout_click) #choose the layout of the plate\n",
    "        self.ui.train_dropdown.currentIndexChanged.connect(self.ModelChoiceDropDown_click)#choose the model\n",
    "        #SSH TOOLS tab\n",
    "        #page 1\n",
    "        self.ui.plot_plate_dropdown.currentIndexChanged.connect(self.PlateChoiceChanged_click)#drop box with plates names list\n",
    "        self.ui.plot_button.clicked.connect(self.Plot_selected_segment_click)\n",
    "        self.ui.platre_data_button_2.clicked.connect(self.Plate_info_click)\n",
    "        self.ui.unload_as_csv_button_data_button_3.clicked.connect(self.Save_signal_as_scv_click)\n",
    "        self.ui.calssification_plot_segment.clicked.connect(self.Classification_Plot_Segment) #for supervised clasification labelling we plot the signal\n",
    "        self.ui.classification_set_category.clicked.connect(self.Classification_Set_Category_Click)\n",
    "        self.ui.classification_clear_labels_button.clicked.connect(self.Classification_ClearLabelling_Click)\n",
    "        self.ui.classification_clear_all_segments_labels_button_2.clicked.connect(self.Classification_ClearLabellingForAllSegments_Click)\n",
    "        self.ui.classification_run_classification_button.clicked.connect(self.RunClassificationClick)\n",
    "        self.ui.calssification_segment_savetofolder_button.clicked.connect(self.SaveLabelingAsCSV_Click)\n",
    "        self.ui.Classification_set_as_main_model_button.clicked.connect(self.SetAsMainModelButton_Click)\n",
    "        self.ui.Classification_run_test_on_complete_segment_button.clicked.connect(self.RunClassifForSegment_Click)\n",
    "        self.ui.classification_dataset_info_button.clicked.connect(self.Classification_Dataset_Info_Click)\n",
    "        self.ui.classification_entire_segment_to_label_button.clicked.connect(self.Classification_Entire_Segm_To_Label_Click)\n",
    "        self.ui.classification_all_segments_to_label_button_2.clicked.connect(self.Classification_All_Segm_To_Label_Click)\n",
    "        self.ui.tools_show_scpetrogram_button.clicked.connect(self.Tool_Show_Spectrograms_Botton_Click)\n",
    "        #settings\n",
    "        #colors\n",
    "        self.ui.COlors_list_generate_button.clicked.connect(self.GenerateCOlors_Botton_Click)\n",
    "        #classifiiers\n",
    "        #autoencoder\n",
    "        self.ui.Autoencoder_set_threshold_button.clicked.connect(self.Autoencoder_set_threshold_click)\n",
    "\n",
    "        #SPECTROGARMS\n",
    "        self.ui.Settings_test_MEL_Segment.clicked.connect(self.Tool_Test_Spectrograms_MEL_Botton_Click)\n",
    "        self.ui.Settings_Test_MEL_snippet.clicked.connect(self.Tool_Show_Spectrograms_MEL_Botton_Click)\n",
    "        \n",
    "        #real time\n",
    "        self.ui.Start_real_time_button.clicked.connect(self.Real_Time_Button_Click)\n",
    "        self.ui.Stop_real_time_button_2.clicked.connect(self.Real_Time_Stop_Click)\n",
    "        # Set dropdown options\n",
    "        #model_names = [m.split(\".\")[0] for m in os.listdir(\"models\") if m.endswith(\".pkl\")]\n",
    "        #self.ui.load_model_dropdown.addItems(model_names)\n",
    "        #set widgets starting conditions\n",
    "        self.WidgetsStartingConditions()\n",
    "\n",
    "        #local vairables\n",
    "        self.load_data_thread = None\n",
    "        self.load_data_worker = None\n",
    "        self.extract_features_worker = None\n",
    "        self.train_thread = None\n",
    "        self.train_worker = None\n",
    "        self.predict_thread = None\n",
    "        self.predict_worker = None\n",
    "        self.dl = None  # To store the DataLoaderBPPLines object\n",
    "        self.fe = None  # To store the FeatureExtractorBPPLines object\n",
    "        self.ms = None  # To store the ModelSelectorBPPLines object\n",
    "        self.ps = None  # To store the PredictorScorerBPPLines object\n",
    "        self.model = None  # To store the trained model\n",
    "        self.threshold_params = None  # To store threshold parameters for trained model\n",
    "\n",
    "        #SSH ADD-ON\n",
    "        #plate\n",
    "        self.plate_segments_id=[] #segnents of the plate as a string list\n",
    "        self.plates=[] #plate segments with signals   \n",
    "        #data preprocessing\n",
    "        self.DataPreproc=None\n",
    "        #classifier or regressor\n",
    "        self.s_model = None\n",
    "        #service\n",
    "        self.proc_settings=None  #processing pipeline from GUI\n",
    "        self.proc_graph_settings=None #display graphics settings from GUI        \n",
    "        self.classif_plot_fig_id=\"\"\n",
    "        self.classif_fig=None\n",
    "        #self.classif_tmp=None #here we store the classifier from the intermidiate test runs\n",
    "        self.autoencoder_hist_form_id=\"\"\n",
    "        \n",
    "        #threading for real time\n",
    "        #folder check\n",
    "        self.RT_Figure_if_orig_sgn = \"\"\n",
    "        self.RT_Figure_if_proc_results_id = \"\"\n",
    "        self.ExitFilesInFolderFlag=False\n",
    "        self.Real_time_FolderTrackerThread=None\n",
    "        #DAQ acquisition\n",
    "        self.RT_SpectrumThread=None\n",
    "        global EXIT_DAQ_FLAG\n",
    "        EXIT_DAQ_FLAG=True\n",
    "        #generate colors lists\n",
    "        self.colors_id = None\n",
    "        self.GenerateCOlors_Botton_Click() #dc.get_colors(500)       \n",
    "\n",
    "    def WidgetsStartingConditions(self):\n",
    "        self.ui.Model_ready_label.setStyleSheet(\"background-color: red\")\n",
    "\n",
    "    def GenerateCOlors_Botton_Click(self):        \n",
    "        graph_sets=shlp.ReadGraphSettings(self)\n",
    "        type_list=graph_sets.get(\"classif_color_list_type\")\n",
    "        col_num=int(graph_sets.get(\"classif_color_list_number\"))\n",
    "        \n",
    "        def ColorsListGen(type_list,col_num):\n",
    "            #https://stackoverflow.com/questions/22408237/named-colors-in-matplotlib\n",
    "            colors_list=[]\n",
    "            if(type_list==\"Grades of red\"):\n",
    "                colors_list=['#228B22','#FF0000','#8B0000']\n",
    "            if(type_list==\"Random colors\"):\n",
    "                colors_list=dc.get_colors(col_num)\n",
    "            return colors_list\n",
    "        self.colors_id = shlp.ColorsListGen(type_list,col_num)\n",
    "    \n",
    "    #BUTTONS EVENTS\n",
    "    #find folder with signal files\n",
    "    def browse_data_folder_click(self):\n",
    "        path_dir = QFileDialog.getExistingDirectory()         \n",
    "        self.ui.load_data_path.setText(path_dir)\n",
    "\n",
    "    def List_segment_names_click(self):\n",
    "        print(\"\")        \n",
    "        print(\"SEGMENT NAMES LIST:\")  \n",
    "        print(\"Segm.num. - \"+str(len(self.plate_segments_id)))\n",
    "        print(self.plate_segments_id)\n",
    "\n",
    "    def PlateLayout_click(self):        \n",
    "        plate_type=self.ui.load_data_plate_type_dropdown.currentText()\n",
    "        self.plate_segments_id=shlp.getSegmentNames(plate_type)\n",
    "        \n",
    "    def ModelChoiceDropDown_click(self):\n",
    "        model_choice = self.ui.train_dropdown.currentIndex()  \n",
    "        if(model_choice==1):\n",
    "            path_dir = QFileDialog.getOpenFileName(self, str(\"Open File\"),\n",
    "                                                   \"/home\",\n",
    "                                                   str(\"Model (*.plk)\"))   \n",
    "            if(path_dir==\"\"):#if was canceled\n",
    "                self.ui.load_data_plate_type_dropdown.setCurrentIndex(0)\n",
    "                model_choice=0\n",
    "            else:\n",
    "                loaded_model_data = joblib.load(model_path)\n",
    "                self.model = loaded_model_data['trained_model']\n",
    "                self.threshold_params = loaded_model_data['best_threshold_params']\n",
    "                \n",
    "        if(model_choice==0):\n",
    "            pass#this is for autoencoder\n",
    "\n",
    "    #SSH TOOLS TAB EVENTS \n",
    "    def PlateChoiceChanged_click(self):\n",
    "        if(self.plates is None):\n",
    "            return        \n",
    "        if(self.plates==[]):\n",
    "            return\n",
    "        cur_plate_name=self.ui.plot_plate_dropdown.currentText()\n",
    "        indx_plate=-1\n",
    "        for k in range(0,len(self.plates)):\n",
    "            if(self.plates[k].name==cur_plate_name):\n",
    "                indx_plate=k\n",
    "                break\n",
    "        #fill segments\n",
    "        segm_available=self.plates[indx_plate].segments_names#\n",
    "        self.ui.plot_segment_dropdown.clear()\n",
    "        self.ui.plot_segment_dropdown.addItems(segm_available)\n",
    "        self.ui.plot_segment_dropdown.setCurrentIndex(0)\n",
    "        #fill channels\n",
    "        chans_available=self.plates[indx_plate].chans_names.copy()\n",
    "        chans_available.insert(0, \"all\")\n",
    "        self.ui.Channel_segment_plot.clear()\n",
    "        self.ui.Channel_segment_plot.addItems(chans_available)\n",
    "        self.ui.Channel_segment_plot.setCurrentIndex(0)\n",
    "        \n",
    "    #plot sepctrogram for selected segment\n",
    "    def Tool_Show_Spectrograms_Botton_Click(self):\n",
    "        if(self.plates==None):\n",
    "            print(\"plates are not loaded...\")\n",
    "            return\n",
    "        if(self.plates==[]):\n",
    "            print(\"plates are not loaded...\")\n",
    "            return\n",
    "        self.proc_settings = shlp.ReadSettings(self)\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()   \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        signals=[]\n",
    "        end_=indx_chan+1\n",
    "        start_=indx_chan\n",
    "        if(end_==-1): \n",
    "            end_ = len(self.plates[indx_plate].segment_sign[indx_segment]) #we taek all signals\n",
    "            start=0\n",
    "        SAMPLE_RATE=int(self.plates[indx_plate].sr)\n",
    "        spec_type=self.proc_settings.get(\"spectrogrym_type\")\n",
    "        for i in range(start_,end_):\n",
    "            # Define transform            \n",
    "            waveform=torch.tensor(self.plates[indx_plate].sigments_sign[indx_segment][i])\n",
    "            if(len(waveform.shape)==1): waveform = waveform[None, :]\n",
    "            if(spec_type==\"MEL\"):\n",
    "                    spectrogrym_MEL_nfft=int(self.proc_settings.get(\"spectrogrym_MEL_nfft\"))\n",
    "                    spectrogram = T.Spectrogram(n_fft=spectrogrym_MEL_nfft)\n",
    "                    # Perform transform\n",
    "                    spec = spectrogram(waveform)\n",
    "                    %matplotlib qt\n",
    "                    fig, axs = plt.subplots(2, 1)\n",
    "                    shlp.plot_waveform(waveform, SAMPLE_RATE, title=\"Original waveform\", ax=axs[0])\n",
    "                    shlp.plot_spectrogram(spec[0], title=\"spectrogram\", ax=axs[1])\n",
    "                    fig.tight_layout()\n",
    "        \n",
    "    #plot selected segment\n",
    "    def Plot_selected_segment_click(self):\n",
    "        \n",
    "        if(self.plates==[]):\n",
    "            return\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()\n",
    "        signal_type=self.ui.type_of_signal_dropdown.currentText()\n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()   \n",
    "\n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        \n",
    "        \"\"\"\n",
    "        #find plate in list\n",
    "        indx_plate=-1\n",
    "        for k in range(0,len(self.plates)):\n",
    "            if(self.plates[k].name==p_name):\n",
    "                indx_plate=k\n",
    "                break\n",
    "        #find channel in list\n",
    "        indx_chan=-1\n",
    "        if(ch_name!=\"all\"):\n",
    "            for k in range(0,len(self.plates[indx_plate].chans_names)):\n",
    "                if(self.plates[indx_plate].chans_names[k]==ch_name):\n",
    "                    indx_chan=k\n",
    "                    break\n",
    "        #find the segment\n",
    "        indx_segment=-1\n",
    "        for k in range(0,len(self.plates[indx_plate].segments_names)):\n",
    "                if(self.plates[indx_plate].segments_names[k]==segment_name):\n",
    "                    indx_segment=k\n",
    "                    break\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(ch_name)\n",
    "        #print(indx_chan)\n",
    "        #print(self.plates[indx_plate].chans_names)\n",
    "        \"\"\"\n",
    "        %matplotlib qt\n",
    "        if(plot_type==\"Segment\"):\n",
    "            shlp.ShowSingleSegmentWithLabels(self.classif_plot_fig_id,self.plates[indx_plate],indx_segment=indx_segment,\n",
    "                                                                                              colors_code=self.colors_id,\n",
    "                                                                                              indx_chan=indx_chan)\n",
    "        if(plot_type==\"All_segments\"):\n",
    "            shlp.ShowAllSingleSegmentsWithLabels(self.classif_plot_fig_id, self.plates[indx_plate],\n",
    "                                                 colors_code=self.colors_id,\n",
    "                                                 indx_chan=indx_chan,\n",
    "                                                 aplpha=0.1\n",
    "                                                )\n",
    "        \"\"\"\n",
    "        %matplotlib qt\n",
    "        if(signal_type==\"Raw signals\"):\n",
    "            if(indx_chan!=-1):#this is the case of not all channels are selected\n",
    "                fig=plt.figure(1)\n",
    "                plt.clf()\n",
    "                plt.plot(self.plates[indx_plate].time, self.plates[indx_plate].raw_signals[indx_chan])\n",
    "                plt.show()\n",
    "            else:\n",
    "                fig=plt.figure(1)\n",
    "                plt.clf()\n",
    "                for kp in range(0,len(self.plates[indx_plate].chans_names)):\n",
    "                    plt.plot(self.plates[indx_plate].time, self.plates[indx_plate].raw_signals[kp])\n",
    "                plt.show()\n",
    "        else: #segments\n",
    "            if(indx_chan!=-1):#this is the case when single channel is selected                \n",
    "                shlp.ShowSingleSegmentWithLabels(self.classif_plot_fig_id,\n",
    "                                                 self.plates[indx_plate],\n",
    "                                                 indx_segment=indx_segment,\n",
    "                                                 colors_code=self.colors_id,\n",
    "                                                 indx_chan=[indx_chan]\n",
    "                                                )\n",
    "            else:\n",
    "                shlp.ShowAllSingleSegmentsWithLabels(self.classif_plot_fig_id, \n",
    "                                                     self.plates[indx_plate],\n",
    "                                                     colors_code=self.colors_id,\n",
    "                                                     indx_chan=indx_chan,\n",
    "                                                     aplpha=0.1\n",
    "                                                    )\n",
    "                \n",
    "                \"\"\"\n",
    "                t_start=self.plates[indx_plate].sigments_start_t\n",
    "                d_t=self.plates[indx_plate].delta_t\n",
    "                durat=d_t*len(self.plates[indx_plate].sigments_sign[indx_segment][indx_chan])\n",
    "                time=np.linspace(t_start,t_start+durat,len(self.plates[indx_plate].sigments_sign[indx_segment][indx_chan]))                \n",
    "                fig=plt.figure(1)\n",
    "                plt.clf()\n",
    "                plt.plot(time, self.plates[indx_plate].sigments_sign[indx_segment][indx_chan])\n",
    "                plt.show()\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                fig=plt.figure(1)\n",
    "                plt.clf()\n",
    "                for kp in range(0,len(self.plates[indx_plate].chans_names)):\n",
    "                    t_start=self.plates[indx_plate].sigments_start_t\n",
    "                    d_t=self.plates[indx_plate].delta_t\n",
    "                    durat=d_t*len(self.plates[indx_plate].sigments_sign[indx_segment][indx_chan])\n",
    "                    time=np.linspace(t_start,t_start+durat,len(self.plates[indx_plate].sigments_sign[indx_segment][indx_chan]))    \n",
    "                    plt.plot(time, self.plates[indx_plate].sigments_sign[indx_segment][kp])\n",
    "                plt.show()    \n",
    "                \"\"\"\n",
    "                \n",
    "    def Save_signal_as_scv_click(self):\n",
    "        if(self.plates==[]):\n",
    "            return\n",
    "        \n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()\n",
    "        signal_type=self.ui.type_of_signal_dropdown.currentText()\n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()   \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        \n",
    "        path_dir = QFileDialog.getExistingDirectory()       \n",
    "        if(path_dir==\"\"): return\n",
    "        else:\n",
    "            if(indx_chan==-1):#we save all channels\n",
    "                start_num=0\n",
    "                chans_num=len(self.plates[indx_plate].chans_names)\n",
    "            else:\n",
    "                start_num=indx_chan\n",
    "                chans_num=indx_chan+1\n",
    "                \n",
    "            for k in range(start_num,chans_num):\n",
    "                    chan_sub_f=path_dir+\"\\\\\"+self.plates[indx_plate].chans_names[k]                    \n",
    "                    if(os.path.exists(chan_sub_f)==False):\n",
    "                        try: os.mkdir(chan_sub_f)\n",
    "                        except:\n",
    "                            print(\"Failed to creat a directory. Signals are not saved...\")\n",
    "                            return\n",
    "                    f_name=chan_sub_f+\"\\\\\"+p_name+\"_\"+segment_name+\"_\"+ch_name+\"_\"+signal_type+\".csv\"\n",
    "                    if os.path.exists(f_name)==True:\n",
    "                        counter=0\n",
    "                        while(True):\n",
    "                            counter+=1\n",
    "                            f_name=chan_sub_f+\"\\\\\"+str(counter)+\"_\"+p_name+\"_\"+segment_name+\"_\"+ch_name+\"_\"+signal_type+\".csv\"\n",
    "                            if (os.path.exists(f_name)==False):\n",
    "                                break\n",
    "                    arr=self.plates[indx_plate].sigments_sign[indx_segment][k]\n",
    "                    df = pd.DataFrame(arr)\n",
    "                    df.to_csv(f_name)\n",
    "            print(\"filed saved into folder...\")\n",
    "           \n",
    "    #classification section - Tools->Page 1\n",
    "    def Classification_Dataset_Info_Click(self):\n",
    "        self.proc_settings = shlp.ReadSettings(self)\n",
    "        print(\"\")\n",
    "        print(\"Settings:\")\n",
    "        print(self.proc_settings)\n",
    "        \n",
    "    def Classification_Plot_Segment(self):        \n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return   \n",
    "\n",
    "        self.proc_graph_settings = shlp.ReadGraphSettings(self)\n",
    "        plot_type = self.proc_graph_settings.get(\"classification_show_labeled_data_type\")\n",
    "            \n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()    \n",
    "                \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        if (self.classif_plot_fig_id==\"\"):self.classif_plot_fig_id = str(uuid.uuid1())[:5]  \n",
    "        %matplotlib qt\n",
    "        if(plot_type==\"Segment\"):\n",
    "            shlp.ShowSingleSegmentWithLabels(self.classif_plot_fig_id,self.plates[indx_plate],indx_segment=indx_segment,\n",
    "                                                                                              colors_code=self.colors_id,\n",
    "                                                                                              indx_chan=indx_chan)\n",
    "        if(plot_type==\"All_segments\"):\n",
    "            shlp.ShowAllSingleSegmentsWithLabels(self.classif_plot_fig_id, self.plates[indx_plate],\n",
    "                                                 colors_code=self.colors_id,\n",
    "                                                 indx_chan=indx_chan,\n",
    "                                                 aplpha=0.1\n",
    "                                                )\n",
    "            \n",
    "        \"\"\"\n",
    "        if(plt.fignum_exists(self.classif_plot_fig_id)==False) or(self.classif_plot_fig_id==\"\"):\n",
    "            self.classif_plot_fig_id=str(uuid.uuid1())[:5]  \n",
    "            %matplotlib qt\n",
    "            self.classif_fig=plt.figure(self.classif_plot_fig_id)    \n",
    "        shlp.ShowSignalInFigure(self.classif_fig,\n",
    "                                plates=self.plates,\n",
    "                                colors_code=self.colors_id,\n",
    "                                indx_plate=indx_plate,\n",
    "                                indx_segment=indx_segment,\n",
    "                                indx_chan=indx_chan)       \n",
    "        \"\"\"\n",
    "    #assign label to the segment pattern\n",
    "    def Classification_Set_Category_Click(self):\n",
    "        \n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return\n",
    "        \n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()    \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        \n",
    "        try:\n",
    "            start_el = int(self.ui.classification_labeling_start_element_text.text())\n",
    "            end_el=int(self.ui.classification_labeling_end_element_text.text())\n",
    "            label=self.ui.classification_labeling_label_text.text()\n",
    "            if(label==\"\" or label==\" \"):\n",
    "                print(\"fill lable info and repeat...\")\n",
    "                return\n",
    "            #self.plates[indx_plate].sigments_labels[indx_segment].append(list([start_el,end_el,label]))\n",
    "            self.plates[indx_plate].AssignLabelToSegmentPattern(segment_indx=indx_segment,label=label,start_el=start_el,end_el=end_el)\n",
    "        except:\n",
    "            print(\"check the values in the text boxes\")\n",
    "            return\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"new label assigned to:\")\n",
    "        print(\"plate name - \"+str(p_name))\n",
    "        print(\"segment name - \"+str(segment_name))\n",
    "        print(\"patterns first samp.point - \"+str(start_el))\n",
    "        print(\"patterns last samp.point - \"+str(end_el))\n",
    "        print(\"total number of samp.points - \"+str(end_el-start_el))\n",
    "        print(\"label - \"+str(label))\n",
    "    \n",
    "        if plt.fignum_exists(self.classif_plot_fig_id)==True:\n",
    "            self.Classification_Plot_Segment()\n",
    "    \n",
    "    #assign label for entire segment\n",
    "    def Classification_Entire_Segm_To_Label_Click(self):\n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()    \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        \n",
    "        try:\n",
    "            label=(self.ui.classification_labeling_label_text.text())\n",
    "            if(label==\"\" or label==\" \"):\n",
    "                print(\"fill lable info and repeat...\")\n",
    "                return\n",
    "            #self.plates[indx_plate].sigments_labels[indx_segment].append(list([start_el,end_el,label]))\n",
    "            self.plates[indx_plate].AssignLabelToEntireSegment(segment_indx=indx_segment,label=label)\n",
    "        except:\n",
    "            print(\"check the values in the text boxes\")\n",
    "            return\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"label assigned to:\")\n",
    "        print(\"plate name - \"+str(p_name))\n",
    "        print(\"segment name - \"+str(segment_name))       \n",
    "        print(\"label - \"+str(label))\n",
    "        \n",
    "        if plt.fignum_exists(self.classif_plot_fig_id)==True:\n",
    "            self.Classification_Plot_Segment()\n",
    "    \n",
    "    #assign all labels to to category\n",
    "    def Classification_All_Segm_To_Label_Click(self):\n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return        \n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()    \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        label_=(self.ui.classification_labeling_label_text.text())\n",
    "        self.plates[indx_plate].AssignLabelToAllSegments(label=label_)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"label assigned to:\")\n",
    "        print(\"plate name - \"+str(p_name))\n",
    "        print(\"segment num. - \"+str(len(self.plates[indx_plate].sigments_sign)))       \n",
    "        print(\"label - \"+str(label_))\n",
    "\n",
    "        if plt.fignum_exists(self.classif_plot_fig_id)==True:\n",
    "            self.Classification_Plot_Segment()\n",
    "\n",
    "    #clear fo only this segment\n",
    "    def Classification_ClearLabelling_Click(self):\n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()    \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        self.plates[indx_plate].sigments_labels[indx_segment]=[]\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Labelling for plate - \"+str(p_name)+\" , segment - \"+str(segment_name) +\" erased...\")\n",
    "        \n",
    "        if plt.fignum_exists(self.classif_plot_fig_id)==True:\n",
    "            self.Classification_Plot_Segment()\n",
    "        \n",
    "\n",
    "    def Classification_ClearLabellingForAllSegments_Click(self):\n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()   \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        l_sl=len(self.plates[indx_plate].sigments_labels)\n",
    "        for jk in range(0,l_sl):\n",
    "            self.plates[indx_plate].sigments_labels[jk]=[]\n",
    "        if plt.fignum_exists(self.classif_plot_fig_id)==True:\n",
    "            self.Classification_Plot_Segment()\n",
    "        print(\"\")\n",
    "        print(\"Labelling for plate - \"+str(p_name)+\" is erased...\")\n",
    "                \n",
    "    def RunClassificationClick(self):\n",
    "        \n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return\n",
    "            \n",
    "        self.proc_settings = shlp.ReadSettings(self)\n",
    "        #read settings\n",
    "        snip_size = int(self.proc_settings.get(\"snippet_size\")) #int(self.ui.classification_snippet_size_text.text())\n",
    "        test_size=int(self.ui.classification_test_text.text())/100.0\n",
    "        classif_name= self.ui.classificationclassifier_dropdown.currentText()\n",
    "        preproc= self.proc_settings.get(\"preprocessing\")#self.ui.classification_preproc_dropdown.currentText()\n",
    "        \n",
    "        #start to create dataset from segment\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()    \n",
    "        #collect general information\n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)        \n",
    "        channels_to_use=[indx_chan]\n",
    "        if(self.proc_settings.get(\"chans_to_use\")==\"From settings\"):\n",
    "            pass\n",
    "        else:\n",
    "            chans_string=self.proc_settings.get(\"chans_list_user\")\n",
    "            channels_to_use = shlp.ExtractChannelsFromString(chans_string,separator=\",\")\n",
    "            if(channels_to_use is None):\n",
    "                print(\"Exiting training. Check settings and repeat.\")\n",
    "                return\n",
    "            else: pass\n",
    "                \n",
    "        print(\"\")\n",
    "        print(\"*********************************************************************\")\n",
    "        print(\"Training start\")\n",
    "        print(\"User selected channels: \"+str(channels_to_use))                \n",
    "        \n",
    "        #chans_to_use=window.ui.classification_channels_choice_drop_down.currentText()\n",
    "        #settings[\"chans_to_use\"] = chans_to_use\n",
    "        #chans_list_user=window.ui.classification_user_channels_text_box.text()\n",
    "        #settings[\"chans_list_user\"] = chans_list_user\n",
    "    \n",
    "        #makes snippets\n",
    "        #feat,labs = shlp.SplitIntoSnips(plates=self.plates,snip_size=snip_size,plate_name=p_name,chan_name=ch_name,segment_name=segment_name)\n",
    "        unique_labs_tags=[]\n",
    "        feat=[]\n",
    "        labs=[]\n",
    "        if(self.DataPreproc is None): self.DataPreproc=shlp.DataPreproc()   \n",
    "        plate_segm=self.proc_settings.get(\"plate_segm_process\")        \n",
    "        if(plate_segm == \"this_plate_this_segment\"):\n",
    "            feat,labs= self.DataPreproc.SplitLabPlateSegmentIntoSnips(self.plates[indx_plate],\n",
    "                                                                      snip_size=snip_size,\n",
    "                                                                      segm_index=indx_segment,\n",
    "                                                                      channs_indx=channels_to_use,#indx_chan,\n",
    "                                                                      torch_tensor=False, \n",
    "                                                                      preproc_type=preproc\n",
    "                                                                     )    \n",
    "            #print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "            #print(np.shape(np.asarray(feat)))\n",
    "            unique_labs_tags=self.plates[indx_plate].GetUniqueLabelsList()\n",
    "            #print(unique_labs_tags)\n",
    "        if(plate_segm == \"this_plate_all_segments\"):                        \n",
    "            feat,labs= self.DataPreproc.SplitAllLabPlateSegmentsIntoSnips(self.plates[indx_plate],\n",
    "                                                                          snip_size=snip_size,\n",
    "                                                                          channs_indx=channels_to_use,#indx_chan,\n",
    "                                                                          torch_tensor=False, \n",
    "                                                                          preproc_type=preproc\n",
    "                                                                         )    \n",
    "            \n",
    "            feat,labs=self.DataPreproc.Helper_FlatListOfLabeledFeat(feat,labs)\n",
    "            unique_labs_tags=self.plates[indx_plate].GetUniqueLabelsList()\n",
    "            \n",
    "        if(plate_segm == \"all_plates_all_segments\"):\n",
    "            feat,labs= self.DataPreproc.SplitAllLabPlateOfAllSegmentsIntoSnips(self.plates,\n",
    "                                                                               channs_indx=channels_to_use,#indx_chan,\n",
    "                                                                               torch_tensor=False,\n",
    "                                                                               snip_size=snip_size\n",
    "                                                                              )\n",
    "            rrt=[]\n",
    "            for l in range(0,len(self.plates)):\n",
    "                jk=self.plates[l].GetUniqueLabelsList()\n",
    "                for k in range(0,len(jk)):\n",
    "                    rrt.append(jk[k])\n",
    "            unique_labs_tags=shlp.GetUniqueElements_List(list(rrt))#list(set(rrt))\n",
    "\n",
    "        #le = preprocessing.LabelEncoder()\n",
    "        #labs_num = le.fit_transform(labs)\n",
    "        new_lab=[]\n",
    "        tag_tmp=np.arange(0,len(unique_labs_tags))#linspace(0,len(unique_labs_tags),len(unique_labs_tags))\n",
    "        for xx in range(0,len(labs)):\n",
    "            indx=unique_labs_tags.index(labs[xx])\n",
    "            tag=int(tag_tmp[indx])\n",
    "            new_lab.append(tag)\n",
    "                    \n",
    "        global CLASSIF_FEAT\n",
    "        CLASSIF_FEAT = feat\n",
    "        global CLASSIF_LABS\n",
    "        CLASSIF_LABS = new_lab\n",
    "                        \n",
    "        #*****************output info**************************\n",
    "        try:\n",
    "            print(\"\")\n",
    "            print(\"Start calssification...\")\n",
    "            print(\"Settings...\")\n",
    "            print(\"data source - \"+str(plate_segm))\n",
    "            if(plate_segm == \"this_plate_this_segment\"):\n",
    "                print(\"plate name - \"+str(p_name))\n",
    "                print(\"segment name - \"+str(segment_name))\n",
    "            if(plate_segm == \"this_plate_all_segments\"):\n",
    "                print(\"plate name - \"+str(p_name))\n",
    "                print(\"egm.num - \"+str(len(self.plates[indx_plate].sigments_sign)))\n",
    "            print(\"chan. name - \"+str(ch_name))\n",
    "            print(\"snip. length - \"+str(snip_size))\n",
    "            print(\"test set (% from training) - \"+str(test_size*100))\n",
    "            try:                 \n",
    "                print(\"unique lab. - \"+str(unique_labs_tags))  \n",
    "                print(\"unique lab. encoding \"+str(shlp.GetUniqueElements_List(new_lab)))\n",
    "            except: print(\"unique labels are undefined\")   \n",
    "            print(\"feat.shape - \" + str(np.shape(np.asarray(feat))))\n",
    "            #print(\"train shape - \"+str(np.shape(np.asarray(X_train))))\n",
    "            #print(\"test shape - \"+str(np.shape(np.asarray(X_test))))\n",
    "        except:\n",
    "            pass\n",
    "        #******************************************************\n",
    "        \n",
    "        #classification     \n",
    "        clf=None        \n",
    "        self.s_model=None\n",
    "                \n",
    "        if(self.proc_settings.get(\"algorithm\")==\"XGBoost\"):    \n",
    "            unique_labs=shlp.GetUniqueElements_List(new_lab)\n",
    "            if(len(unique_labs)<=1):\n",
    "                print(\"\")\n",
    "                if(self.proc_settings.get(\"plate_segm_process\")==\"this_plate_this_segment\"):\n",
    "                    print(\"In this segment only one label is detected. Add another label to segment and inlcude other plates/segments.\")                    \n",
    "                if(self.proc_settings.get(\"plate_segm_process\")==\"this_plate_all_segments\"):\n",
    "                    print(\"In all plate segments only one label is detected. Add another label or inlcude other plates.\")\n",
    "                else:\n",
    "                    print(\"In all plates only one label is detected.Add another label...\")\n",
    "                return\n",
    "            X_train, X_test, y_train, y_test = train_test_split(feat, new_lab, test_size=test_size)\n",
    "            print(\"training with XGBoost...\")               \n",
    "            clf,tests_l,orig_labs,intern_labs = shlp.XGBoostClassifRun(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)                           \n",
    "            cm = confusion_matrix(y_test,tests_l)#, xgb_labs_back)            \n",
    "            self.s_model=shlp.S_Classif()\n",
    "            self.s_model.AssignClassif(clf,unique_labs_tags,tag_tmp)  \n",
    "            print(str(type(self.s_model.classifier)))\n",
    "            %matplotlib qt\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clf.classes_)\n",
    "            disp.plot(cmap=plt.cm.Blues)            \n",
    "            plt.show()               \n",
    "            \n",
    "        if(self.proc_settings.get(\"algorithm\")==\"IsolationForest\"):\n",
    "            \n",
    "            #binary anomaly detector\n",
    "            clf = shlp.IsolTreesTraining(feat=feat,labels=new_lab)                        \n",
    "            self.s_model=shlp.S_Classif()\n",
    "            self.s_model.AssignClassif(clf,None,None)  \n",
    "\n",
    "        if(self.proc_settings.get(\"algorithm\")==\"DBSCAN\"):\n",
    "            clf = shlp.DBSCANTraining(feat=feat,labels=new_lab)                        \n",
    "            self.s_model=shlp.S_Classif()\n",
    "            self.s_model.AssignClassif(clf,None,None)  \n",
    "\n",
    "        if(self.proc_settings.get(\"algorithm\")==\"OneClassSVM\"):\n",
    "            clf = shlp.OneCLassSVMTraining(feat=feat,labels=new_lab)#OneClassSVM(nu=0.1, kernel=\"rbf\",gamma=0.2).fit(feat)                      \n",
    "            self.s_model=shlp.S_Classif()\n",
    "            self.s_model.AssignClassif(clf,None,None)  \n",
    "\n",
    "        if(self.proc_settings.get(\"algorithm\")==\"Autoencoder_1\"):\n",
    "            threshold=float(self.proc_settings.get(\"autoencoder_torch_thershold\"))\n",
    "            lr=float(self.proc_settings.get(\"autoencoder_torch_learn_rate\"))\n",
    "            epochs_num=int(self.proc_settings.get(\"autoencoder_torch_epochs_num\"))\n",
    "            #train/test classifier\n",
    "            model=shlp.TrainTorchAutoencoder(feat=feat,labels=new_lab,num_epochs=epochs_num,lr=lr)            \n",
    "            self.s_model=shlp.S_Classif()\n",
    "            self.s_model.AssignClassif(model,None,None)  \n",
    "            self.s_model.tocrh_autoencoder_threshold_factor=threshold\n",
    "\n",
    "        if(self.proc_settings.get(\"algorithm\")==\"Autoencoder_2\"):\n",
    "            clf,train_phi,train_mu,train_cov,args,loss=shlp.Train_Autoencoder_2(CLASSIF_FEAT,CLASSIF_LABS,\n",
    "                                                                      num_of_epochs=10,\n",
    "                                                                      patience=10,\n",
    "                                                                      lr=1e-6,\n",
    "                                                                      lr_milestones=[10],\n",
    "                                                                      batch_size=10,\n",
    "                                                                      latent_dim=50,\n",
    "                                                                      n_gmm=5,\n",
    "                                                                      lambda_energy=0.1,\n",
    "                                                                      lambda_cov=0.00005,                                                                             \n",
    "                                                                     )\n",
    "            self.s_model=shlp.S_Classif()\n",
    "            self.s_model.AssignClassif(clf,None,None)  \n",
    "            self.s_model.autoenc2_train_phi=train_phi\n",
    "            self.s_model.autoenc2_train_mu=train_mu\n",
    "            self.s_model.autoenc2_train_cov=train_cov\n",
    "            self.s_model.autoenc2_args=args\n",
    "            threshold=float(self.proc_settings.get(\"autoencoder_torch_thershold\"))\n",
    "            self.s_model.tocrh_autoencoder_threshold_factor=threshold\n",
    "            \n",
    "        if(self.proc_settings.get(\"algorithm\")==\"NonStatKern_1\"):\n",
    "            #literature links - non-stationary kernels\n",
    "            #https://www.sgp-tools.com/tutorials/non_stationary_kernels.html\n",
    "            #https://github.com/google/neural-tangents\n",
    "            pass\n",
    "\n",
    "        if(self.proc_settings.get(\"algorithm\")==\"GHKern\"):\n",
    "            #https://github.com/paulinebourigault/GHKernelAnomalyDetect\n",
    "            pass\n",
    "\n",
    "        if(self.s_model!=None):\n",
    "            self.s_model.train_feat=feat\n",
    "            self.s_model.train_labs=new_lab\n",
    "        global CLASSIFIER\n",
    "        CLASSIFIER=clf#self.classif_tmp\n",
    "        print(\"Training is complete...\")        \n",
    "            \n",
    "    def SaveLabelingAsCSV_Click(self):\n",
    "        \n",
    "        if(self.plates==[]) or(len(self.plates)==0) or (self.plates is None):\n",
    "            print(\"Plates are not loaded\")\n",
    "            return        \n",
    "            \n",
    "        path_dir = QFileDialog.getExistingDirectory()          \n",
    "        #start to create dataset from segment\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()    \n",
    "        #collect general information\n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)        \n",
    "        if(indx_chan==-1):#save all channels\n",
    "            start_=0\n",
    "            end_=len(self.plates[indx_plate].chans_names)\n",
    "        else:\n",
    "            start_=indx_chan\n",
    "            end_=indx_chan+1\n",
    "\n",
    "        for l in range(0,len(self.plates[indx_plate].sigments_labels[indx_segment])):\n",
    "            #save labels here\n",
    "            label=int(self.plates[indx_plate].sigments_labels[indx_segment][l][2])\n",
    "            labels_path=path_dir+\"\\\\Label_\"+str(label)\n",
    "            if(os.path.exists(labels_path)==False):\n",
    "                        try: os.mkdir(labels_path)\n",
    "                        except:\n",
    "                            print(\"Failed to creat a directory. Signals are not saved...\")\n",
    "                            return\n",
    "            #save channels\n",
    "            for k in range(start_,end_):             \n",
    "                    chan_sub_f=labels_path+\"\\\\\"+self.plates[indx_plate].chans_names[k]                    \n",
    "                    if(os.path.exists(chan_sub_f)==False):\n",
    "                        try: os.mkdir(chan_sub_f)\n",
    "                        except:\n",
    "                            print(\"Failed to creat a directory. Signals are not saved...\")\n",
    "                            return\n",
    "                    f_name=chan_sub_f+\"\\\\\"+p_name+\"_\"+segment_name+\"_\"+ch_name+\"_\"+\"_label_\"+str(label)+\".csv\"\n",
    "                    if os.path.exists(f_name)==True:\n",
    "                        counter=0\n",
    "                        while(True):\n",
    "                            counter+=1\n",
    "                            f_name=chan_sub_f+\"\\\\\"+str(counter)+\"_\"+p_name+\"_\"+segment_name+\"_\"+ch_name+\"_\"+signal_type+\"_label_\"+str(label)+\".csv\"\n",
    "                            if (os.path.exists(f_name)==False):\n",
    "                                break\n",
    "                    st1=int(self.plates[indx_plate].sigments_labels[indx_segment][l][0])            \n",
    "                    st2=int(self.plates[indx_plate].sigments_labels[indx_segment][l][1])            \n",
    "                    arr=self.plates[indx_plate].sigments_sign[indx_segment][k][st1:st2]\n",
    "                    df = pd.DataFrame(arr)\n",
    "                    df.to_csv(f_name)\n",
    "\n",
    "    def SetAsMainModelButton_Click(self):\n",
    "        if(self.s_model is None):\n",
    "            print(\"Prepare the model first and repeat....\")\n",
    "            self.ui.Model_ready_label.setStyleSheet(\"background-color: red\")\n",
    "        self.model=self.s_model\n",
    "        self.ui.Model_ready_label.setStyleSheet(\"background-color: green\")        \n",
    "        #if(self.model is None): self.ui.Model_ready_label.setStyleSheet(\"background-color: red\")\n",
    "        #else: self.ui.Model_ready_label.setStyleSheet(\"background-color: green\")        \n",
    "        self.ui.train_dropdown.setCurrentText(self.ui.classificationclassifier_dropdown.currentText())  \n",
    "\n",
    "    def RunClassifForSegment_Click(self):\n",
    "        self.proc_settings = shlp.ReadSettings(self)\n",
    "        if(self.plates is None): return\n",
    "        if(len(self.plates)==0): return\n",
    "        if(self.s_model is None): \n",
    "            print(\"prepare the classifier first and repeat...\")\n",
    "            return\n",
    "        #check the plate\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()   \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates,plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        snip_size=int(self.proc_settings.get(\"snippet_size\"))\n",
    "        dp=shlp.DataPreproc()     \n",
    "\n",
    "        channels_to_use=[indx_chan]\n",
    "        if(self.proc_settings.get(\"chans_to_use\")==\"From settings\"):\n",
    "            pass\n",
    "        else:\n",
    "            chans_string=self.proc_settings.get(\"chans_list_user\")\n",
    "            channels_to_use = shlp.ExtractChannelsFromString(chans_string,separator=\",\")\n",
    "            if(channels_to_use is None):\n",
    "                print(\"Exiting training. Check settings and repeat.\")\n",
    "                return\n",
    "            else:\n",
    "                pass\n",
    "        print(\"\")\n",
    "        print(\"*********************************************************************\")\n",
    "        print(\"Start test on segment.\")\n",
    "        print(\"Selected channels: \"+str(channels_to_use))              \n",
    "                    \n",
    "        %matplotlib qt\n",
    "        #show figure with results\n",
    "        \n",
    "        if(self.proc_settings.get(\"plate_segm_process\")==\"this_plate_this_segment\"):\n",
    "\n",
    "            fd=dp.SplitEntireSignalIntoSnippets(signal=self.plates[indx_plate].sigments_sign[indx_segment],\n",
    "                                            channs_indx=channels_to_use,\n",
    "                                            torch_tensor=False,\n",
    "                                            snip_size = snip_size,\n",
    "                                            preproc_type = self.proc_settings.get(\"preprocessing\")\n",
    "                                           )        \n",
    "        \n",
    "            labels=self.s_model.np_predict(np.asarray(fd))\n",
    "            classif_type=self.s_model.getClassifType()                   \n",
    "            sgn=self.plates[indx_plate].sigments_sign[indx_segment][indx_chan]    \n",
    "\n",
    "            #show everything\n",
    "            fig, ax = plt.subplots(1, sharex=True, figsize=(6, 6))        \n",
    "            ax.plot(sgn)        \n",
    "            if(True):            \n",
    "                st_=0\n",
    "                en_=snip_size\n",
    "                colors_l=[]\n",
    "                unique_l=[]\n",
    "                line_v=[]\n",
    "                \n",
    "                for l in range(0,len(labels)):\n",
    "                    cur_color=self.colors_id[int(labels[l])]\n",
    "                    line_=ax.axvspan(st_, en_, alpha=0.1, color=cur_color)\n",
    "                    st_=en_\n",
    "                    en_=st_+snip_size   \n",
    "                    if(int(labels[l]) not in unique_l):\n",
    "                        unique_l.append(int(labels[l]))\n",
    "                        colors_l.append(cur_color)\n",
    "                        line_v.append(line_)    \n",
    "                legend_tags=[]\n",
    "                orig_tags=self.s_model.orig_labels\n",
    "                for l in range(0,len(unique_l)):\n",
    "                    if(orig_tags is not None):\n",
    "                        legend_tags.append(str(orig_tags[l]))  \n",
    "                    else:\n",
    "                        legend_tags.append(str(unique_l[l]))  \n",
    "                plt.legend(line_v,legend_tags)\n",
    "                plt.show()\n",
    "\n",
    "        #only for this pattern\n",
    "        if(self.proc_settings.get(\"plate_segm_process\")==\"this_plate_all_segments\"):\n",
    "            \n",
    "            fig, ax = plt.subplots(1, sharex=True, figsize=(6, 6))        \n",
    "            segm_num=len(self.plates[indx_plate].sigments_sign)\n",
    "\n",
    "            borders=[]\n",
    "            borders.append(0)\n",
    "            ymin=[]\n",
    "            ymax=[]\n",
    "\n",
    "            unique_l=[]\n",
    "            colors_l=[]\n",
    "            \n",
    "            for n_segm in range(0,segm_num):\n",
    "\n",
    "                fd=dp.SplitEntireSignalIntoSnippets(signal=self.plates[indx_plate].sigments_sign[n_segm],\n",
    "                                            channs_indx=channels_to_use,\n",
    "                                            torch_tensor=False,\n",
    "                                            snip_size = snip_size,\n",
    "                                            preproc_type = self.proc_settings.get(\"preprocessing\")\n",
    "                                           )        \n",
    "\n",
    "                labels=self.s_model.np_predict(np.asarray(fd))                                \n",
    "                classif_type=self.s_model.getClassifType()                        \n",
    "                sgn=self.plates[indx_plate].sigments_sign[n_segm][indx_chan]  \n",
    "                ymin.append(np.min(sgn))\n",
    "                ymax.append(np.max(sgn))\n",
    "                \n",
    "                start_=borders[n_segm]\n",
    "                l_shp=np.shape(np.asarray(sgn))#self.plates[indx_plate].sigments_sign[n_segm]))\n",
    "                if(len(l_shp)==2): l_=l_shp[1]\n",
    "                if(len(l_shp)==1): l_=l_shp[0]\n",
    "                end_=start_+l_\n",
    "                borders.append(start_+l_)\n",
    "                x_=np.arange(start_,end_)\n",
    "                #print(\"XXXXXXXXXXXXXXXXXX\")\n",
    "                #print(l_shp)\n",
    "                #print(start_)\n",
    "                #print(end_)\n",
    "                #print(np.shape(sgn))\n",
    "                ax.plot(x_,sgn,color=\"blue\")     \n",
    "                \n",
    "                if(True):                  \n",
    "                    st_=start_\n",
    "                    en_=st_+snip_size\n",
    "                    colors_l=[]\n",
    "                    unique_l=[]\n",
    "                    line_v=[]\n",
    "                    #fill the backgrounds\n",
    "                    for l in range(0,len(labels)):\n",
    "                        cur_color=self.colors_id[int(labels[l])]\n",
    "                        line_=ax.axvspan(st_, en_, alpha=0.1, color=cur_color)\n",
    "                        st_=en_\n",
    "                        en_=en_+snip_size   \n",
    "                        if(int(labels[l]) not in unique_l):\n",
    "                            unique_l.append(int(labels[l]))\n",
    "                            colors_l.append(cur_color)\n",
    "                            line_v.append(line_)    \n",
    "                    legend_tags=[]\n",
    "                    orig_tags=self.s_model.orig_labels\n",
    "                \n",
    "                for l in range(0,len(unique_l)):\n",
    "                    if(orig_tags is not None):\n",
    "                        legend_tags.append(str(orig_tags[l]))  \n",
    "                    else:\n",
    "                        legend_tags.append(str(unique_l[l]))  \n",
    "\n",
    "            for jj in range(0,len(borders)):\n",
    "                if(jj<len(borders) and jj<len(ymin) and jj<len(ymax)):\n",
    "                    ax.vlines(borders[jj], ymin[jj], ymax[jj], colors=\"red\")\n",
    "            \n",
    "            plt.legend(line_v,legend_tags)\n",
    "            plt.show()\n",
    "        \n",
    "    def Plate_info_click(self):\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        indx_plate=-1\n",
    "        for k in range(0,len(self.plates)):\n",
    "            if(self.plates[k].name==p_name):\n",
    "                indx_plate=k\n",
    "                break\n",
    "        self.plates[indx_plate].plate_info()\n",
    "        \n",
    "    def set_buttons(self, enabled: bool):        \n",
    "        self.ui.load_data_button.setEnabled(enabled)\n",
    "        self.ui.load_model_button.setEnabled(enabled)\n",
    "        self.ui.train_button.setEnabled(enabled)\n",
    "        self.ui.predict_button.setEnabled(enabled)\n",
    "        #self.ui.plot_button.setEnabled(enabled)\n",
    "\n",
    "    def load_data(self):\n",
    "        PATH=self.ui.load_data_path.text()        \n",
    "        #update plates layout data        \n",
    "        plate_type=self.ui.load_data_plate_type_dropdown.currentText()\n",
    "        self.plate_segments_id=shlp.getSegmentNames(plate_type)          \n",
    "        #clean everything\n",
    "        self.plates=[]                        \n",
    "        self.plates=None #plate segments with signals     \n",
    "        self.ui.plot_plate_dropdown.clear()\n",
    "        self.ui.plot_segment_dropdown.clear()\n",
    "        self.ui.Channel_segment_plot.clear()    \n",
    "        \n",
    "        self.plates=shlp.OpenDataFromFolder(PATH=PATH,\n",
    "                                            SEGMENTATION_REF_CHAN_NAME=\"Trigger\",\n",
    "                                            SEGMENTATION_THRESHOLD=\"automatic\"    ,\n",
    "                                            SEGMENTATION_SEGMENTS_NAMES_LIST=self.plate_segments_id\n",
    "                                           )\n",
    "        \n",
    "        #fill the gui with plates collection\n",
    "        plates_names=[]\n",
    "        for k in self.plates:\n",
    "            plates_names.append(k.name)\n",
    "        \n",
    "        global PLATES\n",
    "        PLATES=self.plates\n",
    "        \n",
    "        self.ui.plot_plate_dropdown.clear()\n",
    "        self.ui.plot_plate_dropdown.addItems(plates_names)     \n",
    "        self.ui.plot_plate_dropdown.setCurrentIndex(0)\n",
    "        #set teh available segments\n",
    "        self.ui.plot_segment_dropdown.clear()\n",
    "        segm_available=list(self.plates[0].segments_names.copy())        \n",
    "        self.ui.plot_segment_dropdown.addItems(segm_available)\n",
    "        self.ui.plot_segment_dropdown.setCurrentIndex(0)\n",
    "        #channels for this plat        \n",
    "        chans_available=self.plates[0].chans_names.copy()\n",
    "        chans_available.insert(0, \"all\")\n",
    "        self.ui.Channel_segment_plot.clear()\n",
    "        self.ui.Channel_segment_plot.addItems(chans_available)\n",
    "        self.ui.Channel_segment_plot.setCurrentIndex(1)\n",
    "        #globals assign\n",
    "        print(\"Loaded plates num.: \"+str(len(self.plates)))\n",
    "        global PLATES_ARRAY\n",
    "        PLATES_ARRAY=self.plates.copy()        \n",
    "        \n",
    "    def load_data_error(self, err_text):\n",
    "        # Option 1: append to text box        \n",
    "        # # Option 2: pop up a message box\n",
    "        # from PySide6.QtWidgets import QMessageBox\n",
    "        # QMessageBox.critical(self, \"Error\", err_text)\n",
    "        # ensure thread stops\n",
    "        if hasattr(self, \"load_data_thread\") and self.load_data_thread.isRunning():\n",
    "            self.load_data_thread.quit()\n",
    "        # re-enable buttons\n",
    "        self.set_buttons(enabled=True)\n",
    "\n",
    "    def load_data_finished(self, result):\n",
    "        # Store the DataLoaderBPPLines object\n",
    "        self.dl = result\n",
    "        filenames = [plate.identifier for plate in self.dl.list_bpp]\n",
    "        # Add available options for plotting to dropdown\n",
    "        self.ui.plot_plate_dropdown.clear()\n",
    "        self.ui.plot_plate_dropdown.addItems(filenames)\n",
    "        segments = [\"ALL\"]+[f\"{seg[0]}_{seg[1]}\" for seg in self.dl.segment_keys]\n",
    "        self.ui.plot_segment_dropdown.clear()\n",
    "        self.ui.plot_segment_dropdown.addItems(segments)\n",
    "\n",
    "    def extract_features_finished(self, result):\n",
    "        # Store the FeatureExtractorBPPLines object\n",
    "        self.fe = result        \n",
    "        self.set_buttons(enabled=True)\n",
    "        # # Reset worker and thread references after cleanup\n",
    "        # self.load_data_worker = None\n",
    "        # self.extract_features_worker = None\n",
    "        # self.load_data_thread = None\n",
    "\n",
    "    def train_model(self):\n",
    "        # Clear previous output        \n",
    "        self.set_buttons(enabled=False)\n",
    "        # Setup QThread + Worker\n",
    "        self.train_thread = QThread()        \n",
    "        self.train_worker.moveToThread(self.train_thread)\n",
    "        # Connect signals:\n",
    "        # When thread starts, run train_worker\n",
    "        self.train_thread.started.connect(self.train_worker.run)\n",
    "        # When the worker emits an error signal (using error.emit()), it triggers the self.train_error method\n",
    "        self.train_worker.error.connect(self.train_error)\n",
    "        # When the worker emits the message signal (using message.emit()), it triggers the self.train_finished method\n",
    "        self.train_worker.message.connect(self.train_finished)\n",
    "        # When the worker finishes, quit the thread\n",
    "        self.train_worker.finished.connect(self.train_thread.quit)\n",
    "        # When the thread completes (successfully or with error), it emits the finished signal\n",
    "        # The deleteLater() method is called, which schedules the thread object for deletion\n",
    "        # Memory is cleaned up automatically when Qt's event loop processes the deletion\n",
    "        self.train_thread.finished.connect(self.train_thread.deleteLater)        \n",
    "        # Start thread\n",
    "        self.train_thread.start()\n",
    "\n",
    "    def train_error(self, err_text):\n",
    "        # Option 1: append to text box\n",
    "        \n",
    "        # # Option 2: pop up a message box\n",
    "        # from PySide6.QtWidgets import QMessageBox\n",
    "        # QMessageBox.critical(self, \"Error\", err_text)\n",
    "        # ensure thread stops\n",
    "        if hasattr(self, \"train_thread\") and self.train_thread.isRunning():\n",
    "            self.train_thread.quit()\n",
    "        # re-enable button\n",
    "        self.set_buttons(enabled=True)\n",
    "\n",
    "    def train_finished(self, result):\n",
    "        # Store the ModelSelectorBPPLines object\n",
    "        self.ms = result\n",
    "        self.model = result.trained_model\n",
    "        self.threshold_params = result.best_threshold_params        \n",
    "        # Set dropdown options\n",
    "        #self.ui.load_model_dropdown.clear()\n",
    "        #model_names = [m.split(\".\")[0] for m in os.listdir(\"models\") if m.endswith(\".pkl\")]\n",
    "        #self.ui.load_model_dropdown.addItems(model_names)\n",
    "        self.set_buttons(enabled=True)\n",
    "        # # Reset worker and thread references\n",
    "        # self.train_worker = None\n",
    "        # self.train_thread = None\n",
    "\n",
    "    def load_model(self):        \n",
    "        self.set_buttons(enabled=False)\n",
    "        try:\n",
    "            #model_name = self.ui.load_model_dropdown.currentText()\n",
    "            model_path = os.path.join(\"models\", f\"{model_name}.pkl\")\n",
    "            loaded_model_data = joblib.load(model_path)\n",
    "            self.model = loaded_model_data['trained_model']\n",
    "            self.threshold_params = loaded_model_data['best_threshold_params']        \n",
    "        except Exception as e:\n",
    "            pass\n",
    "        finally:\n",
    "            self.set_buttons(enabled=True)\n",
    "\n",
    "    def predict(self):\n",
    "\n",
    "        # Clear previous output\n",
    "        self.ui.predict_output.clear()\n",
    "        self.set_buttons(enabled=False)\n",
    "\n",
    "        # Setup QThread + Worker\n",
    "        self.predict_thread = QThread()\n",
    "        self.predict_worker = Worker(PredictorScorerBPPLines, self.fe, self.model, self.threshold_params, output_widget=self.ui.predict_output)\n",
    "        self.predict_worker.moveToThread(self.predict_thread)\n",
    "\n",
    "        # Connect signals:\n",
    "        # When thread starts, run train_worker\n",
    "        self.predict_thread.started.connect(self.predict_worker.run)\n",
    "        # When the worker emits an error signal (using error.emit()), it triggers the self.train_error method\n",
    "        self.predict_worker.error.connect(self.predict_error)\n",
    "        # When the worker emits the message signal (using message.emit()), it triggers the self.train_finished method\n",
    "        self.predict_worker.message.connect(self.predict_finished)\n",
    "        # When the worker finishes, quit the thread\n",
    "        self.predict_worker.finished.connect(self.predict_thread.quit)\n",
    "        # When the thread completes (successfully or with error), it emits the finished signal\n",
    "        # The deleteLater() method is called, which schedules the thread object for deletion\n",
    "        # Memory is cleaned up automatically when Qt's event loop processes the deletion\n",
    "        self.predict_thread.finished.connect(self.predict_thread.deleteLater)        \n",
    "        # Start thread\n",
    "        self.predict_thread.start()\n",
    "\n",
    "    def predict_error(self, err_text):\n",
    "        # Option 1: append to text box\n",
    "        self.ui.predict_output.append(f\"ERROR\\n{err_text}\")\n",
    "        # # Option 2: pop up a message box\n",
    "        # from PySide6.QtWidgets import QMessageBox\n",
    "        # QMessageBox.critical(self, \"Error\", err_text)\n",
    "\n",
    "        # ensure thread stops\n",
    "        if hasattr(self, \"predict_thread\") and self.predict_thread.isRunning():\n",
    "            self.predict_thread.quit()\n",
    "\n",
    "        # re-enable button\n",
    "        self.set_buttons(enabled=True)\n",
    "\n",
    "    def predict_finished(self, result):\n",
    "        # Store the PredictorScorerBPPLines object\n",
    "        self.ps = result\n",
    "        self.ui.predict_output.append(\"DONE\")\n",
    "        self.set_buttons(enabled=True)\n",
    "\n",
    "    def plot_signal(self):\n",
    "\n",
    "        self.set_buttons(enabled=False)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            # Create your plot here - replace this with your actual plotting function\n",
    "            plate_id = self.ui.plot_plate_dropdown.currentText()\n",
    "            segment = self.ui.plot_segment_dropdown.currentText()\n",
    "            plate = next((p for p in self.dl.list_bpp if p.identifier == plate_id), None)\n",
    "            if plate is None:\n",
    "                raise ValueError(f\"Plate with identifier '{plate_id}' not found.\")\n",
    "\n",
    "            fig, ax = self.prepare_plot(plate = plate, segment = segment)\n",
    "            \n",
    "            # Create a new window to display the plot\n",
    "            plot_dialog = QDialog(self)\n",
    "            plot_dialog.setWindowTitle(\"Empa GUI Plot\")\n",
    "            # Get screen dimensions and fit plot to screen\n",
    "            screen = QApplication.primaryScreen().geometry()\n",
    "            plot_dialog.resize(int(screen.width()), int(screen.height()*0.9))\n",
    "            \n",
    "            layout = QVBoxLayout()\n",
    "            canvas = FigureCanvasQTAgg(fig)\n",
    "            layout.addWidget(canvas)\n",
    "            plot_dialog.setLayout(layout)\n",
    "            \n",
    "            plot_dialog.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            QMessageBox.critical(self, \"Error\", f\"Failed to create plot: {str(e)}\")\n",
    "\n",
    "        finally:\n",
    "            self.set_buttons(enabled=True)\n",
    "\n",
    "    def prepare_plot(\n",
    "        self,\n",
    "        plate,\n",
    "        segment: str,\n",
    "        plot_every: int = 1,\n",
    "        include_trigger: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        TBC\n",
    "        \"\"\"\n",
    "        plot_kwargs = {\n",
    "            \"x\": \"Time\",\n",
    "            \"xlabel\": \"Time [s]\",\n",
    "            \"ylabel\": \"Amplitude [V]\",\n",
    "        }\n",
    "\n",
    "        colors = [\"purple\", \"orange\", \"blue\"]\n",
    "\n",
    "        # Get screen dimensions for maximum figure size\n",
    "        # screen = QApplication.primaryScreen().geometry()\n",
    "        # figsize = (screen.width()/100, screen.height()/100)  # Convert pixels to inches (approximate)\n",
    "\n",
    "        data = plate.dataframe[::plot_every] if segment == \"ALL\" else plate.segments[tuple(segment.split(\"_\"))][::plot_every]\n",
    "\n",
    "        channels=(\n",
    "            plate.data_channels + [plate.trigger_channel]\n",
    "            if include_trigger\n",
    "            else plate.data_channels\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(nrows = len(channels), sharex=True)#figsize=figsize)\n",
    "\n",
    "        for idx, channel in enumerate(channels):\n",
    "            ax[idx] = data.plot(\n",
    "                y=channel,\n",
    "                ax=ax[idx],\n",
    "                color = colors[idx % len(colors)],\n",
    "                **plot_kwargs,\n",
    "            )\n",
    "\n",
    "        fig.suptitle(f\"Segment {segment} from plate {plate.identifier}\" if segment != \"ALL\" else f\"Complete signal from plate {plate.identifier}\")\n",
    "\n",
    "        # Mark defective segments with a red vertical band\n",
    "        if self.ps is not None and hasattr(self.ps, 'pred_defect_seg'):  \n",
    "            if segment == \"ALL\":\n",
    "                pred_defect_seg_plate = [(seg[1],seg[2]) for seg in self.ps.pred_defect_seg if seg[0]==plate.identifier]\n",
    "                for seg in pred_defect_seg_plate:\n",
    "                    seg_start, seg_end = plate.segments[seg][\"Time\"].iloc[[0, -1]]\n",
    "                    for idx in range(len(channels)):\n",
    "                        ax[idx].axvspan(seg_start, seg_end, alpha=0.2, color='red')\n",
    "            else:\n",
    "                seg_key = tuple(segment.split(\"_\"))\n",
    "                df_all = self.fe.df_all_locations\n",
    "                df_seg = df_all[(df_all['plate']==plate.identifier) & (df_all['segment_type']==seg_key[0]) & (df_all['segment_number']==seg_key[1])]\n",
    "                \n",
    "                for _, row in df_seg.iterrows():\n",
    "                    for idx in range(len(channels)):\n",
    "                        ax[idx].axvspan(row[\"start_time\"], row[\"end_time\"], alpha=row[\"pred_proba\"], color='red')\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "    #\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "    #\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"Settings\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "    #autoencoder settings\n",
    "    def Autoencoder_set_threshold_click(self):        \n",
    "        if(self.s_model is None):\n",
    "            print(\"Classifier is not defined. Prepare the calssifier and repeat\")\n",
    "            return\n",
    "        cls_type=type(self.s_model.classifier)\n",
    "        if(str(cls_type) != \"<class 'SHelpers.Autoencoder'>\"):\n",
    "            print(\"Current classifier is not the Autoencoder type. Make autoencoder model and repeat...\")\n",
    "            return\n",
    "        self.proc_settings = shlp.ReadSettings(self)\n",
    "        self.s_model.tocrh_autoencoder_threshold_factor=float(self.proc_settings.get(\"autoencoder_torch_thershold\"))     \n",
    "        #extract features\n",
    "        feat=  self.s_model.train_feat\n",
    "        thresh=self.s_model.tocrh_autoencoder_threshold_factor\n",
    "        bins=int(self.proc_settings.get(\"autoencoder_bin_num\")) #Autoencoderbins_text_input\n",
    "        if (self.autoencoder_hist_form_id==\"\"):self.autoencoder_hist_form_id = str(uuid.uuid1())[:5]  \n",
    "        %matplotlib qt\n",
    "        fig=plt.figure(self.autoencoder_hist_form_id)\n",
    "        ax=fig.subplots()\n",
    "        labs_tests=shlp.PredictTorchAutoencoder(model=self.s_model.classifier, feat=feat,thresh_fact=thresh,show_hist=True,bins_num=bins,fig_ax=ax)\n",
    "\n",
    "    #spectrograms settings\n",
    "    def Tool_Test_Spectrograms_MEL_Botton_Click(self):\n",
    "        if(self.plates==None):\n",
    "            print(\"plates are not loaded...\")\n",
    "            return\n",
    "        if(self.plates==[]):\n",
    "            print(\"plates are not loaded...\")\n",
    "            return\n",
    "        self.proc_settings = shlp.ReadSettings(self)\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()   \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        signals=[]\n",
    "        end_=indx_chan+1\n",
    "        start_=indx_chan\n",
    "        if(end_==-1): \n",
    "            end_ = len(self.plates[indx_plate].segment_sign[indx_segment]) #we taek all signals\n",
    "            start=0\n",
    "        SAMPLE_RATE=int(self.plates[indx_plate].sr)        \n",
    "        for i in range(start_,end_):\n",
    "            # Define transform            \n",
    "            waveform=torch.tensor(self.plates[indx_plate].sigments_sign[indx_segment][i])\n",
    "            if(len(waveform.shape)==1):waveform = waveform[None, :]\n",
    "            spectrogrym_MEL_nfft=int(self.proc_settings.get(\"spectrogrym_MEL_nfft\"))\n",
    "            spectrogram = T.Spectrogram(n_fft=spectrogrym_MEL_nfft)\n",
    "            # Perform transform\n",
    "            spec = spectrogram(waveform)\n",
    "            %matplotlib qt\n",
    "            fig, axs = plt.subplots(2, 1)\n",
    "            shlp.plot_waveform(waveform, SAMPLE_RATE, title=\"Original waveform\", ax=axs[0])\n",
    "            shlp.plot_spectrogram(spec[0], title=\"spectrogram\", ax=axs[1])\n",
    "            fig.tight_layout()\n",
    "        \n",
    "        \n",
    "    def Tool_Show_Spectrograms_MEL_Botton_Click(self):\n",
    "        if(self.plates==None):\n",
    "            print(\"plates are not loaded...\")\n",
    "            return\n",
    "        if(self.plates==[]):\n",
    "            print(\"plates are not loaded...\")\n",
    "            return\n",
    "        self.proc_settings = shlp.ReadSettings(self)\n",
    "        p_name = self.ui.plot_plate_dropdown.currentText()\n",
    "        ch_name=self.ui.Channel_segment_plot.currentText()        \n",
    "        segment_name=self.ui.plot_segment_dropdown.currentText()   \n",
    "        indx_plate,indx_chan, indx_segment = shlp.FindPlateInArray(plates=self.plates.copy(),plate_name=p_name,chan_name=ch_name,segm_name=segment_name)\n",
    "        signals=[]\n",
    "        end_=indx_chan+1\n",
    "        start_=indx_chan\n",
    "        if(end_==-1): \n",
    "            end_ = len(self.plates[indx_plate].segment_sign[indx_segment]) #we taek all signals\n",
    "            start=0\n",
    "        SAMPLE_RATE=int(self.plates[indx_plate].sr)        \n",
    "        snip_size=int(self.proc_settings.get(\"snippet_size\"))\n",
    "        spectrogrym_MEL_nfft=int(self.proc_settings.get(\"spectrogrym_MEL_nfft\"))\n",
    "        for i in range(start_,end_):\n",
    "            # Define transform            \n",
    "            waveform=torch.tensor(self.plates[indx_plate].sigments_sign[indx_segment][i])         \n",
    "            sls=None\n",
    "            try: sls=waveform.data[:snip_size]#snip_tensor = torch.take(waveform, torch.tensor([0:snip_size]))#\n",
    "            except:\n",
    "                print(\"waveform is too short to line it into snippets...\")\n",
    "                return            \n",
    "            if(len(sls.shape)==1):sls=sls[None, :]   \n",
    "            if(len(waveform.shape)==1):waveform=waveform[None, :]              \n",
    "            spectrogram = T.Spectrogram(n_fft=spectrogrym_MEL_nfft)\n",
    "            # Perform transform\n",
    "            spec = spectrogram(sls)\n",
    "            ymin=torch.min(waveform)\n",
    "            ymax=torch.max(waveform)\n",
    "            %matplotlib qt            \n",
    "            #matplotlib.pyplot.vlines(x, ymin, ymax,colors=red)\n",
    "            fig, axs = plt.subplots(2, 1)\n",
    "            shlp.plot_waveform(waveform, SAMPLE_RATE, title=\"Original waveform\", ax=axs[0])\n",
    "            shlp.plot_spectrogram(spec[0], title=\"spectrogram\", ax=axs[1])\n",
    "            axs[0].vlines(snip_size, ymin, ymax,colors=\"red\")\n",
    "            fig.tight_layout()\n",
    "    #**********************************************************************************************\n",
    "    #**********************************************************************************************\n",
    "    #******************************FILES FOLDERS/DAQ TRACKING**************************************\n",
    "    #**********************************************************************************************\n",
    "    def Real_Time_Stop_Click(self):        \n",
    "        if(self.Real_time_FolderTrackerThread is None):\n",
    "            pass\n",
    "        else:\n",
    "            #self.ExitFilesInFolderFlag=True\n",
    "            #self.Real_time_FolderTrackerThread.join()\n",
    "            #while (self.Real_time_FolderTrackerThread.is_alive()):\n",
    "            #time.sleep(20)\n",
    "            #self.ui.Real_time_Frame_counter_label.setText(\"-\")\n",
    "            self.ExitFilesInFolderFlag=True\n",
    "            #self.Real_time_FolderTrackerThread.kill()#for shlp.thread_with_trace            \n",
    "            #self.Real_time_FolderTrackerThread.join(timeout=0.5)\n",
    "            if not self.Real_time_FolderTrackerThread.is_alive():\n",
    "                print(\"Real time tracking is terminated...\")            \n",
    "            self.ui.real_time_status_label.setText(\"Not active\")\n",
    "            self.ExitFilesInFolderFlag=False\n",
    "            self.Real_time_FolderTrackerThread=None\n",
    "            \n",
    "        if(self.RT_SpectrumThread is None):\n",
    "            pass\n",
    "        else:\n",
    "            global EXIT_DAQ_FLAG\n",
    "            EXIT_DAQ_FLAG=True\n",
    "            self.RT_SpectrumThread.do_run = False\n",
    "            try:\n",
    "                while (self.Real_time_FolderTrackerThread.is_alive()):z=0 \n",
    "            except: pass\n",
    "            self.ui.real_time_status_label.setText(\"Not active\")            \n",
    "            self.RT_SpectrumThread=None\n",
    "        \n",
    "    def Real_Time_Button_Click(self):        \n",
    "        if(self.s_model is None):\n",
    "            print(\"Load model first and repeat...\")\n",
    "            return\n",
    "        \n",
    "        self.proc_settings = shlp.ReadSettings(self)        \n",
    "        rt_source=self.proc_settings.get(\"real_time_source\")\n",
    "        channs_indx=[0]\n",
    "        snip_size=int(self.proc_settings.get(\"snippet_size\"))\n",
    "        s_model=self.s_model \n",
    "        colors=self.colors_id\n",
    "        rt_folder=self.proc_settings.get(\"real_time_folder_text\")\n",
    "        preprocessing=self.proc_settings.get(\"preprocessing\")\n",
    "        \n",
    "        if(rt_source != \"Folder\") and (rt_source != \"RealTime\"):\n",
    "            return                           \n",
    "        if(rt_source == \"Folder\"):\n",
    "            rt_path = self.proc_settings.get(\"real_time_folder_text\")                \n",
    "            if not os.path.exists(rt_path):\n",
    "                try: os.makedirs(rt_path)\n",
    "                except: \n",
    "                    print(\"\")\n",
    "                    print(\"The real time folder cant be created. Check admin rights and repeat...\")\n",
    "                    return\n",
    "\n",
    "            %matplotlib qt\n",
    "            plt.ion()\n",
    "            fig, fig_ax = plt.subplots()\n",
    "                    \n",
    "            self.ui.Real_time_Frame_counter_label.setText(str(0))\n",
    "            self.rt_FrameCounter=0\n",
    "            self.ExitFilesInFolderFlag=False        \n",
    "            self.Real_time_FolderTrackerThread= threading.Thread(target=self.FilesFolderTracking1,\n",
    "                                                                 args=(rt_folder,channs_indx,snip_size,preprocessing,s_model,colors,fig,fig_ax)) \n",
    "            self.Real_time_FolderTrackerThread.start()            \n",
    "            self.ui.real_time_status_label.setText(\"Active\")\n",
    "\n",
    "        if(rt_source == \"RealTime\"):\n",
    "            #read settings         \n",
    "            try:\n",
    "                trig_level=float(self.proc_settings.get(\"trigger_level\"))\n",
    "                sampling_rate=float(self.proc_settings.get(\"sampling_rate\"))\n",
    "                pre_trigger_duration=float(self.proc_settings.get(\"pre_trigger_duration\"))\n",
    "                post_trigger_duration=float(self.proc_settings.get(\"post_trigger_duration\"))\n",
    "                ampl_per_channel=float(self.proc_settings.get(\"ampl_per_channel\"))\n",
    "                trig_chan_num=int(self.proc_settings.get(\"trig_chan_num\"))\n",
    "                show_info=bool(self.proc_settings.get(\"show_info\"))\n",
    "                show_original_signals=bool(self.proc_settings.get(\"show_original_signals\"))\n",
    "                show_proc_signals=bool(self.proc_settings.get(\"show_proc_signals\"))\n",
    "                only_single_shot=bool(self.proc_settings.get(\"only_single_shot\"))                \n",
    "            except:\n",
    "                print(\"non correct values in textboxes in real time settings. Correct and restart...\")\n",
    "                return\n",
    "            \n",
    "            #set globals for exit loop in thread\n",
    "            global EXIT_DAQ_FLAG\n",
    "            EXIT_DAQ_FLAG=False\n",
    "                       \n",
    "            %matplotlib qt            \n",
    "            if(show_proc_signals==True):\n",
    "                plt.ion()\n",
    "                if(self.RT_Figure_if_proc_results_id == \"\"):self.RT_Figure_if_proc_results_id=\"Spectrum_original_signals\"+str(uuid.uuid1())[:5]             \n",
    "                fig_processed = plt.figure(self.RT_Figure_if_proc_results_id)\n",
    "                fig_ax_processed = fig_processed.add_subplot(111)\n",
    "                plt.show()\n",
    "                #fig_processed, fig_ax_processed = plt.subplots()\n",
    "                #fig_processed.canvas.set_window_title(self.RT_Figure_if_proc_results_id)\n",
    "            else:\n",
    "                fig_processed, fig_ax_processed=None,None\n",
    "            if(show_original_signals==True):\n",
    "                plt.ion()\n",
    "                if(self.RT_Figure_if_orig_sgn==\"\"):self.RT_Figure_if_orig_sgn=\"Spectrum_original_signals\"+str(uuid.uuid1())[:5]  \n",
    "                fig_orig_signals = plt.figure(self.RT_Figure_if_orig_sgn)\n",
    "                fig_ax_orig_signals = fig_orig_signals.add_subplot(111)\n",
    "                plt.show()\n",
    "                #fig_orig_signals.canvas.set_window_title(self.RT_Figure_if_orig_sgn)\n",
    "            else:\n",
    "                fig_orig_signals, fig_ax_orig_signals = None, None\n",
    "                \n",
    "            self.RT_SpectrumThread= threading.Thread(target=self.DAQCard,args=(trig_level,\n",
    "                                                                               sampling_rate,\n",
    "                                                                               ampl_per_channel,\n",
    "                                                                               [0,3,5],\n",
    "                                                                               trig_chan_num,\n",
    "                                                                               post_trigger_duration,\n",
    "                                                                               pre_trigger_duration,\n",
    "                                                                               snip_size,\n",
    "                                                                               preprocessing,\n",
    "                                                                               only_single_shot,\n",
    "                                                                               s_model,\n",
    "                                                                               colors,\n",
    "                                                                               show_original_signals,\n",
    "                                                                               fig_orig_signals,\n",
    "                                                                               fig_ax_orig_signals,\n",
    "                                                                               show_info,                                                                    \n",
    "                                                                               show_proc_signals,                                                                               \n",
    "                                                                               fig_processed,\n",
    "                                                                               fig_ax_processed)) \n",
    "            self.RT_SpectrumThread.start()   \n",
    "\n",
    "    #****************************************************************************************************************************\n",
    "    #*******************************TRACKING FOLDER******************************************************************************\n",
    "        \n",
    "    def FilesFolderTracking1(self,rt_folder,chan_indx,snip_size,preprocessing,s_model,colorscheme,fig,fig_ax): \n",
    "\n",
    "        import SHelpers as shlp\n",
    "        #import matplotlib\n",
    "        #matplotlib.use('agg')\n",
    "        #%matplotlib qt    \n",
    "        \n",
    "        Counter=0\n",
    "        txtfiles = []          \n",
    "        proc_data=shlp.DataPreproc()\n",
    "        Proceed_to_proc=False\n",
    "        plates=[]\n",
    "        data_proc=shlp.DataPreproc()\n",
    "        all_labels=[]\n",
    "        all_segm_sign=[]\n",
    "\n",
    "        start_t=0\n",
    "        end_t=0\n",
    "\n",
    "        viz_start_t=0\n",
    "        viz_end_t=0\n",
    "\n",
    "        t = threading.current_thread()\n",
    "        while(getattr(t, \"do_run\", True)):\n",
    "            #check for exit\n",
    "            if(self.ExitFilesInFolderFlag==True):\n",
    "                print(\"Exiting file tracker\")\n",
    "                break\n",
    "\n",
    "            txtfiles=[]\n",
    "            for x in os.listdir(rt_folder):#for file in glob.glob(\"*.txt\"):\n",
    "                #check for exit\n",
    "                if(self.ExitFilesInFolderFlag==True):\n",
    "                    print(\"Exiting file tracker\")\n",
    "                    break                \n",
    "                #txtfiles.append(file)                \n",
    "                if x.endswith(\".txt\"):\n",
    "                    txtfiles.append(x)\n",
    "                    \n",
    "            if(len(txtfiles)==0):\n",
    "                continue\n",
    "\n",
    "            for l in range(0,len(txtfiles)):\n",
    "                #check for exit\n",
    "                if(self.ExitFilesInFolderFlag==True):\n",
    "                    print(\"Exiting file tracker\")\n",
    "                    break     \n",
    "                txt_path=rt_folder+\"\\\\\"+txtfiles[l]                \n",
    "                #open plate - first check \n",
    "                f_base=os.path.splitext(os.path.basename(txtfiles[l]))[0]                \n",
    "                f_bin=\"\"\n",
    "                for x in os.listdir(rt_folder):\n",
    "                    if x.endswith(\".bin\"):\n",
    "                        x_base=os.path.splitext(os.path.basename(x))[0]          \n",
    "                        if(str(x_base) in str(f_base)):\n",
    "                            f_bin=x\n",
    "                if(f_bin==\"\"):\n",
    "                    continue\n",
    "                bin_path=rt_folder+\"\\\\\"+f_bin     \n",
    "                #check if files are occupied or not                \n",
    "                try:\n",
    "                    os.rename(bin_path,bin_path)\n",
    "                    os.rename(txt_path,txt_path)\n",
    "                except:                     \n",
    "                    continue\n",
    "\n",
    "                #open/processing                \n",
    "                plates=[]\n",
    "                try: plates= shlp.OpenDataFromFolder(ONLY_SINGLE_FILE=True,SINGLE_FILE_PATH_BIN=bin_path,SINGLE_FILE_PATH_TXT=txt_path)\n",
    "                except Exception as ex: \n",
    "                    print(\"\")\n",
    "                    print(\"Impossible to open data. Exception raised: \"+str(ex))\n",
    "                    \n",
    "                #preprocessing\n",
    "                if(len(plates)==0):Proceed_to_proc=False\n",
    "                elif(plates is None): Proceed_to_proc=False\n",
    "                elif(plates[0] is None): Proceed_to_proc=False\n",
    "                else: Proceed_to_proc=True\n",
    "                if(Proceed_to_proc==True):\n",
    "                    sgn_len = len(plates[0].sigments_sign)\n",
    "                    all_labels=[]\n",
    "                    all_segm_sign=[]\n",
    "                    for seg_i in range(0,sgn_len):\n",
    "                        #take segment\n",
    "                        segm_signal=plates[0].sigments_sign[seg_i]\n",
    "                        snippets=data_proc.SplitEntireSignalIntoSnippets(signal=segm_signal,\n",
    "                                                                         channs_indx=chan_indx,\n",
    "                                                                         torch_tensor=False,\n",
    "                                                                         snip_size = snip_size,\n",
    "                                                                         preproc_type = preprocessing\n",
    "                                                                         )\n",
    "                        start_t=time.time()\n",
    "                        labels=s_model.np_predict(np.asarray(snippets))\n",
    "                        end_t=time.time()\n",
    "                        all_labels.append(labels) \n",
    "                        all_segm_sign.append(segm_signal)\n",
    "                    #show everything in the chart   \n",
    "                    try:\n",
    "                        #check for exit\n",
    "                        if(self.ExitFilesInFolderFlag==True):\n",
    "                            print(\"Exiting file tracker\")\n",
    "                            break\n",
    "                        viz_start_t=time.time()\n",
    "                        shlp.ShowResultsInFigure_AllSegmentsInRow(all_segm_sign,all_labels,chan_indx,snip_size,colorscheme,fig,fig_ax,None)\n",
    "                        viz_end_t=time.time()\n",
    "                    except:\n",
    "                        print(\"Figure is anavailable.\")\n",
    "                #end of processing\n",
    "\n",
    "                #clean files\n",
    "                try:  os.remove(txt_path)\n",
    "                except: pass\n",
    "                try:  os.remove(bin_path)                    \n",
    "                except: pass  #not_deleted_files.append(rt_folder+\"\\\\\"+txtfiles[l])\n",
    "                Counter+=1  \n",
    "                print(\"\")\n",
    "                print(\"Measurements number - \"+str(Counter))\n",
    "                print(\"Processing time - \"+str(end_t-start_t))\n",
    "                print(\"Vizualization time - \"+str(viz_end_t-viz_start_t))\n",
    "            #self.ui.Real_time_Frame_counter_label.setText(str(self.rt_FrameCounter))       \n",
    "            \n",
    "            #check for exit\n",
    "            if(self.ExitFilesInFolderFlag==True):\n",
    "                print(\"Exiting file tracker\")\n",
    "                break\n",
    "\n",
    "    #*****************************************************************************************************\n",
    "    #*****************************************************************************************************\n",
    "    #*****************SPECTRUM DAQ************************************************************************\n",
    "\n",
    "    def DAQCard(self,\n",
    "                trigger_level,#=2200, # mV\n",
    "                sampling_rate,#=0.1, #MHz\n",
    "                amplitude,#=5000, # mV\n",
    "                channels_to_use,#[0,3,5],                \n",
    "                trigger_channel,#=0,\n",
    "                post_trig_duarat,#=1, # ms\n",
    "                pretrig_duaration,#=0.1,#ms\n",
    "                snip_size,#500\n",
    "                preprocessing,\n",
    "                only_single_shot,\n",
    "                s_model,       \n",
    "                colorscheme,#this is to show\n",
    "                show_origin_signals,#=False,\n",
    "                show_origin_signals_fig,\n",
    "                show_origin_signals_ax,#=None,\n",
    "                info_print,#=True,\n",
    "                #processing\n",
    "                show_proc_signals,                                              \n",
    "                fig_show_proc_signals,\n",
    "                fig_ax_proc_signals,\n",
    "            ):\n",
    "\n",
    "        import SHelpers as shlp\n",
    "        \n",
    "        # EXIT_FLAG=exit_flag#False\n",
    "        TRIGGER_LEVEL=trigger_level#2200 # mV\n",
    "        SAMPLING_RATE=sampling_rate#0.1 #MHz\n",
    "        AMPLITUDE=amplitude#5000 # mV\n",
    "        CHANNELS_TO_USE=channels_to_use#[0,3,5]\n",
    "        TRIGGER_CHANNEL=trigger_channel#0\n",
    "        POSTTRIG_DURATION=post_trig_duarat #1 # ms\n",
    "        PRETRIG_DURATION=pretrig_duaration#0.1#ms\n",
    "        SHOW_ORIGIN_SIGNALS=show_origin_signals#False\n",
    "        SHOW_ORIGIN_SIGNALS_FIG=show_origin_signals_fig\n",
    "        SHOW_ORIGIN_SIGNALS_AX=show_origin_signals_ax#None\n",
    "        DATA_PRINT=info_print#True\n",
    "        SHOW_PROC_RESULTS= show_proc_signals\n",
    "        SHOW_PROC_RESULTS_FIG=fig_show_proc_signals\n",
    "        SHOW_PROC_RESULTS_AX=fig_ax_proc_signals\n",
    "        ONLY_SINGLE_SHOT=only_single_shot\n",
    "        #https://spectruminstrumentation.github.io/spcm/spcm.html#Trigger\n",
    "        #def SPECTRUM_DAQ():\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Spectrum card real time settings: \")\n",
    "        print(\"Trigger level(mV): \" +str(TRIGGER_LEVEL))\n",
    "        print(\"Sampling rate(MHz): \" +str(SAMPLING_RATE))\n",
    "        print(\"Amplitude/channel(mV): \" +str(AMPLITUDE))\n",
    "        print(\"Channels to use: \" +str(CHANNELS_TO_USE))\n",
    "        print(\"Trigger channel: \" +str(TRIGGER_CHANNEL))\n",
    "        print(\"Trigger level(mV): \" +str(TRIGGER_LEVEL))\n",
    "        print(\"Post trigger duration(ms): \" +str(POSTTRIG_DURATION))\n",
    "        print(\"Pre trigger duration(ms): \" +str(PRETRIG_DURATION))\n",
    "        print(\"SHow original signals: \" +str(SHOW_ORIGIN_SIGNALS))\n",
    "        print(\"Signal info output: \" +str(DATA_PRINT))\n",
    "        print(\"Show preprocessing results: \" +str(SHOW_PROC_RESULTS))\n",
    "        print(\"\")\n",
    "        print(\"LAUNCH REAL TIME...\")\n",
    "        print(\"\")\n",
    "        \n",
    "        signals_counter=0\n",
    "        signals=[]\n",
    "        for i in range(0,8):\n",
    "            signals.append([])        \n",
    "        plate=None\n",
    "        data_proc=shlp.DataPreproc()\n",
    "        all_labels=[]\n",
    "        all_segm_sign=[]\n",
    "        proc_time=[]\n",
    "        viz_time=[]\n",
    "        \n",
    "        card:spcm.Card\n",
    "        #prepare the figure\n",
    "        #with spcm.Card('/dev/spcm0') as card:                         # if you want to open a specific card\n",
    "        # with spcm.Card('TCPIP::192.168.1.10::inst0::INSTR') as card:  # if you want to open a remote card\n",
    "        # with spcm.Card(serial_number=12345) as card:                  # if you want to open a card by its serial number\n",
    "          \n",
    "        with spcm.Card(card_type=spcm.SPCM_TYPE_AI) as card:            # if you want to open the first card of a specific type\n",
    "            ##threading termination - https://stackoverflow.com/questions/18018033/how-to-stop-a-looping-thread-in-python\n",
    "            t = threading.current_thread()\n",
    "            while(getattr(t, \"do_run\", True)):   \n",
    "                if(EXIT_DAQ_FLAG==True):\n",
    "                    print(\"Data acquisition is terminating...\")\n",
    "                    break\n",
    "                \n",
    "                # do a simple standard setup\n",
    "                card.card_mode(spcm.SPC_REC_STD_SINGLE)     # single trigger standard mode\n",
    "                card.timeout(5 * units.s)                     # timeout 5 s\n",
    "            \n",
    "                trigger = spcm.Trigger(card)\n",
    "                trigger.or_mask(spcm.SPC_TMASK_NONE)       # trigger set to none #software\n",
    "                trigger.and_mask(spcm.SPC_TMASK_NONE)      # no AND mask\n",
    "            \n",
    "                clock = spcm.Clock(card)\n",
    "                clock.mode(spcm.SPC_CM_INTPLL)            # clock mode internal PLL\n",
    "                clock.sample_rate(SAMPLING_RATE * units.MHz, return_unit=units.MHz)\n",
    "            \n",
    "                # setup the channels\n",
    "                #channel0\n",
    "                channel0, = spcm.Channels(card, card_enable=spcm.CHANNEL0) # enable channel 0\n",
    "                channel0.amp(AMPLITUDE * units.mV)\n",
    "                channel0.offset(0 * units.mV)\n",
    "                channel0.termination(0)\n",
    "                #channel1\n",
    "                channel1, = spcm.Channels(card, card_enable=spcm.CHANNEL1) # enable channel 1\n",
    "                channel1.amp(AMPLITUDE * units.mV)\n",
    "                channel1.offset(0 * units.mV)\n",
    "                channel1.termination(0)\n",
    "                #channel2\n",
    "                channel2, = spcm.Channels(card, card_enable=spcm.CHANNEL2) # enable channel 1\n",
    "                channel2.amp(AMPLITUDE * units.mV)\n",
    "                channel2.offset(0 * units.mV)\n",
    "                channel2.termination(0)\n",
    "                #channel3\n",
    "                channel3, = spcm.Channels(card, card_enable=spcm.CHANNEL3) # enable channel 1\n",
    "                channel3.amp(AMPLITUDE * units.mV)\n",
    "                channel3.offset(0 * units.mV)\n",
    "                channel3.termination(0)\n",
    "                #channel4\n",
    "                channel4, = spcm.Channels(card, card_enable=spcm.CHANNEL4) # enable channel 1\n",
    "                channel4.amp(AMPLITUDE * units.mV)\n",
    "                channel4.offset(0 * units.mV)\n",
    "                channel4.termination(0)\n",
    "                #channel5\n",
    "                channel5, = spcm.Channels(card, card_enable=spcm.CHANNEL5) # enable channel 1\n",
    "                channel5.amp(AMPLITUDE * units.mV)\n",
    "                channel5.offset(0 * units.mV)\n",
    "                channel5.termination(0)\n",
    "                #channel6\n",
    "                channel6, = spcm.Channels(card, card_enable=spcm.CHANNEL6) # enable channel 1\n",
    "                channel6.amp(AMPLITUDE * units.mV)\n",
    "                channel6.offset(0 * units.mV)\n",
    "                channel6.termination(0)\n",
    "                #channel7\n",
    "                channel7, = spcm.Channels(card, card_enable=spcm.CHANNEL7) # enable channel 1\n",
    "                channel7.amp(AMPLITUDE * units.mV)\n",
    "                channel7.offset(0 * units.mV)\n",
    "                channel7.termination(0)\n",
    "    \n",
    "                if(EXIT_DAQ_FLAG==True):\n",
    "                    print(\"Data acquisition is terminating...\")\n",
    "                    break\n",
    "                \n",
    "                # Channel triggering\n",
    "                #https://github.com/SpectrumInstrumentation/spcm\n",
    "                #trigger = spcm.Trigger(card)\n",
    "                trigger.or_mask(spcm.SPC_TMASK_EXT0) # set the ext0 hardware input as trigger source\n",
    "                trigger.ext0_mode(spcm.SPC_TM_POS) # wait for a positive edge\n",
    "                trigger.ext0_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                trigger.ext0_coupling(spcm.COUPLING_DC) # set DC coupling\n",
    "\n",
    "                \"\"\"\n",
    "                if(TRIGGER_CHANNEL==0):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT0)\n",
    "                    trigger.ext0_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext0_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                    trigger.ext0_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)                \n",
    "                    #print(\"Trigger channel 0\")\n",
    "                if(TRIGGER_CHANNEL==1):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT1)\n",
    "                    trigger.ext1_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext1_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)\n",
    "                    trigger.ext1_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                    print(\"Trigger channel 1\")\n",
    "                if(TRIGGER_CHANNEL==2):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT2)\n",
    "                    trigger.ext2_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext2_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)\n",
    "                    trigger.ext2_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                    \n",
    "                if(TRIGGER_CHANNEL==3):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT3)\n",
    "                    trigger.ext3_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext3_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)\n",
    "                    trigger.ext3_level0(float(TRIGGER_LEVEL) * units.mV)                \n",
    "                if(TRIGGER_CHANNEL==4):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT4)\n",
    "                    trigger.ext4_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext4_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)\n",
    "                    trigger.ext4_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                    \n",
    "                if(TRIGGER_CHANNEL==5):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT5)\n",
    "                    trigger.ext5_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext5_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)\n",
    "                    trigger.ext5_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                    \n",
    "                if(TRIGGER_CHANNEL==6):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT6)\n",
    "                    trigger.ext6_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext6_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)\n",
    "                    trigger.ext6_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                    \n",
    "                if(TRIGGER_CHANNEL==7):                \n",
    "                    trigger.and_mask(spcm.SPC_TMASK_NONE)\n",
    "                    trigger.or_mask(spcm.SPC_TMASK_EXT7)\n",
    "                    trigger.ext7_mode(spcm.SPC_TM_POS)\n",
    "                    trigger.ext7_coupling(spcm.COUPLING_DC)\n",
    "                    trigger.termination(termination=0)\n",
    "                    trigger.ext7_level0(float(TRIGGER_LEVEL) * units.mV)\n",
    "                \"\"\"\n",
    "                \n",
    "                # define the data buffer\n",
    "                data_transfer = spcm.DataTransfer(card)\n",
    "                data_transfer.duration((PRETRIG_DURATION+POSTTRIG_DURATION)*units.ms, post_trigger_duration=POSTTRIG_DURATION*units.ms)\n",
    "            \n",
    "                if(True):#while(True)\n",
    "    \n",
    "                    if(EXIT_DAQ_FLAG==True):\n",
    "                        print(\"Data acquisition is terminating...\")\n",
    "                        break\n",
    "                    \n",
    "                    # start card and wait until recording is finished\n",
    "                    try:\n",
    "                        card.start(spcm.M2CMD_CARD_ENABLETRIGGER, spcm.M2CMD_CARD_WAITREADY)\n",
    "                    except:\n",
    "                        continue\n",
    "                    #print(\"Finished acquiring...\")\n",
    "                    \n",
    "                    # Start DMA transfer and wait until the data is transferred\n",
    "                    data_transfer.start_buffer_transfer(spcm.M2CMD_DATA_STARTDMA, spcm.M2CMD_DATA_WAITDMA)                                                     \n",
    "                    \n",
    "                    signals[0]=channel0.convert_data(data_transfer.buffer[channel0, :], units.V)\n",
    "                    signals[1]=channel1.convert_data(data_transfer.buffer[channel1, :], units.V)\n",
    "                    signals[2]=channel2.convert_data(data_transfer.buffer[channel2, :], units.V)\n",
    "                    signals[3]=channel3.convert_data(data_transfer.buffer[channel3, :], units.V)\n",
    "                    signals[4]=channel4.convert_data(data_transfer.buffer[channel4, :], units.V)\n",
    "                    signals[5]=channel5.convert_data(data_transfer.buffer[channel5, :], units.V)\n",
    "                    signals[6]=channel6.convert_data(data_transfer.buffer[channel6, :], units.V)\n",
    "                    signals[7]=channel7.convert_data(data_transfer.buffer[channel7, :], units.V)\n",
    "\n",
    "                    #*********************************processing***************************                    \n",
    "                    plate=shlp.SPlate()\n",
    "                    plate.raw_signals=signals\n",
    "                    plate.time=np.arange(0,len(signals[0]))\n",
    "                    plate.get_segments(ref_chan_name=trigger_channel)\n",
    "                    sgn_len = len(plate.sigments_sign)\n",
    "                    all_labels=[]\n",
    "                    all_segm_sign=[]   \n",
    "                    prerpoc_time=[]\n",
    "                    proc_time=[]\n",
    "                    snip_number_processed=0\n",
    "                    for seg_i in range(0,sgn_len):\n",
    "                        #take segment\n",
    "                        segm_signal=plate.sigments_sign[seg_i]\n",
    "                        #print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "                        #print(len(segm_signal))\n",
    "                        if(len(plate.sigments_sign[seg_i])==0):\n",
    "                            continue\n",
    "                        preproc_t_strart=time.time()\n",
    "                        snippets=data_proc.SplitEntireSignalIntoSnippets(signal=segm_signal,\n",
    "                                                                         channs_indx=CHANNELS_TO_USE,\n",
    "                                                                         torch_tensor=False,\n",
    "                                                                         snip_size = snip_size,\n",
    "                                                                         preproc_type = preprocessing\n",
    "                                                                         )\n",
    "                        preproc_t_end=time.time()\n",
    "                        prerpoc_time.append(preproc_t_strart-preproc_t_end)\n",
    "                        \n",
    "                        start_proc=time.time()\n",
    "                        labels=s_model.np_predict(np.asarray(snippets))\n",
    "                        snip_number_processed+=len(labels)\n",
    "                        end_proc=time.time()                        \n",
    "                        proc_time.append(end_proc-start_proc)\n",
    "                        \n",
    "                        all_labels.append(labels) \n",
    "                        all_segm_sign.append(segm_signal)\n",
    "                    #show everything in the chart   \n",
    "                    if(SHOW_PROC_RESULTS==True):\n",
    "                        try:                        \n",
    "                            viz_start_t=time.time()\n",
    "                            shlp.ShowResultsInFigure_AllSegmentsInRow(all_segm_sign,\n",
    "                                                                      all_labels,\n",
    "                                                                      CHANNELS_TO_USE,\n",
    "                                                                      snip_size,\n",
    "                                                                      colorscheme,\n",
    "                                                                      SHOW_PROC_RESULTS_FIG,\n",
    "                                                                      SHOW_PROC_RESULTS_AX,\n",
    "                                                                      None)\n",
    "                            viz_end_t=time.time()                        \n",
    "                        except:\n",
    "                            print(\"Figure is unavailable.\")\n",
    "                            \n",
    "                    #**********************************************************************\n",
    "                    \n",
    "                    if(DATA_PRINT==True):                    \n",
    "                        now = datetime.datetime.now()\n",
    "                        signals_counter+=1\n",
    "                        trig_time_st=int((PRETRIG_DURATION/1000)*SAMPLING_RATE*1000000)\n",
    "                        proc_mean_t=-1                        \n",
    "                        try: \n",
    "                            if(len(proc_time)!=0):proc_mean_t=sum(proc_time) / float(len(proc_time))\n",
    "                        except: pass\n",
    "                        print(\"\")\n",
    "                        print(\"******************************************\")\n",
    "                        print(\"Data received: \"+str(now))\n",
    "                        print(\"Data length/chan.: \"+str(len(signals[0])))\n",
    "                        print(\"Chans.num.: \"+str(len(signals)))\n",
    "                        print(\"Frame num.:\"+str(signals_counter))\n",
    "                        print(\"Trig. chan.: \"+str(TRIGGER_CHANNEL))     \n",
    "                        print(\"Trig. chan. max/min: \"+str(np.max(signals[TRIGGER_CHANNEL]))+\"/\"+str(np.min(signals[TRIGGER_CHANNEL])))     \n",
    "                        print(\"Trig.timestamp: \"+str(trig_time_st/1000)+\" ms\")\n",
    "                        print(\"Trig. val.:\"+str(signals[TRIGGER_CHANNEL][trig_time_st]))\n",
    "                        if(len(prerpoc_time)>0): print(\"Average preproc. time(s): \"+str(float(sum(prerpoc_time) / float(len(prerpoc_time)))))\n",
    "                        if(float(proc_mean_t) >= 0): print(\"Average proc.time(s): \"+str(proc_mean_t))\n",
    "                        print(\"Number of proc.snips.: \"+str(snip_number_processed))\n",
    "                        try: print(\"Vizualization time: \"+str(viz_end_t-viz_start_t))                            \n",
    "                        except: pass\n",
    "                        \n",
    "                        print(\"******************************************\")\n",
    "                        print(\"\")\n",
    "                    \n",
    "                    # Plot the acquired data\n",
    "                    if(SHOW_ORIGIN_SIGNALS==True) and (SHOW_ORIGIN_SIGNALS_FIG is not None) and (SHOW_ORIGIN_SIGNALS_AX is not None):            \n",
    "                        time_data_s = data_transfer.time_data()\n",
    "                        #fig, ax = plt.subplots()                                                \n",
    "                        #print(channel0)\n",
    "                        #print(\"\\tMinimum: {:.3~P}\".format(np.min(unit_data_V)))\n",
    "                        #print(\"\\tMaximum: {:.3~P}\".format(np.max(unit_data_V)))                    \n",
    "                        SHOW_ORIGIN_SIGNALS_AX.clear()\n",
    "                        for ws in range(0,len(CHANNELS_TO_USE)):\n",
    "                            chan_index=CHANNELS_TO_USE[ws]\n",
    "                            SHOW_ORIGIN_SIGNALS_AX.plot(time_data_s, signals[chan_index], label=(\"channel \"+str(chan_index)))\n",
    "                        SHOW_ORIGIN_SIGNALS_AX.yaxis.set_units(units.mV)\n",
    "                        SHOW_ORIGIN_SIGNALS_AX.xaxis.set_units(units.us)\n",
    "                        SHOW_ORIGIN_SIGNALS_AX.axvline(0, color='k', linestyle='--', label='Trigger')\n",
    "                        SHOW_ORIGIN_SIGNALS_AX.legend()\n",
    "                        SHOW_ORIGIN_SIGNALS_FIG.canvas.draw()\n",
    "                        SHOW_ORIGIN_SIGNALS_FIG.canvas.flush_events()\n",
    "                    \n",
    "                    if(EXIT_DAQ_FLAG==True):\n",
    "                        print(\"Data acquisition is terminating...\")\n",
    "                        break\n",
    "\n",
    "                    if(ONLY_SINGLE_SHOT==True):\n",
    "                        break\n",
    "                    \n",
    "        #reproting of the data aquisition exit\n",
    "        now = datetime.datetime.now()\n",
    "        print(\"\")\n",
    "        print(\"******************************************\")\n",
    "        print(\"Data acquisition is terminated on event\")\n",
    "        print(str(now))\n",
    "        print(\"******************************************\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7722f09-1c97-46f7-af56-bdd6b62537a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100%  Opening files (*.csv)\n",
      "Loaded plates num.: 10\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "\n",
      "label assigned to:\n",
      "plate name - 3856.csv\n",
      "segment name - noname_0\n",
      "label - qwe1\n",
      "\n",
      "label assigned to:\n",
      "plate name - 3856.csv\n",
      "segment name - noname_1\n",
      "label - qwe1\n",
      "\n",
      "label assigned to:\n",
      "plate name - 3856.csv\n",
      "segment name - noname_2\n",
      "label - qwe2\n",
      "\n",
      "label assigned to:\n",
      "plate name - 3856.csv\n",
      "segment name - noname_3\n",
      "label - qwe2\n",
      "\n",
      "*********************************************************************\n",
      "Training start\n",
      "User selected channels: [2]\n",
      "\n",
      "Start calssification...\n",
      "Settings...\n",
      "data source - this_plate_all_segments\n",
      "plate name - 3856.csv\n",
      "egm.num - 184\n",
      "chan. name - Plasma R\n",
      "snip. length - 1000\n",
      "test set (% from training) - 20.0\n",
      "unique lab. - ['qwe1', 'qwe2']\n",
      "unique lab. encoding [0, 1]\n",
      "feat.shape - (57, 1000)\n",
      "training with XGBoost...\n",
      "[0, 1]\n",
      "Classifier of type assigned: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Training is complete...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shse\\.conda\\envs\\MyEnv_1\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3675: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    sys.exit(app.exec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a191ad-f1c8-4a3c-9a86-a0ba9b06ae7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbbb63-f718-455e-810a-8c801136cc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d0c2b-cb61-4781-a4f4-d23d5102fe78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635e792d-7fd2-4219-b0c6-fca5d02c48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/paya54/Anomaly_Detect_DAGMM/blob/master/dagmm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2098c19a-41f9-4a51-8a75-db89c6732a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13810945-0333-490e-95dc-9222fadb25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_euclidean_distance(x, x_hat):\n",
    "    x_ = x.unsqueeze(1)\n",
    "    x_hat_ = x_hat.unsqueeze(1)\n",
    "    # d1 shape: [batch_size, 1]\n",
    "    d1 = torch.cdist(x_, x_hat_).squeeze(1)\n",
    "    # d2 shape: [batch_size, 1]\n",
    "    d2 = torch.cdist(x_, torch.zeros(x_.shape)).squeeze(1)\n",
    "    return d1/d2\n",
    "\n",
    "\n",
    "class CompressNet(nn.Module):\n",
    "    def __init__(self, x_dim, hidden1_dim, hidden2_dim, hidden3_dim, zc_dim):\n",
    "        super(CompressNet, self).__init__()\n",
    "\n",
    "        self.encoder_layer1 = nn.Linear(x_dim, hidden1_dim)\n",
    "        self.encoder_layer2 = nn.Linear(hidden1_dim, hidden2_dim)\n",
    "        self.encoder_layer3 = nn.Linear(hidden2_dim, hidden3_dim)\n",
    "        self.encoder_layer4 = nn.Linear(hidden3_dim, zc_dim)\n",
    "\n",
    "        self.decoder_layer1 = nn.Linear(zc_dim, hidden3_dim)\n",
    "        self.decoder_layer2 = nn.Linear(hidden3_dim, hidden2_dim)\n",
    "        self.decoder_layer3 = nn.Linear(hidden2_dim, hidden1_dim)\n",
    "        self.decoder_layer4 = nn.Linear(hidden1_dim, x_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder_layer1(x)\n",
    "        h = self.encoder_layer2(h)\n",
    "        h = self.encoder_layer3(h)\n",
    "        zc = self.encoder_layer4(h)\n",
    "\n",
    "        h = self.decoder_layer1(zc)\n",
    "        h = self.decoder_layer2(h)\n",
    "        h = self.decoder_layer3(h)\n",
    "        x_hat = self.decoder_layer4(h)\n",
    "\n",
    "        # ed shape: [batch_size, 1]\n",
    "        ed = relative_euclidean_distance(x, x_hat)\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        # cosim shape: [batch_size, 1]\n",
    "        cosim = cos(x, x_hat).unsqueeze(1)\n",
    "        # z shape: [batch_size, zc_dim+2]\n",
    "        z = torch.cat((zc, ed, cosim), dim=1)\n",
    "        assert zc.shape[0] == z.shape[0]\n",
    "        assert zc.shape[1] == z.shape[1] - 2\n",
    "\n",
    "        return z, x_hat\n",
    "    \n",
    "    def reconstruct_error(self, x, x_hat):\n",
    "        e = torch.tensor(0.0)\n",
    "        for i in range(x.shape[0]):\n",
    "            e += torch.dist(x[i], x_hat[i])\n",
    "        return e / x.shape[0]\n",
    "\n",
    "class EstimateNet(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, dropout_p, mixture_dim, lam1, lam2):\n",
    "        super(EstimateNet, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.mixture_dim = mixture_dim\n",
    "        self.lam1 = lam1\n",
    "        self.lam2 = lam2\n",
    "\n",
    "        self.layer1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.drop = nn.Dropout(dropout_p)\n",
    "        self.layer2 = nn.Linear(hidden_dim, mixture_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.layer1(z)\n",
    "        h = torch.tanh(h)\n",
    "        h = self.drop(h)\n",
    "        h = self.layer2(h)\n",
    "        # gamma shape: [batch_size, mixture_dim]\n",
    "        gamma = F.softmax(h, dim=1)\n",
    "        return gamma\n",
    "\n",
    "    # return shape: [mixture_dim]\n",
    "    def mixture_prob(self, gamma):\n",
    "        n = gamma.shape[0]\n",
    "        return torch.sum(gamma, dim=0) / n\n",
    "\n",
    "    # return shape: [mixture_dim, z_dim]\n",
    "    def mixture_mean(self, gamma, z):\n",
    "        gamma_t = torch.t(gamma)\n",
    "        miu = torch.mm(gamma_t, z)\n",
    "        miu = miu / torch.sum(gamma_t, dim=1).unsqueeze(1)\n",
    "        return miu\n",
    "\n",
    "    # return shape: [mixture_dim, z_dim, z_dim]\n",
    "    def mixture_covar(self, gamma, z, miu):\n",
    "        cov = torch.zeros((self.mixture_dim, self.z_dim, self.z_dim))\n",
    "        # z_t shape: [z_dim, batch_size]\n",
    "        z_t = torch.t(z)\n",
    "        for k in range(self.mixture_dim):\n",
    "            miu_k = miu[k].unsqueeze(1)\n",
    "            # dm shape: [z_dim, batch_size]\n",
    "            dm = z_t - miu_k\n",
    "            # gamma_k shape: [batch_size, batch_size]\n",
    "            gamma_k = torch.diag(gamma[:, k])\n",
    "            # cov_k shape: [z_dim, z_dim]\n",
    "            cov_k = torch.chain_matmul(dm, gamma_k, torch.t(dm))\n",
    "            cov_k = cov_k / torch.sum(gamma[:, k])\n",
    "            cov[k] = cov_k\n",
    "        return cov\n",
    "    \n",
    "    # m_prob shape: [mixture_dim]\n",
    "    # m_mean shape: [mixture_dim, z_dim]\n",
    "    # m_cov shape: [mixture_dim, z_dim, z_dim]\n",
    "    # zi shape: [z_dim, 1]\n",
    "    def sample_energy(self, m_prob, m_mean, m_cov, zi):\n",
    "        e = torch.tensor(0.0)\n",
    "        cov_eps = torch.eye(m_mean.shape[1]) * (1e-12)\n",
    "        for k in range(self.mixture_dim):\n",
    "            # miu_k shape: [z_dim, 1]\n",
    "            miu_k = m_mean[k].unsqueeze(1)\n",
    "            d_k = zi - miu_k\n",
    "\n",
    "            # solve the singular covariance\n",
    "            inv_cov = torch.inverse(m_cov[k] + cov_eps)\n",
    "            e_k = torch.exp(-0.5 * torch.chain_matmul(torch.t(d_k), inv_cov, d_k))\n",
    "            e_k = e_k / torch.sqrt(torch.abs(torch.det(2 * math.pi * m_cov[k])))\n",
    "            e_k = e_k * m_prob[k]\n",
    "            e += e_k.squeeze()\n",
    "        return - torch.log(e)\n",
    "\n",
    "    def energy(self, gamma, z):\n",
    "        m_prob = self.mixture_prob(gamma)\n",
    "        m_mean = self.mixture_mean(gamma, z)\n",
    "        m_cov = self.mixture_covar(gamma, z, m_mean)\n",
    "\n",
    "        e = torch.tensor(0.0)\n",
    "        for i in range(z.shape[0]):\n",
    "            zi = z[i].unsqueeze(1)\n",
    "            ei = self.sample_energy(m_prob, m_mean, m_cov, zi)\n",
    "            e += ei\n",
    "        \n",
    "        p = torch.tensor(0.0)\n",
    "        for k in range(self.mixture_dim):\n",
    "            cov_k = m_cov[k]\n",
    "            p_k = torch.sum(1 / torch.diagonal(cov_k, 0))\n",
    "            p += p_k\n",
    "        \n",
    "        return (self.lam1 / z.shape[0]) * e + self.lam2 * p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6fc7f3-5cd7-44d5-a3ea-cbad33f19e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal feat. shape: - (23, 1000)\n",
      "Anomaly feat. shape: - (34, 1000)\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "feat_norm,labs_norm,feat_anomaly,labs_anomaly = shlp.SeparateFeat_Norm_Anom(CLASSIF_FEAT,CLASSIF_LABS)\n",
    "print(\"Normal feat. shape: - \"+str(np.shape(np.asarray(feat_norm))))\n",
    "print(\"Anomaly feat. shape: - \"+str(np.shape(np.asarray(feat_anomaly))))\n",
    "print(\"Device: \"+str(device))\n",
    "norm_x = torch.Tensor(np.asarray(feat_norm)).to(device) \n",
    "norm_y = torch.Tensor(np.asarray(labs_norm)).to(device) \n",
    "class HyperParams:\n",
    "    def __init__(self):\n",
    "        self.epoch_num = 5\n",
    "        self.batch_size = 100\n",
    "        self.input_dim = norm_x.shape[1]\n",
    "        self.cn_hidden1_dim = 600\n",
    "        self.cn_hidden2_dim = 300\n",
    "        self.cn_hidden3_dim = 100\n",
    "        self.zc_dim = 1\n",
    "        self.en_hidden_dim = 10\n",
    "        self.mixture_dim = 2\n",
    "        self.dropout_p = 0.5\n",
    "        self.lam1 = 0.1\n",
    "        self.lam2 = 0.005\n",
    "hyper_params = HyperParams()\n",
    "norm_dataset = torch.utils.data.TensorDataset(norm_x,norm_y)\n",
    "norm_dataloader = torch.utils.data.DataLoader(norm_dataset,batch_size=hyper_params.batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a2f2d7-a29b-4271-a21b-f2c8f784ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = CompressNet(\n",
    "        hyper_params.input_dim,\n",
    "        hyper_params.cn_hidden1_dim,\n",
    "        hyper_params.cn_hidden2_dim,\n",
    "        hyper_params.cn_hidden3_dim,\n",
    "        hyper_params.zc_dim\n",
    "    )\n",
    "if torch.cuda.is_available(): compressor.cuda()\n",
    "\n",
    "estimator = EstimateNet(\n",
    "        hyper_params.zc_dim + 2,\n",
    "        hyper_params.en_hidden_dim,\n",
    "        hyper_params.dropout_p,\n",
    "        hyper_params.mixture_dim,\n",
    "        hyper_params.lam1,\n",
    "        hyper_params.lam2\n",
    "    )\n",
    "if torch.cuda.is_available(): estimator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532acc49-44d6-419b-b4a9-78a1abd7f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(False)\n",
    "losses = []\n",
    "loss_plot_interval = 20\n",
    "steps = 0\n",
    "loss_total = 0\n",
    "compressor_opt = torch.optim.Adam(compressor.parameters(), lr=1e-4, amsgrad=True)\n",
    "estimator_opt = torch.optim.Adam(estimator.parameters(), lr=1e-4, amsgrad=True)\n",
    "\n",
    "for i in range(hyper_params.epoch_num):\n",
    "        for x, _ in norm_dataloader:\n",
    "            steps += 1\n",
    "            if(x.is_cuda==True):\n",
    "                print(\"Cuda\")\n",
    "            if(next(compressor.parameters()).is_cuda==True):\n",
    "                print(\"Cuda\")\n",
    "            z, x_hat = compressor(x)\n",
    "            loss = compressor.reconstruct_error(x, x_hat)\n",
    "\n",
    "            gamma = estimator(z)\n",
    "            loss += estimator.energy(gamma, z)\n",
    "            loss_total += loss.detach().item()\n",
    "\n",
    "            compressor_opt.zero_grad()\n",
    "            estimator_opt.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            compressor_opt.step()\n",
    "            estimator_opt.step()\n",
    "\n",
    "            if steps % loss_plot_interval == 0:\n",
    "                print('Epoch: %d  step: %d  loss: %.4f' % (i, steps, loss_total/loss_plot_interval))\n",
    "                losses.append(loss_total / loss_plot_interval)\n",
    "                loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc1aa1-9db3-4265-b82e-41b4274c4862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bb175-292a-46eb-b504-d20cbb0887e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2aba7-6eff-4b61-a363-f2ce08506f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d7926-c0ef-4807-98e6-b24d64201db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a16f76-a6ce-4db2-833a-47d70d0bae34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d4733-1cb6-42a4-9c7d-1f1ccf400a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051212f-9bd2-442e-b3e6-e9710e177ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd062a21-b4fb-412a-98db-be859a9de932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d9897-6535-4a72-a479-738a4ce00990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f423a079-2eab-4e9a-b09f-6dad8d9edd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7553f7f-dfdb-4732-8525-d97ec7f39d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f66aa0-88a3-4e9e-a866-c40814cae880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47c01e-1e5c-49fb-841e-102c83b471b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOENCODER 2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19a112e3-c9e1-4957-ad1c-3bc5759dd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import itertools\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import datetime\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dd0a08a-95ae-4b99-9180-aa8aff8e2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/danieltan07/dagmm\n",
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, volatile=volatile)\n",
    "\n",
    "def mkdir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "class Cholesky(torch.autograd.Function):\n",
    "    def forward(ctx, a):\n",
    "        l = torch.linalg.cholesky(a, upper=False)#torch.potrf(a, False)#https://docs.pytorch.org/docs/stable/generated/torch.cholesky.html\n",
    "        ctx.save_for_backward(l)\n",
    "        return l\n",
    "    def backward(ctx, grad_output):\n",
    "        l, = ctx.saved_variables\n",
    "        linv = l.inverse()\n",
    "        inner = torch.tril(torch.mm(l.t(), grad_output)) * torch.tril(\n",
    "            1.0 - Variable(l.data.new(l.size(1)).fill_(0.5).diag()))\n",
    "        s = torch.mm(linv.t(), torch.mm(inner, linv))\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dacbcd3f-cb78-437a-afbb-2df64fe886c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DaGMM(nn.Module):\n",
    "    \"\"\"Residual Block.\"\"\"\n",
    "    def __init__(self, input_layer=100, n_gmm = 5, latent_dim=3,low_dims=45):\n",
    "        super(DaGMM, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(input_layer,600)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(600,300)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(300,100)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(100,low_dims)]\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(low_dims,100)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(100,300)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(300,600)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(600,input_layer)]\n",
    "\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(latent_dim,15)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Dropout(p=0.5)]        \n",
    "        layers += [nn.Linear(15,n_gmm)]\n",
    "        layers += [nn.Softmax(dim=1)]\n",
    "\n",
    "\n",
    "        self.estimation = nn.Sequential(*layers)\n",
    "\n",
    "        self.register_buffer(\"phi\", torch.zeros(n_gmm))\n",
    "        self.register_buffer(\"mu\", torch.zeros(n_gmm,latent_dim))\n",
    "        self.register_buffer(\"cov\", torch.zeros(n_gmm,latent_dim,latent_dim))\n",
    "\n",
    "    def relative_euclidean_distance(self, a, b):\n",
    "        return (a-b).norm(2, dim=1) / a.norm(2, dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        enc = self.encoder(x)\n",
    "\n",
    "        dec = self.decoder(enc)\n",
    "\n",
    "        rec_cosine = F.cosine_similarity(x, dec, dim=1)\n",
    "        rec_euclidean = self.relative_euclidean_distance(x, dec)\n",
    "\n",
    "        z = torch.cat([enc, rec_euclidean.unsqueeze(-1), rec_cosine.unsqueeze(-1)], dim=1)        \n",
    "        print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "        print(z.shape)\n",
    "        gamma = self.estimation(z)\n",
    "\n",
    "        return enc, dec, z, gamma\n",
    "\n",
    "    def compute_gmm_params(self, z, gamma):\n",
    "        N = gamma.size(0)\n",
    "        # K\n",
    "        sum_gamma = torch.sum(gamma, dim=0)\n",
    "\n",
    "        # K\n",
    "        phi = (sum_gamma / N)\n",
    "\n",
    "        self.phi = phi.data\n",
    "\n",
    " \n",
    "        # K x D\n",
    "        mu = torch.sum(gamma.unsqueeze(-1) * z.unsqueeze(1), dim=0) / sum_gamma.unsqueeze(-1)\n",
    "        self.mu = mu.data\n",
    "        # z = N x D\n",
    "        # mu = K x D\n",
    "        # gamma N x K\n",
    "\n",
    "        # z_mu = N x K x D\n",
    "        z_mu = (z.unsqueeze(1)- mu.unsqueeze(0))\n",
    "\n",
    "        # z_mu_outer = N x K x D x D\n",
    "        z_mu_outer = z_mu.unsqueeze(-1) * z_mu.unsqueeze(-2)\n",
    "\n",
    "        # K x D x D\n",
    "        cov = torch.sum(gamma.unsqueeze(-1).unsqueeze(-1) * z_mu_outer, dim = 0) / sum_gamma.unsqueeze(-1).unsqueeze(-1)\n",
    "        self.cov = cov.data\n",
    "\n",
    "        return phi, mu, cov\n",
    "        \n",
    "    def compute_energy(self, z, phi=None, mu=None, cov=None, size_average=True):\n",
    "        if phi is None:\n",
    "            phi = to_var(self.phi)\n",
    "        if mu is None:\n",
    "            mu = to_var(self.mu)\n",
    "        if cov is None:\n",
    "            cov = to_var(self.cov)\n",
    "\n",
    "        k, D, _ = cov.size()\n",
    "\n",
    "        z_mu = (z.unsqueeze(1)- mu.unsqueeze(0))\n",
    "\n",
    "        cov_inverse = []\n",
    "        det_cov = []\n",
    "        cov_diag = 0\n",
    "        eps = 1e-12\n",
    "        for i in range(k):\n",
    "            # K x D x D\n",
    "            cov_k = cov[i] + to_var(torch.eye(D)*eps)\n",
    "            cov_k=torch.add(cov_k,0.0001)\n",
    "            cov_inverse.append(torch.inverse(cov_k).unsqueeze(0))\n",
    "\n",
    "            #det_cov.append(np.linalg.det(cov_k.data.cpu().numpy()* (2*np.pi)))\n",
    "            det_cov.append((Cholesky.apply(cov_k.cpu() * (2*np.pi)).diag().prod()).unsqueeze(0))\n",
    "            cov_diag = cov_diag + torch.sum(1 / cov_k.diag())\n",
    "\n",
    "        # K x D x D\n",
    "        cov_inverse = torch.cat(cov_inverse, dim=0)\n",
    "        # K\n",
    "        det_cov = torch.cat(det_cov).cuda()\n",
    "        #det_cov = to_var(torch.from_numpy(np.float32(np.array(det_cov))))\n",
    "\n",
    "        # N x K\n",
    "        exp_term_tmp = -0.5 * torch.sum(torch.sum(z_mu.unsqueeze(-1) * cov_inverse.unsqueeze(0), dim=-2) * z_mu, dim=-1)\n",
    "        # for stability (logsumexp)\n",
    "        max_val = torch.max((exp_term_tmp).clamp(min=0), dim=1, keepdim=True)[0]\n",
    "\n",
    "        exp_term = torch.exp(exp_term_tmp - max_val)\n",
    "\n",
    "        # sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (det_cov).unsqueeze(0), dim = 1) + eps)\n",
    "        sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (torch.sqrt(det_cov)).unsqueeze(0), dim = 1) + eps)\n",
    "        # sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (torch.sqrt((2*np.pi)**D * det_cov)).unsqueeze(0), dim = 1) + eps)\n",
    "\n",
    "\n",
    "        if size_average:\n",
    "            sample_energy = torch.mean(sample_energy)\n",
    "\n",
    "        return sample_energy, cov_diag\n",
    "\n",
    "\n",
    "    def loss_function(self, x, x_hat, z, gamma, lambda_energy, lambda_cov_diag):\n",
    "\n",
    "        recon_error = torch.mean((x - x_hat) ** 2)\n",
    "\n",
    "        phi, mu, cov = self.compute_gmm_params(z, gamma)\n",
    "\n",
    "        sample_energy, cov_diag = self.compute_energy(z, phi, mu, cov)\n",
    "\n",
    "        loss = recon_error + lambda_energy * sample_energy + lambda_cov_diag * cov_diag\n",
    "\n",
    "        return loss, sample_energy, recon_error, cov_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "debbdadc-376c-4c7d-8376-a613200fa878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "    DEFAULTS = {}   \n",
    "    def __init__(self, data_loader, config):\n",
    "        # Data loader\n",
    "        self.__dict__.update(Solver.DEFAULTS, **config)\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "        # Build tensorboard if use\n",
    "        self.build_model()\n",
    "        if self.use_tensorboard:\n",
    "            self.build_tensorboard()\n",
    "\n",
    "        # Start with trained model\n",
    "        if self.pretrained_model:\n",
    "            self.load_pretrained_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        #\n",
    "        #print(\"ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ\")\n",
    "        #print(int(self.__dict__.get(\"input_layer\")))\n",
    "        #print(int(self.__dict__.get(\"n_gmm\")))\n",
    "        #print(int(self.__dict__.get(\"latent_dim\")))\n",
    "        # Define model\n",
    "        self.dagmm = DaGMM(input_layer= int(self.__dict__.get(\"input_layer\")), \n",
    "                           n_gmm=int(self.__dict__.get(\"n_gmm\")), \n",
    "                           latent_dim=int(self.__dict__.get(\"latent_dim\")), \n",
    "                           low_dims=int(self.__dict__.get(\"low_dims\")),\n",
    "                          )\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.dagmm.parameters(), lr=self.lr)\n",
    "\n",
    "        # Print networks\n",
    "        self.print_network(self.dagmm, 'DaGMM')\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.dagmm.cuda()\n",
    "\n",
    "    def print_network(self, model, name):\n",
    "        num_params = 0\n",
    "        for p in model.parameters():\n",
    "            num_params += p.numel()\n",
    "        print(name)\n",
    "        print(model)\n",
    "        print(\"The number of parameters: {}\".format(num_params))\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "        self.dagmm.load_state_dict(torch.load(os.path.join(\n",
    "            self.model_save_path, '{}_dagmm.pth'.format(self.pretrained_model))))\n",
    "\n",
    "        print(\"phi\", self.dagmm.phi,\"mu\",self.dagmm.mu, \"cov\",self.dagmm.cov)\n",
    "\n",
    "        print('loaded trained models (step: {})..!'.format(self.pretrained_model))\n",
    "\n",
    "    def build_tensorboard(self):\n",
    "        from logger import Logger\n",
    "        self.logger = Logger(self.log_path)\n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.dagmm.zero_grad()\n",
    "\n",
    "    def to_var(self, x, volatile=False):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "        return Variable(x, volatile=volatile)\n",
    "\n",
    "    def train(self):\n",
    "                \n",
    "        iters_per_epoch = len(self.data_loader)\n",
    "\n",
    "        # Start with trained model if exists\n",
    "        if self.pretrained_model:\n",
    "            start = int(self.pretrained_model.split('_')[0])\n",
    "        else:\n",
    "            start = 0\n",
    "\n",
    "        # Start training\n",
    "        iter_ctr = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        #self.log_step=194//4 #float(self.__dict__.get(\"log_step\"))\n",
    "\n",
    "        self.ap_global_train = np.array([0,0,0])\n",
    "        for e in range(start, self.num_epochs):\n",
    "            for i, (input_data, labels) in enumerate(tqdm(self.data_loader)):\n",
    "                iter_ctr += 1\n",
    "                start = time.time()\n",
    "\n",
    "                input_data = self.to_var(input_data)\n",
    "\n",
    "                total_loss,sample_energy, recon_error, cov_diag = self.dagmm_step(input_data)\n",
    "                # Logging\n",
    "                loss = {}\n",
    "                loss['total_loss'] = total_loss.data.item()\n",
    "                loss['sample_energy'] = sample_energy.item()\n",
    "                loss['recon_error'] = recon_error.item()\n",
    "                loss['cov_diag'] = cov_diag.item()\n",
    "\n",
    "                \"\"\"\n",
    "                # Print out log info\n",
    "                if (i+1) % self.log_step == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    total_time = ((self.num_epochs*iters_per_epoch)-(e*iters_per_epoch+i)) * elapsed/(e*iters_per_epoch+i+1)\n",
    "                    epoch_time = (iters_per_epoch-i)* elapsed/(e*iters_per_epoch+i+1)\n",
    "                    \n",
    "                    epoch_time = str(datetime.timedelta(seconds=epoch_time))\n",
    "                    total_time = str(datetime.timedelta(seconds=total_time))\n",
    "                    elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "\n",
    "                    lr_tmp = []\n",
    "                    for param_group in self.optimizer.param_groups:\n",
    "                        lr_tmp.append(param_group['lr'])\n",
    "                    tmplr = np.squeeze(np.array(lr_tmp))\n",
    "\n",
    "                    log = \"Elapsed {}/{} -- {} , Epoch [{}/{}], Iter [{}/{}], lr {}\".format(\n",
    "                        elapsed,epoch_time,total_time, e+1, self.num_epochs, i+1, iters_per_epoch, tmplr)\n",
    "\n",
    "                    for tag, value in loss.items():\n",
    "                        log += \", {}: {:.4f}\".format(tag, value)\n",
    "\n",
    "                    IPython.display.clear_output()\n",
    "                    print(log)\n",
    "\n",
    "                    if self.use_tensorboard:\n",
    "                        for tag, value in loss.items():\n",
    "                            self.logger.scalar_summary(tag, value, e * iters_per_epoch + i + 1)\n",
    "                    else:\n",
    "                        plt_ctr = 1\n",
    "                        if not hasattr(self,\"loss_logs\"):\n",
    "                            self.loss_logs = {}\n",
    "                            for loss_key in loss:\n",
    "                                self.loss_logs[loss_key] = [loss[loss_key]]\n",
    "                                plt.subplot(2,2,plt_ctr)\n",
    "                                plt.plot(np.array(self.loss_logs[loss_key]), label=loss_key)\n",
    "                                plt.legend()\n",
    "                                plt_ctr += 1\n",
    "                        else:\n",
    "                            for loss_key in loss:\n",
    "                                self.loss_logs[loss_key].append(loss[loss_key])\n",
    "                                plt.subplot(2,2,plt_ctr)\n",
    "                                plt.plot(np.array(self.loss_logs[loss_key]), label=loss_key)\n",
    "                                plt.legend()\n",
    "                                plt_ctr += 1\n",
    "\n",
    "                        plt.show()\n",
    "\n",
    "                    print(\"phi\", self.dagmm.phi,\"mu\",self.dagmm.mu, \"cov\",self.dagmm.cov)\n",
    "                # Save model checkpoints\n",
    "                if (i+1) % self.model_save_step == 0:\n",
    "                    torch.save(self.dagmm.state_dict(),\n",
    "                        os.path.join(self.model_save_path, '{}_{}_dagmm.pth'.format(e+1, i+1)))\n",
    "                \"\"\"\n",
    "    def dagmm_step(self, input_data):\n",
    "        self.dagmm.train()        \n",
    "        enc, dec, z, gamma = self.dagmm(input_data)\n",
    "\n",
    "        total_loss, sample_energy, recon_error, cov_diag = self.dagmm.loss_function(input_data, dec, z, gamma, self.lambda_energy, self.lambda_cov_diag)\n",
    "\n",
    "        self.reset_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(self.dagmm.parameters(), 5)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return total_loss,sample_energy, recon_error, cov_diag\n",
    "\n",
    "    def test(self):\n",
    "        print(\"======================TEST MODE======================\")\n",
    "        self.dagmm.eval()\n",
    "        self.data_loader.dataset.mode=\"train\"\n",
    "\n",
    "        N = 0\n",
    "        mu_sum = 0\n",
    "        cov_sum = 0\n",
    "        gamma_sum = 0\n",
    "\n",
    "        for it, (input_data, labels) in enumerate(self.data_loader):\n",
    "            input_data = self.to_var(input_data)\n",
    "            enc, dec, z, gamma = self.dagmm(input_data)\n",
    "            phi, mu, cov = self.dagmm.compute_gmm_params(z, gamma)\n",
    "            \n",
    "            batch_gamma_sum = torch.sum(gamma, dim=0)\n",
    "            \n",
    "            gamma_sum += batch_gamma_sum\n",
    "            mu_sum += mu * batch_gamma_sum.unsqueeze(-1) # keep sums of the numerator only\n",
    "            cov_sum += cov * batch_gamma_sum.unsqueeze(-1).unsqueeze(-1) # keep sums of the numerator only\n",
    "            \n",
    "            N += input_data.size(0)\n",
    "            \n",
    "        train_phi = gamma_sum / N\n",
    "        train_mu = mu_sum / gamma_sum.unsqueeze(-1)\n",
    "        train_cov = cov_sum / gamma_sum.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        print(\"N:\",N)\n",
    "        print(\"phi :\\n\",train_phi)\n",
    "        print(\"mu :\\n\",train_mu)\n",
    "        print(\"cov :\\n\",train_cov)\n",
    "\n",
    "        train_energy = []\n",
    "        train_labels = []\n",
    "        train_z = []\n",
    "        for it, (input_data, labels) in enumerate(self.data_loader):\n",
    "            input_data = self.to_var(input_data)\n",
    "            enc, dec, z, gamma = self.dagmm(input_data)\n",
    "            sample_energy, cov_diag = self.dagmm.compute_energy(z, phi=train_phi, mu=train_mu, cov=train_cov, size_average=False)\n",
    "            \n",
    "            train_energy.append(sample_energy.data.cpu().numpy())\n",
    "            train_z.append(z.data.cpu().numpy())\n",
    "            train_labels.append(labels.numpy())\n",
    "\n",
    "\n",
    "        train_energy = np.concatenate(train_energy,axis=0)\n",
    "        train_z = np.concatenate(train_z,axis=0)\n",
    "        train_labels = np.concatenate(train_labels,axis=0)\n",
    "\n",
    "\n",
    "        self.data_loader.dataset.mode=\"test\"\n",
    "        test_energy = []\n",
    "        test_labels = []\n",
    "        test_z = []\n",
    "        for it, (input_data, labels) in enumerate(self.data_loader):\n",
    "            input_data = self.to_var(input_data)\n",
    "            enc, dec, z, gamma = self.dagmm(input_data)\n",
    "            sample_energy, cov_diag = self.dagmm.compute_energy(z, size_average=False)\n",
    "            test_energy.append(sample_energy.data.cpu().numpy())\n",
    "            test_z.append(z.data.cpu().numpy())\n",
    "            test_labels.append(labels.numpy())\n",
    "\n",
    "\n",
    "        test_energy = np.concatenate(test_energy,axis=0)\n",
    "        test_z = np.concatenate(test_z,axis=0)\n",
    "        test_labels = np.concatenate(test_labels,axis=0)\n",
    "\n",
    "        combined_energy = np.concatenate([train_energy, test_energy], axis=0)\n",
    "        combined_labels = np.concatenate([train_labels, test_labels], axis=0)\n",
    "\n",
    "        thresh = np.percentile(combined_energy, 100 - 20)\n",
    "        print(\"Threshold :\", thresh)\n",
    "\n",
    "        pred = (test_energy > thresh).astype(int)\n",
    "        gt = test_labels.astype(int)\n",
    "\n",
    "        from sklearn.metrics import precision_recall_fscore_support as prf, accuracy_score\n",
    "\n",
    "        accuracy = accuracy_score(gt,pred)\n",
    "        precision, recall, f_score, support = prf(gt, pred, average='binary')\n",
    "\n",
    "        print(\"Accuracy : {:0.4f}, Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f}\".format(accuracy, precision, recall, f_score))\n",
    "        \n",
    "        return accuracy, precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0587fcf5-2587-4f4c-9bb4-3366d14474f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal feat. shape: - (404, 50)\n",
      "Anomaly feat. shape: - (403, 50)\n"
     ]
    }
   ],
   "source": [
    "feat_norm,labs_norm,feat_anomaly,labs_anomaly = shlp.SeparateFeat_Norm_Anom(CLASSIF_FEAT,CLASSIF_LABS)\n",
    "print(\"Normal feat. shape: - \"+str(np.shape(np.asarray(feat_norm))))\n",
    "print(\"Anomaly feat. shape: - \"+str(np.shape(np.asarray(feat_anomaly))))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "norm_x = torch.Tensor(np.asarray(feat_norm)).to(device) \n",
    "norm_y = torch.Tensor(np.asarray(labs_norm)).to(device) \n",
    "norm_dataset = torch.utils.data.TensorDataset(norm_x,norm_y)\n",
    "norm_dataloader = torch.utils.data.DataLoader(norm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a38a9dc7-fa37-4ed0-b8c9-697307d342b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyperparams():\n",
    "    def __init__(self, config):\n",
    "        self.__dict__.update(**config)\n",
    "defaults = {\n",
    "    'lr' : 1e-4,\n",
    "    'num_epochs' : 200,\n",
    "    'batch_size' : 1024,\n",
    "    'gmm_k' : 4,\n",
    "    'lambda_energy' : 0.1,\n",
    "    'lambda_cov_diag' : 0.005,\n",
    "    'pretrained_model' : None,\n",
    "    'mode' : 'train',\n",
    "    'use_tensorboard' : False,\n",
    "    'data_path' : 'kdd_cup.npz',\n",
    "\n",
    "    \"input_layer\" : norm_x.shape[1], \n",
    "    \"n_gmm\" : 5,\n",
    "    \"low_dims\":32,\n",
    "    \"latent_dim\" : 34,\n",
    "    \n",
    "    \"\"\"\n",
    "    'log_path' : './dagmm/logs',\n",
    "    'model_save_path' : './dagmm/models',\n",
    "    'sample_path' : './dagmm/samples',\n",
    "    'test_sample_path' : './dagmm/test_samples',\n",
    "    'result_path' : './dagmm/results',\n",
    "    \"\"\"\n",
    "\n",
    "    'log_step' : 194//4,\n",
    "    'sample_step' : 194,\n",
    "    'model_save_step' : 194,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d16c2978-633c-405a-8eb9-dd3190356f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaGMM\n",
      "DaGMM(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=600, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=600, out_features=300, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=100, out_features=32, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=100, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=100, out_features=300, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=300, out_features=600, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=600, out_features=50, bias=True)\n",
      "  )\n",
      "  (estimation): Sequential(\n",
      "    (0): Linear(in_features=34, out_features=15, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=15, out_features=5, bias=True)\n",
      "    (4): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "The number of parameters: 489087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/404 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "torch.Size([1, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "_LinAlgError",
     "evalue": "linalg.inv: The diagonal element 2 is zero, the inversion could not be completed because the input matrix is singular.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_LinAlgError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m args=hyperparams(defaults)\n\u001b[32m      3\u001b[39m solver = Solver(norm_dataloader,defaults)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m solver.train()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mSolver.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m start = time.time()\n\u001b[32m     89\u001b[39m input_data = \u001b[38;5;28mself\u001b[39m.to_var(input_data)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m total_loss,sample_energy, recon_error, cov_diag = \u001b[38;5;28mself\u001b[39m.dagmm_step(input_data)\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Logging\u001b[39;00m\n\u001b[32m     93\u001b[39m loss = {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36mSolver.dagmm_step\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.dagmm.train()        \n\u001b[32m    155\u001b[39m enc, dec, z, gamma = \u001b[38;5;28mself\u001b[39m.dagmm(input_data)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m total_loss, sample_energy, recon_error, cov_diag = \u001b[38;5;28mself\u001b[39m.dagmm.loss_function(input_data, dec, z, gamma, \u001b[38;5;28mself\u001b[39m.lambda_energy, \u001b[38;5;28mself\u001b[39m.lambda_cov_diag)\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.reset_grad()\n\u001b[32m    160\u001b[39m total_loss.backward()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 146\u001b[39m, in \u001b[36mDaGMM.loss_function\u001b[39m\u001b[34m(self, x, x_hat, z, gamma, lambda_energy, lambda_cov_diag)\u001b[39m\n\u001b[32m    142\u001b[39m recon_error = torch.mean((x - x_hat) ** \u001b[32m2\u001b[39m)\n\u001b[32m    144\u001b[39m phi, mu, cov = \u001b[38;5;28mself\u001b[39m.compute_gmm_params(z, gamma)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m sample_energy, cov_diag = \u001b[38;5;28mself\u001b[39m.compute_energy(z, phi, mu, cov)\n\u001b[32m    148\u001b[39m loss = recon_error + lambda_energy * sample_energy + lambda_cov_diag * cov_diag\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss, sample_energy, recon_error, cov_diag\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mDaGMM.compute_energy\u001b[39m\u001b[34m(self, z, phi, mu, cov, size_average)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# K x D x D\u001b[39;00m\n\u001b[32m    109\u001b[39m     cov_k = cov[i] + to_var(torch.eye(D)*eps)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     cov_inverse.append((torch.inverse(cov_k+\u001b[32m0.0001\u001b[39m)).unsqueeze(\u001b[32m0\u001b[39m))\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m#det_cov.append(np.linalg.det(cov_k.data.cpu().numpy()* (2*np.pi)))\u001b[39;00m\n\u001b[32m    113\u001b[39m     det_cov.append((Cholesky.apply(cov_k.cpu() * (\u001b[32m2\u001b[39m*np.pi)).diag().prod()).unsqueeze(\u001b[32m0\u001b[39m))\n",
      "\u001b[31m_LinAlgError\u001b[39m: linalg.inv: The diagonal element 2 is zero, the inversion could not be completed because the input matrix is singular."
     ]
    }
   ],
   "source": [
    "torch.use_deterministic_algorithms(False)\n",
    "args=hyperparams(defaults)\n",
    "solver = Solver(norm_dataloader,defaults)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6b419-c9c2-4140-a31d-5e31ff3a7c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58995c-5d7b-47b3-9287-d6781f6ed442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6199a-3a34-45b3-8493-eafa4068b854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d0db2-a96e-4ac6-85ac-d8e6c304437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19667c-a588-444e-ad14-7b2b02ac4962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44204f1c-39ee-4956-b942-e690c450638b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521828d-95f1-4b1e-bb74-4952b194997d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d7ce9-7d78-410a-b608-522c9bea43c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9456985-ab12-448e-90eb-593ffed37675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bb2ef-499e-4662-bb06-950ce23ec685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646c6c0-984c-45de-80e5-bdee50b0d124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36af5b3-5b4d-4cb7-853c-2d0ed3227326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb08e0-811f-4742-b854-0e4483f3a5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af7b41-6ad8-4c62-9ea6-a8b97d63f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d7de7-ebd6-4dec-95c2-0086e0c9e065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd553d1-e416-4461-a912-55a36985f573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d950cfad-4250-4cc0-89c1-1645772e95cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd07c4d-b9e9-4a24-be5b-151fb16e8bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a3f3f-2955-4c7b-8344-e0cc7fb26345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e95332-5f74-4a36-be47-8b7684e3171d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c43fe8-d8c7-4c32-97f1-e3e5078af041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6856dcb-d3f1-4174-88f6-37cd3df3da05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a13d99-4ad1-4126-8393-af9b04a80e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965cfe14-7de1-4e2a-9d42-a985e9f17cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db661d9a-42b5-4f91-93d6-31d09517d319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b90132-1d60-4aea-bc48-87a5779ca59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadff21-929c-4cbf-b14d-8aca37d115bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57585a93-6cf3-4198-842d-8a0d1e540505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223041ca-acd1-4ad4-80b3-ba39823d28b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb0ef2-4c3f-4382-84b5-8a77de3605af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9b957-4f6a-45fb-9bb0-f784c3dc213a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf16917-6395-4ee9-8552-46ce7155a91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96287193-6230-4913-b619-53ef7587a7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04dcb4-ca65-4190-9cb4-8e437041036e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec11e4c-1196-4c63-b3d0-4c910e9c5466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6b2bb-5b5f-4b88-add6-2397376d92f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444f40a-84bc-4562-98ef-943c813faf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949f378-4307-498a-a59f-d28f1a0b5c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab32c8-1ba8-4cb3-bad2-a1db62614ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/spcm/\n",
    "#https://github.com/SpectrumInstrumentation/spcm/blob/master/src/examples/01_acquisition/01_acq_single.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5b566287-f82d-4f5f-9a36-dee55a8f87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished acquiring...\n",
      "Channel 0\n",
      "\tMinimum: 0.000153 V\n",
      "\tMaximum: 4.35 V\n"
     ]
    }
   ],
   "source": [
    "import spcm\n",
    "from spcm import units # spcm uses the pint library for unit handling (units is a UnitRegistry object)\n",
    "card : spcm.Card\n",
    "\n",
    "#prepare the figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# with spcm.Card('/dev/spcm0') as card:                         # if you want to open a specific card\n",
    "# with spcm.Card('TCPIP::192.168.1.10::inst0::INSTR') as card:  # if you want to open a remote card\n",
    "# with spcm.Card(serial_number=12345) as card:                  # if you want to open a card by its serial number\n",
    "with spcm.Card(card_type=spcm.SPCM_TYPE_AI) as card:            # if you want to open the first card of a specific type\n",
    "    # do a simple standard setup\n",
    "    card.card_mode(spcm.SPC_REC_STD_SINGLE)     # single trigger standard mode\n",
    "    card.timeout(5 * units.s)                     # timeout 5 s\n",
    "\n",
    "    trigger = spcm.Trigger(card)\n",
    "    trigger.or_mask(spcm.SPC_TMASK_NONE)       # trigger set to none #software\n",
    "    trigger.and_mask(spcm.SPC_TMASK_NONE)      # no AND mask\n",
    "\n",
    "    clock = spcm.Clock(card)\n",
    "    clock.mode(spcm.SPC_CM_INTPLL)            # clock mode internal PLL\n",
    "    clock.sample_rate(0.5 * units.MHz, return_unit=units.MHz)\n",
    "\n",
    "    # setup the channels\n",
    "    #channel0\n",
    "    channel0, = spcm.Channels(card, card_enable=spcm.CHANNEL0) # enable channel 0\n",
    "    channel0.amp(5000 * units.mV)\n",
    "    channel0.offset(0 * units.mV)\n",
    "    channel0.termination(1)\n",
    "    #channel1\n",
    "    channel1, = spcm.Channels(card, card_enable=spcm.CHANNEL0) # enable channel 0\n",
    "    channel1.amp(5000 * units.mV)\n",
    "    channel1.offset(0 * units.mV)\n",
    "    channel1.termination(1)\n",
    "    \n",
    "    # Channel triggering\n",
    "    trigger.ch_or_mask0(channel0.ch_mask())\n",
    "    trigger.ch_mode(channel0, spcm.SPC_TM_POS)\n",
    "    trigger.ch_level0(channel0, 0 * units.mV, return_unit=units.mV)\n",
    "\n",
    "    # define the data buffer\n",
    "    data_transfer = spcm.DataTransfer(card)\n",
    "    data_transfer.duration(90*units.us, post_trigger_duration=80*units.us)\n",
    "\n",
    "    # start card and wait until recording is finished\n",
    "    card.start(spcm.M2CMD_CARD_ENABLETRIGGER, spcm.M2CMD_CARD_WAITREADY)\n",
    "    print(\"Finished acquiring...\")\n",
    "    \n",
    "    # Start DMA transfer and wait until the data is transferred\n",
    "    data_transfer.start_buffer_transfer(spcm.M2CMD_DATA_STARTDMA, spcm.M2CMD_DATA_WAITDMA)\n",
    "\n",
    "    # Plot the acquired data\n",
    "    time_data_s = data_transfer.time_data()\n",
    "    #fig, ax = plt.subplots()\n",
    "    unit_data_V = channel0.convert_data(data_transfer.buffer[channel0, :], units.V)\n",
    "    print(channel0)\n",
    "    print(\"\\tMinimum: {:.3~P}\".format(np.min(unit_data_V)))\n",
    "    print(\"\\tMaximum: {:.3~P}\".format(np.max(unit_data_V)))\n",
    "    ax.clear()\n",
    "    ax.plot(time_data_s, unit_data_V, label=f\"{channel0}\")\n",
    "    ax.yaxis.set_units(units.mV)\n",
    "    ax.xaxis.set_units(units.us)\n",
    "    ax.axvline(0, color='k', linestyle='--', label='Trigger')\n",
    "    ax.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50659d0-3e14-4e04-ab02-a0c6da36a82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cca55-fa19-4cc0-8709-b10d934d24bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6cddb4-ddb3-4517-9443-442735150264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66aa7c-13ca-4f55-99b2-65e823a604e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469d156-f881-4505-86d0-20fc6eecc28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80558e-b859-4b0f-83f9-8ee1d1ff98f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32b1b7-cfd0-4b1c-9b08-fe5de73fe8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0e2a2-f677-4430-89f9-3e84d50fae91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf28e6-d93a-4734-9895-0802acb6331d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ce12d-4f7b-402f-9b55-bc0ae2ec05b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625402b7-51af-4393-aff8-48f9168d8bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddb833-cabf-47e8-aab3-1bed8d544a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d8725-54c7-443f-a2dd-ab517c7e2b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876f6fe-aabf-4f9e-992c-b0821481fd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524d7844-0488-4b34-add0-72b07b8f3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.gpytorch.ai/en/v1.12/examples/05_Deep_Gaussian_Processes/Deep_Gaussian_Processes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86c4ca1-d3c9-4ce8-83c3-279142196089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean, LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.models import ApproximateGP, GP\n",
    "from gpytorch.mlls import VariationalELBO, AddedLossTerm\n",
    "from gpytorch.likelihoods import GaussianLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df74ade8-682c-47c1-b691-1e18f8494a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3c1d3-9647-4f23-a744-6ac85efc6374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5c525-819a-4049-8c4b-c701fa6ca6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59858699-65ee-4891-bdca-24ad48e23b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3061993-fc95-4b0b-a4fd-420d9fc47b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b772bc-edb6-4022-a6a7-0cb2e2fd7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_norm,labs_norm,feat_anomaly,labs_anomaly=shlp.SeparateFeat_Norm_Anom(CLASSIF_FEAT,CLASSIF_LABS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1376addf-9a04-479d-bf07-3435a80bc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.Tensor(np.asarray(feat_norm)).to(device) \n",
    "y = torch.Tensor(np.asarray(labs_norm)).to(device) \n",
    "dataset = torch.utils.data.TensorDataset(x,y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3f9707-1046-4afe-825a-87f256cf0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDeepGPHiddenLayer(DeepGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, num_inducing=128, mean_type='constant'):\n",
    "        if output_dims is None:\n",
    "            inducing_points = torch.randn(num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([])\n",
    "        else:\n",
    "            inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([output_dims])\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "\n",
    "        super(ToyDeepGPHiddenLayer, self).__init__(variational_strategy, input_dims, output_dims)\n",
    "\n",
    "        if mean_type == 'constant':\n",
    "            self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        else:\n",
    "            self.mean_module = LinearMean(input_dims)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=batch_shape, ard_num_dims=input_dims),\n",
    "            batch_shape=batch_shape, ard_num_dims=None\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def __call__(self, x, *other_inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Overriding __call__ isn't strictly necessary, but it lets us add concatenation based skip connections\n",
    "        easily. For example, hidden_layer2(hidden_layer1_outputs, inputs) will pass the concatenation of the first\n",
    "        hidden layer's outputs and the input data to hidden_layer2.\n",
    "        \"\"\"\n",
    "        if len(other_inputs):\n",
    "            if isinstance(x, gpytorch.distributions.MultitaskMultivariateNormal):\n",
    "                x = x.rsample()\n",
    "\n",
    "            processed_inputs = [\n",
    "                inp.unsqueeze(0).expand(gpytorch.settings.num_likelihood_samples.value(), *inp.shape)\n",
    "                for inp in other_inputs\n",
    "            ]\n",
    "\n",
    "            x = torch.cat([x] + processed_inputs, dim=-1)\n",
    "\n",
    "        return super().__call__(x, are_samples=bool(len(other_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ef8d95b-24ad-4d28-851b-8cfcaab11ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_hidden_dims = 10\n",
    "class DeepGP(DeepGP):\n",
    "    def __init__(self, train_x_shape,num_output_dims=10):\n",
    "        hidden_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=train_x_shape[-1],\n",
    "            output_dims=num_output_dims,#num_hidden_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "\n",
    "        last_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=hidden_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant',\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden_rep1 = self.hidden_layer(inputs)\n",
    "        output = self.last_layer(hidden_rep1)\n",
    "        return output\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = self.likelihood(self(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab13fcec-5c94-4431-92f6-6d42853a2179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from tqdm import tqdm\n",
    "#from tqdm.notebook import tqdm\n",
    "import tqdm\n",
    "from tqdm import notebook\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "\n",
    "\n",
    "def DEEPGP_Train(feat,labels,\n",
    "                 num_epochs=2000,\n",
    "                 num_samples=10,\n",
    "                 lr=0.01,\n",
    "                 output_dim=10\n",
    "                ):\n",
    "    \n",
    "    feat_norm,labs_norm,feat_anomaly,labs_anomaly=shlp.SeparateFeat_Norm_Anom(CLASSIF_FEAT,CLASSIF_LABS)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.Tensor(np.asarray(feat_norm)).to(device) \n",
    "    y = torch.Tensor(np.asarray(labs_norm)).to(device) \n",
    "    dataset = torch.utils.data.TensorDataset(x,y)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "    model = DeepGP(x.shape,num_output_dims=output_dim).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam([{'params': model.parameters()},], lr=lr)#0.01)\n",
    "    mll = DeepApproximateMLL(VariationalELBO(model.likelihood, model, x.shape[-2]))\n",
    "    \n",
    "    epochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "    loss_history=[]\n",
    "    for i in epochs_iter:\n",
    "        # Within each iteration, we will go over each minibatch of data\n",
    "        minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "        for x_batch, y_batch in minibatch_iter:\n",
    "            with gpytorch.settings.num_likelihood_samples(num_samples):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(x_batch)\n",
    "                loss = -mll(output, y_batch)\n",
    "                loss.backward()\n",
    "                loss_history.append(loss.item())\n",
    "                optimizer.step()\n",
    "                minibatch_iter.set_postfix(loss=loss.item())\n",
    "    return model,loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00e42b09-466c-421a-93dc-31e902fbc779",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DeepGP.__init__() missing 1 required positional argument: 'train_x_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m classif=DEEPGP_Train(CLASSIF_FEAT,CLASSIF_LABS)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mDEEPGP_Train\u001b[39m\u001b[34m(feat, labels, num_epochs, num_samples, lr, output_dim)\u001b[39m\n\u001b[32m     21\u001b[39m dataset = torch.utils.data.TensorDataset(x,y)\n\u001b[32m     22\u001b[39m train_loader = torch.utils.data.DataLoader(dataset)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m model = DeepGP(x.shape,num_output_dims=output_dim).to(device)\n\u001b[32m     26\u001b[39m optimizer = torch.optim.Adam([{\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m: model.parameters()},], lr=lr)\u001b[38;5;66;03m#0.01)\u001b[39;00m\n\u001b[32m     27\u001b[39m mll = DeepApproximateMLL(VariationalELBO(model.likelihood, model, x.shape[-\u001b[32m2\u001b[39m]))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mDeepGP.__init__\u001b[39m\u001b[34m(self, train_x_shape, num_output_dims)\u001b[39m\n\u001b[32m      4\u001b[39m hidden_layer = ToyDeepGPHiddenLayer(\n\u001b[32m      5\u001b[39m     input_dims=train_x_shape[-\u001b[32m1\u001b[39m],\n\u001b[32m      6\u001b[39m     output_dims=num_output_dims,\u001b[38;5;66;03m#num_hidden_dims,\u001b[39;00m\n\u001b[32m      7\u001b[39m     mean_type=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m last_layer = ToyDeepGPHiddenLayer(\n\u001b[32m     11\u001b[39m     input_dims=hidden_layer.output_dims,\n\u001b[32m     12\u001b[39m     output_dims=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     13\u001b[39m     mean_type=\u001b[33m'\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.hidden_layer = hidden_layer\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.last_layer = last_layer\n",
      "\u001b[31mTypeError\u001b[39m: DeepGP.__init__() missing 1 required positional argument: 'train_x_shape'"
     ]
    }
   ],
   "source": [
    "#https://docs.gpytorch.ai/en/v1.12/examples/05_Deep_Gaussian_Processes/Deep_Gaussian_Processes.html\n",
    "classif=DEEPGP_Train(CLASSIF_FEAT,CLASSIF_LABS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4239c443-a2ff-4945-8c80-1f112fb96d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd6549-ca51-490c-92ad-57ee080b98c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581393a6-0b73-4927-93c5-9920881ac1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221164ea-0064-4e53-b7f5-850c36a97639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4bf94-8d53-4928-85cd-005462b194aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12cbe42-b64f-43e5-a408-38b6c34b5882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b08389-40eb-45d0-b89d-6fab3eb457a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085de15e-3ee7-49e2-b839-c8e0547bcd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507bf9b-e18e-4d43-94c4-2174da2a57f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea6cd2-aef7-4b0d-87e4-0f2250d8e5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdabbc0-5827-446b-b20a-1863d1d377a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOENCODER 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cf0818-1f49-435e-8a96-28451bc61b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(CLASSIF_LABS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "234fe9da-aae4-49ea-bbe8-52ece8cb2722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size=1000\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 0, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 1, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 2, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 3, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 4, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 5, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 6, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 7, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 8, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 9, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 10, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 11, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 12, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 13, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 14, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 15, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 16, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 17, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 18, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 19, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 20, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 21, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 22, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 23, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 24, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 25, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 26, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 27, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 28, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 29, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 30, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 31, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 32, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 33, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 34, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 35, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 36, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 37, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 38, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 39, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 40, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 41, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 42, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 43, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 44, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 45, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 46, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 47, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 48, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 49, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 50, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 51, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 52, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 53, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 54, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 55, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 56, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 57, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 58, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 59, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 60, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 61, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 62, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 63, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 64, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 65, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 66, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 67, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 68, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 69, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 70, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 71, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 72, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 73, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 74, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 75, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 76, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 77, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 78, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 79, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 80, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 81, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 82, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 83, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 84, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 85, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 86, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 87, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 88, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 89, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 90, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 91, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 92, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 93, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 94, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 95, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 96, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 97, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 98, Loss: -inf\n",
      "1/1: [>...............................] - ETA 0.0s\n",
      "Training DAGMM... Epoch: 99, Loss: -inf\n"
     ]
    }
   ],
   "source": [
    "model,train_phi,train_mu,train_cov,args,loss=shlp.Train_Autoencoder_2(CLASSIF_FEAT,CLASSIF_LABS,\n",
    "                                                                      num_of_epochs=100,\n",
    "                                                                      patience=200,\n",
    "                                                                      lr=1e-5,\n",
    "                                                                      lr_milestones=[50],\n",
    "                                                                      batch_size=10,\n",
    "                                                                      latent_dim=15,\n",
    "                                                                      n_gmm=50,\n",
    "                                                                      lambda_energy=0.0000000001,\n",
    "                                                                      lambda_cov=0.00000000000000000050,                                                                             \n",
    "                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe590943-913a-408b-b821-d59295e73235",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad367a14-43a9-49d9-9784-cdca4ce9077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.Tensor(CLASSIF_FEAT).to(device) \n",
    "y = torch.zeros(x.shape[0]).to(device) \n",
    "dataset = torch.utils.data.TensorDataset(x,y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "energies = shlp.model_run(model,args,dataloader,train_phi,train_mu,train_cov)#model,args,anomaly_dataloader,train_phi,train_mu,train_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e3ce430-1726-4e57-8573-96c66f79b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(energies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86992454-7a6d-4a1b-972d-3182a2a689e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438d044-6e81-4b4e-bd96-5869070c403b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42808b85-0938-423e-8a21-525c0de81c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59590ff-7cea-4e2b-b59a-f1e7fbeef313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38da7e-ffe4-4625-88dc-8fc8b7831abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20a48e-6241-4c29-baee-e264075c8a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5314f-2285-4edd-aeb7-17eb4220f231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7168c4-7584-448e-b01e-0d98888ccf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0401e8-2d0f-4d09-be8d-9ba6c0c91435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6859b-80b7-4178-9466-977039a1058b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f807ac2-54cf-4ca5-9a96-7eeba13a747e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab989ff-10ee-45e1-bc75-1819188954ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6b70d-abac-4351-b550-b497e7a263e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df9764-7e45-43df-8b80-14882794846d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a181aa-9a23-4083-8ef1-8faba89cb7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49b062-7e5f-46ce-8203-5acd8a11e538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413f399-07eb-4f50-ad50-7dbeb2b9b628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7406760-782b-468a-aeb7-05965acf7d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f264895-3637-40a3-ba4d-f6eaef4b1a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e2f89e-3b69-484b-a67f-9cd6f0283293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1aea15-f150-44c8-92c5-ac7cf4c1dafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafdeb1-29ca-4f12-9e34-57e36eed8859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f10bb-d7d8-4d6a-b43c-77fd44314dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba5869-f5d2-49f2-a5c3-02815cdeaa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d6f63-24b4-4c06-abff-94afdfc31ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dfdde7-87f5-4dbe-af60-fd39cb83ee4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dc4db-304a-4267-bc28-74909d9e166f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91c7a3-f306-434a-bd3d-8ff9d9af0575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3db2b0-2d31-44e6-bc50-7a665a212ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028833f-93f4-4139-90d9-37c30667d1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a981a2b-4e74-4a9b-a939-5ace4d0bf085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28df7e-b938-4a58-aa43-83bd50579d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370fddd-c4cb-409c-b86a-8d9525e5cebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436dd17-d65e-46d2-9301-879a4b5185fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee550df4-a179-4cc3-8930-07aa2b995a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b011ed-eacd-401e-9fc9-cbd9415c885b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff455dc-be5c-4e81-b63a-5ca98df2bb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7953fe-392f-496d-965b-08c71006ab79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc86f58-99fd-442d-9f77-e7e77d1389e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e8214-6834-42d7-8b25-a4cbfd479e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6865b46-37a2-4312-900c-dced52eaa338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454a88c-97c8-4b23-abcd-6136008426da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563b41d-7325-4f5f-9823-2eab7d55a4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c90ea-02ac-4993-821c-eb6dee63e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_dims = 200\n",
    "\n",
    "class ToyDeepGPHiddenLayer(DeepGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, num_inducing=128, mean_type='constant'):\n",
    "        if output_dims is None:\n",
    "            inducing_points = torch.randn(num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([])\n",
    "        else:\n",
    "            inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([output_dims])\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "\n",
    "        super(ToyDeepGPHiddenLayer, self).__init__(variational_strategy, input_dims, output_dims)\n",
    "\n",
    "        if mean_type == 'constant':\n",
    "            self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        else:\n",
    "            self.mean_module = LinearMean(input_dims)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=batch_shape, ard_num_dims=input_dims),\n",
    "            batch_shape=batch_shape, ard_num_dims=None\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def __call__(self, x, *other_inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Overriding __call__ isn't strictly necessary, but it lets us add concatenation based skip connections\n",
    "        easily. For example, hidden_layer2(hidden_layer1_outputs, inputs) will pass the concatenation of the first\n",
    "        hidden layer's outputs and the input data to hidden_layer2.\n",
    "        \"\"\"\n",
    "        if len(other_inputs):\n",
    "            if isinstance(x, gpytorch.distributions.MultitaskMultivariateNormal):\n",
    "                x = x.rsample()\n",
    "\n",
    "            processed_inputs = [\n",
    "                inp.unsqueeze(0).expand(gpytorch.settings.num_likelihood_samples.value(), *inp.shape)\n",
    "                for inp in other_inputs\n",
    "            ]\n",
    "\n",
    "            x = torch.cat([x] + processed_inputs, dim=-1)\n",
    "\n",
    "        return super().__call__(x, are_samples=bool(len(other_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f4cc0-8bd5-41bb-bc12-22b04f6cb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGP_(DeepGP):\n",
    "    def __init__(self, X_train_shape):\n",
    "        hidden_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=X_train_shape[-1],\n",
    "            output_dims=num_hidden_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "\n",
    "        last_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=hidden_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant',\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden_rep1 = self.hidden_layer(inputs)\n",
    "        output = self.last_layer(hidden_rep1)\n",
    "        return output\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = self.likelihood(self(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831f6a5-72c5-4eb3-bbce-aa257fd3f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.gpytorch.ai/en/v1.13/examples/05_Deep_Gaussian_Processes/Deep_Gaussian_Processes.html\n",
    "model = DeepGP_(X_train.shape)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "num_epochs = 10\n",
    "num_samples = 3 \n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "], lr=0.01)\n",
    "mll = DeepApproximateMLL(VariationalELBO(model.likelihood, model, X_train.shape[-2]))\n",
    "epochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "for i in epochs_iter:\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        with gpytorch.settings.num_likelihood_samples(num_samples):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            minibatch_iter.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71653c0-77db-42c8-8152-414a6fa64452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(X_train.shape)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab243cb-4d1f-46a0-a9a2-f2cfdfffe51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc47d83-b1fc-479a-87a0-d2cc102b1212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b0716-abc6-4175-b9ae-1c3cf4e97595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2044b-ea24-4546-b8be-89f7f67e53e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c382e-c9f4-483f-975a-34bf42b0c25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a68257-49f1-449e-9029-d2ad41be2877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a2789-05e4-431a-805d-4db8a80c7f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a5337-77d9-4b50-81f7-06a1d82f5b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b952a85-a6d0-4f0a-9ef7-828feea50789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea3852-88a2-4ac1-b73b-84cb5aad35ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ef60f-f91b-4b5d-9eff-5d5610a406fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2d8cc-ccff-4eb1-a722-f1958e31f8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787770b1-56c4-4134-9a00-37d976689b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d827e51-f064-47a9-ae47-79e2a6a0ed14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3514b-c575-4c5b-9f14-29517d964fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_plot_fig_id=str(uuid.uuid1())[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdba2e-527c-4dd4-ab61-bc73e4bc546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLATES_ARRAY[0].sigments_labels[0].append([21000,22000,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be33506-cbef-4cb9-9011-9da81f6c5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowSignalInFigure(fig, plates=[],colors_code=[],indx_plate=0,indx_segment=0,indx_chan=0):\n",
    "    #%matplotlib qt\n",
    "    if(indx_chan!=-1):#this is the case of not all channels are selected     \n",
    "        #if(plt.fignum_exists(fig_id)==False):\n",
    "        #    fig=plt.figure(fig_id)                    \n",
    "        fig.clf()        \n",
    "        plt.plot(plates[indx_plate].sigments_sign[indx_segment][indx_chan])\n",
    "        if(plates[indx_plate].sigments_labels[indx_segment]!=[]):#if labels are assigned then show those                \n",
    "            for k in plates[indx_plate].sigments_labels[indx_segment]:                \n",
    "                start=k[0]\n",
    "                end=k[1]\n",
    "                c_num=k[2]\n",
    "                plt.axvspan(start, end, facecolor=colors_code[c_num], alpha=0.5)       \n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        fig.show()\n",
    "    else:\n",
    "        #if(plt.fignum_exists(fig_id)==False):\n",
    "        #    fig=plt.figure(fig_id)        \n",
    "        fig.clf()\n",
    "        for kp in range(0,len(plates[indx_plate].chans_names)):                    \n",
    "           plt.plot(plates[indx_plate].sigments_sign[indx_segment][kp])\n",
    "        if(plates[indx_plate].sigments_labels[indx_segment]!=[]):#if labels are assigned then show those\n",
    "            print(len(plates[indx_plate].sigments_labels[indx_segment]))            \n",
    "            for k in plates[indx_plate].sigments_labels[indx_segment]:                \n",
    "                start=k[0]\n",
    "                end=k[1]\n",
    "                c_num=k[2]\n",
    "                plt.axvspan(start, end, facecolor=colors_code[c_num], alpha=0.5)\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        fig.show()        \n",
    "\n",
    "colors=dc.get_colors(500)\n",
    "if(plt.fignum_exists(classif_plot_fig_id)==False) :            \n",
    "            %matplotlib qt\n",
    "            classif_fig=plt.figure(classif_plot_fig_id)    \n",
    "ShowSignalInFigure(classif_fig,plates=PLATES_ARRAY,colors_code=colors,indx_plate=0,indx_segment=0,indx_chan=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa61f9-c6d8-4a1d-9566-49f0d363c395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06592e99-df61-4d68-b94f-5f16133a0734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80b254-420c-48b2-8f56-7b76b260f2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f9480-3484-4ca0-90cc-b4642eb2ab21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c339fd-7ba6-405f-9dcd-4541c75ebb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05bfe8-3e6d-4622-a69b-6f6befce01b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a15dc3-38fe-4ffe-87b0-e624b364d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels=[]\n",
    "patterns_length=[]\n",
    "indx_plate=0\n",
    "indx_segment=0\n",
    "test_size=0.2\n",
    "\n",
    "for hj in range(0,len(PLATES_ARRAY[indx_plate].sigments_labels[indx_segment])):\n",
    "                    label=PLATES_ARRAY[indx_plate].sigments_labels[indx_segment][hj][2]\n",
    "                    first_el=PLATES_ARRAY[indx_plate].sigments_labels[indx_segment][hj][0]\n",
    "                    last_el=PLATES_ARRAY[indx_plate].sigments_labels[indx_segment][hj][1]\n",
    "                    length=last_el-first_el\n",
    "                    if(label in unique_labels):\n",
    "                        indx=unique_labels.index(label)\n",
    "                        patterns_length[indx]=patterns_length[indx]+length\n",
    "                    else:\n",
    "                        patterns_length.append(length)\n",
    "                        unique_labels.append(label)\n",
    "\n",
    "#chan_name=\"OE_Vis\"\n",
    "feat,labs = shlp.SplitIntoSnips(plates=PLATES_ARRAY,plate_name=\"data_2025-02-06_14-47-50_0.bin\",chan_name=\"OE_Vis\",segment_name=\"noname_0\") \n",
    "X_train, X_test, y_train, y_test = train_test_split(feat, labs, test_size=test_size)\n",
    "\n",
    "if(True):\n",
    "            unique_labels=shlp.GetUniqueElements_List(list(labs))#list(set(labs))\n",
    "            #now adjsut the labels -  the reason is that xgbboost wants the labels start from 0, i.e. 0,1,2....\n",
    "            xgb_unique_labs=[]\n",
    "            for l in range(0,len(unique_labels)):\n",
    "                xgb_unique_labs.append(l)\n",
    "            xgb_lab_train=y_train.copy()\n",
    "            xgb_lab_test=y_test.copy()\n",
    "            for i in range(0,len(xgb_lab_train)):\n",
    "                indx=unique_labels.index(xgb_lab_train[i])\n",
    "                xgb_lab_train[i]=int(xgb_unique_labs[indx])\n",
    "            for i in range(0,len(xgb_lab_test)):\n",
    "                indx1=unique_labels.index(xgb_lab_test[i])\n",
    "                xgb_lab_test[i]=int(xgb_unique_labs[indx1])\n",
    "            #print(\"xgb_unique_labs:\"+str(xgb_unique_labs))            \n",
    "            #print(\"unique_labels:\"+str(unique_labels))     \n",
    "                        \n",
    "            bst = XGBClassifier(n_estimators=200, max_depth=8, learning_rate=1, objective='binary:logistic')\n",
    "            bst.fit(X_train, xgb_lab_train)\n",
    "            preds = bst.predict(X_test)\n",
    "            #show in figure  \n",
    "            xgb_labs_back=preds.copy()\n",
    "            for i in range(0,len(xgb_lab_test)):\n",
    "                indx1=xgb_unique_labs.index(xgb_labs_back[i])\n",
    "                xgb_labs_back[i]=int(unique_labels[indx1])\n",
    "            \n",
    "            cm = confusion_matrix(y_test, xgb_labs_back)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=bst.classes_)\n",
    "            disp.plot(cmap=plt.cm.Blues)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4bfaa-a837-4091-8049-83b4856fa97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62895672-2cc9-486a-b0fa-c284130cd654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a00a2-9c7e-407d-8dc0-1e0fdc5bf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(PLATES_ARRAY[0].sigments_sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f934ed-1b7b-4944-8603-8679a5fa9139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034615c9-eddb-4c44-bd5a-e36e7da5c59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0316dd-5e18-4671-8d54-540e1d824d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9568c-f141-4d0b-8aea-f9cf4271ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindPlateInArray(plates = [],plate_name=\"\",chan_name=\"\",segm_name=\"\"):       \n",
    "            \n",
    "            if(len(plates) == 0):\n",
    "                print(\"Plates list is empty\")                \n",
    "                return -1,-1,-1\n",
    "            \n",
    "            #find plate in list            \n",
    "            indx_plate=-1\n",
    "            for k in range(0,len(plates)):\n",
    "                if(plates[k].name==plate_name):\n",
    "                    indx_plate=k\n",
    "                    break            \n",
    "            #find channel in list\n",
    "            indx_chan=-1\n",
    "            if(chan_name!=\"all\"):\n",
    "                for k in range(0,len(plates[indx_plate].chans_names)):\n",
    "                    if(plates[indx_plate].chans_names[k]==chan_name):\n",
    "                        indx_chan=k\n",
    "                        break            \n",
    "            #find the segment\n",
    "            indx_segment=-1\n",
    "            for k in range(0,len(plates[indx_plate].segments_names)):\n",
    "                    if(plates[indx_plate].segments_names[k]==segm_name):\n",
    "                        indx_segment=k\n",
    "                        break                        \n",
    "            return indx_plate, indx_chan, indx_segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750069c-7665-4146-8e00-1c84927873e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx1,indx2,imdx3=FindPlateInArray(plates = PLATES_ARRAY.copy(),plate_name=\"data_2025-02-06_14-47-50_0.bin\",chan_name=\"OE_Vis\",segm_name=\"noname_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c7139-2156-46af-9962-539e7f75d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indx1,indx2,imdx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1d44c-8f2a-4964-a8e9-be4b950ab88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9e8cf-d9f2-4d6e-99b8-25ea64fae01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d066c-c1ca-4345-a2e9-45dcd2e4413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jjk=str(uuid.uuid1())[:5]\n",
    "print(jjk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9c7cd-9310-48fd-8503-9e4d213b20bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb1d9d1-9743-47d2-9acb-32c5d7302197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d75670-d906-4d08-b572-edad0ab8b38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaab4fb-7f96-41cc-ba27-aca51540f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"C:\\\\SERGEY\\\\ANDRITZ_DATA\\\\E005_BPP\"\n",
    "SEGMENTATION_REF_CHAN_NAME=\"Trigger\"\n",
    "SEGMENTATION_THRESHOLD=\"automatic\"\n",
    "SEGMENTATION_SEGMENTS_NAMES_LIST=[]\n",
    "\n",
    "plates=shlp.OpenDataFromFolder(PATH=PATH,\n",
    "                               SEGMENTATION_REF_CHAN_NAME=SEGMENTATION_REF_CHAN_NAME,\n",
    "                               SEGMENTATION_THRESHOLD=SEGMENTATION_REF_CHAN_NAME,\n",
    "                               SEGMENTATION_SEGMENTS_NAMES_LIST=SEGMENTATION_SEGMENTS_NAMES_LIST\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e97526-61c0-4397-9900-11aa207cc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plates[0].plate_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071c247-e504-4794-9809-865c67a7c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#iteractive figure in python - https://stackoverflow.com/questions/51922480/javascript-error-ipython-is-not-defined-in-jupyterlab\n",
    "#install - i) pip install ipympl and ii) pip install nodejs-bin\n",
    "#%matplotlib widget\n",
    "\n",
    "%matplotlib qt\n",
    "fig=plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(plates[0].time, plates[0].raw_signals[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7079f23-34bf-4907-9020-63de735ffa54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a9f2c-a41d-4995-a8db-d93dbd8e3c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b556c-a642-484c-bd49-c01cc22736f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253c736-cde0-4ee8-b5f8-eb43c683dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d4bf2-ff1a-443a-9c2e-5582e5b4ee81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98db74-63fc-469d-a715-fbab81ccd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "p = figure(title=\"Simple line example\", x_axis_label='Time', y_axis_label='Ampl., mV')\n",
    "p.line(plates[0].time, plates[0].raw_signals[7], legend_label=\"\", line_width=2)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ee989-3f1a-40bc-9482-6d013ba2aa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ad12c-c025-4d54-8171-4923278bfb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc485618-7c88-40b8-bd50-4cc97d249e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7048d7-2fc2-4f56-95ef-f1d0c8098d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0a4ca-8dd2-4604-ad88-f0283e218955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a17c8-a492-460e-b14c-48bd61d03177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8faef60-5084-4dc0-8ad9-f8abc5ae3e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b65f8-86e6-4861-8c38-a57812e341d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "interactive(False)\n",
    "plt.plot(plates[0].time, plates[0].raw_signals[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01770f8e-15c3-4226-a35c-a5518233e65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
