{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4513c5c7-625f-48c0-9530-11512642b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/jan-xu/autoencoders\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from barbar import Bar\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656999d5-6bb7-4d5b-8b82-5733bd6ce488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnorm_dataset = torch.utils.data.TensorDataset(torch.tensor(norm,dtype=torch.float32).to(device),torch.tensor(norm_l,dtype=torch.float32).to(device))\\ntrain_loader = torch.utils.data.DataLoader(norm_dataset)\\nnon_norm_dataset = torch.utils.data.TensorDataset(torch.tensor(non_norm,dtype=torch.float32).to(device),torch.tensor(non_norm_l,dtype=torch.float32).to(device))\\ntest_loader = torch.utils.data.DataLoader(non_norm_dataset)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "\n",
    "norm=np.random.random((400,8))\n",
    "norm_l=np.zeros((np.shape(norm)[0]))\n",
    "non_norm=np.random.random((400,8))\n",
    "non_norm_l=np.ones((np.shape(non_norm)[0]))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\"\"\"\n",
    "norm_dataset = torch.utils.data.TensorDataset(torch.tensor(norm,dtype=torch.float32).to(device),torch.tensor(norm_l,dtype=torch.float32).to(device))\n",
    "train_loader = torch.utils.data.DataLoader(norm_dataset)\n",
    "non_norm_dataset = torch.utils.data.TensorDataset(torch.tensor(non_norm,dtype=torch.float32).to(device),torch.tensor(non_norm_l,dtype=torch.float32).to(device))\n",
    "test_loader = torch.utils.data.DataLoader(non_norm_dataset)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c732999d-f6ff-4a66-9182-47049ec8a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Splits `dataset` into a training set and a validation set, by the given ratio `val_ratio`.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_size = int((1 - val_ratio) * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "    return train_set, val_set\n",
    "\n",
    "def to_img(x):\n",
    "    \"\"\"\n",
    "    Denormalises Tensor `x` (normalised from -1 to 1) to image format (from 0 to 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1299f54b-9f53-4d46-bd53-2f70c99e0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A two-convolutional layer residual block.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, c_in, c_out, k, s=1, p=1, mode='encode'):\n",
    "        assert mode in ['encode', 'decode'], \"Mode must be either 'encode' or 'decode'.\"\n",
    "        super(ResBlock, self).__init__()\n",
    "        if mode == 'encode':\n",
    "            self.conv1 = nn.Conv1d(c_in, c_out, k, s, p)\n",
    "            self.conv2 = nn.Conv1d(c_out, c_out, 3, 1, 1)\n",
    "        elif mode == 'decode':\n",
    "            self.conv1 = nn.ConvTranspose1d(c_in, c_out, k, s, p)\n",
    "            self.conv2 = nn.ConvTranspose1d(c_out, c_out, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.BN = nn.BatchNorm1d(c_out)\n",
    "        self.resize = s > 1 or (s == 1 and p == 0) or c_out != c_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv1 = self.BN(self.conv1(x))\n",
    "        relu = self.relu(conv1)\n",
    "        conv2 = self.BN(self.conv2(relu))\n",
    "        if self.resize:\n",
    "            x = self.BN(self.conv1(x))\n",
    "        return self.relu(x + conv2)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder class, mainly consisting of three residual blocks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.init_conv = nn.Conv1d(1, 16, 3, 1, 1) # 16 32 32\n",
    "        self.BN = nn.BatchNorm1d(16)\n",
    "        self.rb1 = ResBlock(16, 16, 3, 2, 1, 'encode') # 16 16 16\n",
    "        self.rb2 = ResBlock(16, 32, 3, 1, 1, 'encode') # 32 16 16\n",
    "        self.rb3 = ResBlock(32, 32, 3, 2, 1, 'encode') # 32 8 8\n",
    "        self.rb4 = ResBlock(32, 48, 3, 1, 1, 'encode') # 48 8 8\n",
    "        self.rb5 = ResBlock(48, 48, 3, 2, 1, 'encode') # 48 4 4\n",
    "        self.rb6 = ResBlock(48, 64, 3, 2, 1, 'encode') # 64 2 2\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        init_conv = self.relu(self.BN(self.init_conv(inputs)))\n",
    "        rb1 = self.rb1(init_conv)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        rb3 = self.rb3(rb2)\n",
    "        rb4 = self.rb4(rb3)\n",
    "        rb5 = self.rb5(rb4)\n",
    "        rb6 = self.rb6(rb5)\n",
    "        return rb6\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder class, mainly consisting of two residual blocks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.rb1 = ResBlock(64, 48, 2, 2, 0, 'decode') # 48 4 4\n",
    "        self.rb2 = ResBlock(48, 48, 2, 2, 0, 'decode') # 48 8 8\n",
    "        self.rb3 = ResBlock(48, 32, 3, 1, 1, 'decode') # 32 8 8\n",
    "        self.rb4 = ResBlock(32, 32, 2, 2, 0, 'decode') # 32 16 16\n",
    "        self.rb5 = ResBlock(32, 16, 3, 1, 1, 'decode') # 16 16 16\n",
    "        self.rb6 = ResBlock(16, 16, 2, 2, 0, 'decode') # 16 32 32\n",
    "        self.out_conv = nn.ConvTranspose1d(16, 1, 3, 1, 1) # 3 32 32\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        rb1 = self.rb1(inputs)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        rb3 = self.rb3(rb2)\n",
    "        rb4 = self.rb4(rb3)\n",
    "        rb5 = self.rb5(rb4)\n",
    "        rb6 = self.rb6(rb5)\n",
    "        out_conv = self.out_conv(rb6)\n",
    "        output = self.tanh(out_conv)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729b60cb-5d6f-4975-8d56-8ebbdef159cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder class, combines encoder and decoder model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        num_p = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        return num_p\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5de3161-8e82-4376-8430-acf226b0eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUniqueElements_List(inputList):\n",
    "    list_out=[]\n",
    "    for k in range(0,len(inputList)):\n",
    "        if(inputList[k] not in list_out):\n",
    "            list_out.append(inputList[k])\n",
    "    return list_out\n",
    "        \n",
    "def SeparateFeat_Norm_Anom(CLASSIF_FEAT,CLASSIF_LABS):\n",
    "    unique_labels=GetUniqueElements_List(CLASSIF_LABS)\n",
    "    feat_norm=[]\n",
    "    labs_norm=[]\n",
    "    feat_anomaly=[]\n",
    "    labs_anomaly=[]\n",
    "    label_0=CLASSIF_LABS[0]\n",
    "    for k in range(0,len(CLASSIF_LABS)):\n",
    "        if(CLASSIF_LABS[k]==label_0):\n",
    "            feat_norm.append(np.asarray(CLASSIF_FEAT[k][:]))\n",
    "            labs_norm.append(0)\n",
    "        else:\n",
    "            feat_anomaly.append(np.asarray(CLASSIF_FEAT[k][:]))\n",
    "            labs_anomaly.append(1)\n",
    "    return feat_norm,labs_norm,feat_anomaly,labs_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4508650f-f685-4822-a5f8-13de189e5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_f=np.random.random((400,512))\n",
    "norm_l=np.zeros((np.shape(norm)[0]))\n",
    "non_norm_f=np.random.random((400,512))\n",
    "non_norm_l=np.ones((np.shape(non_norm)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d276e2d-7a2d-4dfb-b1ed-928e46eaf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_ResNetAE(feat,labels,\n",
    "                   init_lr=0.00005,\n",
    "                   batch_size=30,\n",
    "                   weight_decay=0.01,\n",
    "                   num_epochs = 100,\n",
    "                   vizualize=True \n",
    "                  ):\n",
    "\n",
    "    norm_f,norm_l,non_norm_f,non_norm_l = SeparateFeat_Norm_Anom(feat,labels)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "    norm=torch.tensor(norm_f,dtype=torch.float32).to(device)\n",
    "    non_norm=torch.tensor(non_norm_f,dtype=torch.float32).to(device)\n",
    "    \n",
    "    if(len(norm.shape) <= 2):\n",
    "        norm=norm[:,None,:]\n",
    "        print(\"Train features are adjsuted to shape: \"+str(norm.shape))\n",
    "    \n",
    "    if(len(non_norm.shape) <= 2) and (non_norm.shape[0]!=0):\n",
    "        non_norm=non_norm[:,None,:]\n",
    "        print(\"Test features are adjsuted to shape: \"+str(non_norm.shape))\n",
    "        \n",
    "    norm_dataset = torch.utils.data.TensorDataset(norm,torch.tensor(norm_l,dtype=torch.float32).to(device))\n",
    "    train_loader = torch.utils.data.DataLoader(norm_dataset,batch_size=batch_size)\n",
    "    non_norm_dataset = torch.utils.data.TensorDataset(non_norm,torch.tensor(non_norm_l,dtype=torch.float32).to(device))\n",
    "    test_loader = torch.utils.data.DataLoader(non_norm_dataset,batch_size=batch_size)\n",
    "    \n",
    "    # Instantiate a network model\n",
    "    ae = Autoencoder().to(device)\n",
    "    # Define optimizer\n",
    "    optimizer = optim.SGD(ae.parameters(), lr=init_lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 60, 0.1)\n",
    "    \n",
    "    loss_hist=[]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "      epoch_loss = 0\n",
    "      # Train the model\n",
    "      #with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:        \n",
    "      for data, _ in Bar(train_loader): #for i, batch in enumerate(train_loader):\n",
    "                images = data.to(device)            \n",
    "                # Zero all gradients\n",
    "                optimizer.zero_grad()            \n",
    "                # Calculating the loss\n",
    "                preds = ae(images)\n",
    "                loss = F.mse_loss(preds, images)            \n",
    "                \"\"\"\n",
    "                if data % 10 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        val_images, _ = next(iter(train_loader))\n",
    "                        val_preds = ae(val_images)\n",
    "                        val_loss = F.mse_loss(val_preds, val_images)\n",
    "                        m.track_loss(val_loss, val_images.size(0), mode='val')\n",
    "                    #print('Epoch {0}, iteration {1}: train loss {2}, val loss {3}'.format(epoch+1,i*hparams.batch_size,round(loss.item(), 6),round(val_loss.item(), 6)))\n",
    "                \"\"\"\n",
    "                epoch_loss += loss.item()\n",
    "                # Backpropagate\n",
    "                loss.backward()\n",
    "                # Update the weights\n",
    "                optimizer.step()            \n",
    "                #m.track_loss(loss, images.size(0), mode='train')        \n",
    "      loss_hist.append(epoch_loss / len(train_loader))\n",
    "      print('Training ResNet AutoEncoder... Epoch: {}, Loss: {:.3f}'.format(epoch, epoch_loss))  \n",
    "    \n",
    "    if(vizualize==True):\n",
    "      plt.plot(loss_hist)          \n",
    "    return ae,loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "317b4d75-3f40-4833-bcba-66c30dc357f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features are adjsuted to shape: torch.Size([400, 1, 512])\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 0, Loss: 7.783\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 1, Loss: 3.064\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 2, Loss: 2.647\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 3, Loss: 2.477\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 4, Loss: 2.380\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 5, Loss: 2.322\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 6, Loss: 2.286\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 7, Loss: 2.268\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 8, Loss: 2.255\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 9, Loss: 2.245\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 10, Loss: 2.234\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 11, Loss: 2.220\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 12, Loss: 2.196\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 13, Loss: 2.153\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 14, Loss: 2.084\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 15, Loss: 1.995\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 16, Loss: 1.899\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 17, Loss: 1.799\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 18, Loss: 1.715\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 19, Loss: 1.633\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 20, Loss: 1.511\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 21, Loss: 1.418\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 22, Loss: 1.370\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 23, Loss: 1.345\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 24, Loss: 1.323\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 25, Loss: 1.305\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 26, Loss: 1.280\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 27, Loss: 1.236\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 28, Loss: 1.165\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 29, Loss: 1.099\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 30, Loss: 1.007\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 31, Loss: 0.919\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 32, Loss: 0.853\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 33, Loss: 0.819\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 34, Loss: 0.779\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 35, Loss: 0.724\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 36, Loss: 0.690\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 37, Loss: 0.674\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 38, Loss: 0.680\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 39, Loss: 0.677\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 40, Loss: 0.651\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 41, Loss: 0.650\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 42, Loss: 0.638\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 43, Loss: 0.642\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 44, Loss: 0.639\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 45, Loss: 0.670\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 46, Loss: 0.684\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 47, Loss: 0.621\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 48, Loss: 0.650\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 49, Loss: 0.654\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 50, Loss: 0.630\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 51, Loss: 0.628\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 52, Loss: 0.616\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 53, Loss: 0.648\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 54, Loss: 0.644\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 55, Loss: 0.640\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 56, Loss: 0.627\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 57, Loss: 0.657\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 58, Loss: 0.638\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 59, Loss: 0.665\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 60, Loss: 0.651\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 61, Loss: 0.628\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 62, Loss: 0.633\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 63, Loss: 0.634\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 64, Loss: 0.650\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 65, Loss: 0.653\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 66, Loss: 0.637\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 67, Loss: 0.635\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 68, Loss: 0.619\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 69, Loss: 0.687\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 70, Loss: 0.637\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 71, Loss: 0.664\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 72, Loss: 0.660\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 73, Loss: 0.648\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 74, Loss: 0.673\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 75, Loss: 0.651\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 76, Loss: 0.655\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 77, Loss: 0.632\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 78, Loss: 0.629\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 79, Loss: 0.666\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 80, Loss: 0.623\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 81, Loss: 0.653\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 82, Loss: 0.614\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 83, Loss: 0.643\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 84, Loss: 0.630\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 85, Loss: 0.622\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 86, Loss: 0.649\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 87, Loss: 0.648\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 88, Loss: 0.625\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 89, Loss: 0.726\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 90, Loss: 0.654\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 91, Loss: 0.628\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 92, Loss: 0.646\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 93, Loss: 0.616\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 94, Loss: 0.642\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 95, Loss: 0.621\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 96, Loss: 0.686\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 97, Loss: 0.632\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 98, Loss: 0.621\n",
      "400/400: [==============================>.] - ETA 0.0s\n",
      "Training ResNet AutoEncoder... Epoch: 99, Loss: 0.641\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGgCAYAAACJ7TzXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOO5JREFUeJzt3Ql8VPW5//EnyWQhQBIgkAVCwibIjiwxCKVVKlhapaIFagtSL966VS6tC1ZAr1pwqX9qRbiXXirWBbB1K1WqIljRyI7sCBgIBLJCMpCQdeb/en5hpoksmRmSOZPk8369Dpnl5OTkZJjznee3nCCn0+kUAACAABZs9Q4AAADUhcACAAACHoEFAAAEPAILAAAIeAQWAAAQ8AgsAAAg4BFYAABAwCOwAACAgEdgAQAAAY/AAgAAmmZgWbhwoaSkpEhERISkpqbKxo0bL7ruW2+9JUOGDJGYmBhp2bKlDBw4UP7yl7/UWkevDjBnzhxJSEiQFi1ayOjRo+XAgQO+7BoAAGiCgry9ltCKFStkypQpsnjxYhNWFixYIG+++abs379fOnTocN7669atk1OnTkmvXr0kLCxMVq1aJb/+9a/lH//4h4wZM8as8/TTT8u8efNk2bJl0qVLF5k9e7bs3LlT9uzZY0JRXRwOhxw/flxat24tQUFB3vw6AADAIhpBTp8+LYmJiRIcXEcNxemlYcOGOe+55x73/aqqKmdiYqJz3rx5Hm9j0KBBzkcffdTcdjgczvj4eOezzz7rfr6wsNAZHh7ufOONNzza3tGjRzV0sbCwsLCwsEjjW/Q8XhebN0movLxctmzZIrNmzXI/polIm3DS09M9SlKffPKJqcZoVUVlZGRIdna22YZLdHS0qd7oNidNmnTedsrKysxSc7vq6NGjEhUV5c2vBAAALGK32yUpKcm0kNTFq8CSn58vVVVVEhcXV+txvb9v376Lfl9RUZF07NjRhIyQkBB56aWX5Pvf/755TsOKaxvf3qbruW/T5qPHH3/8vMc1rBBYAABoXDzpzuGXUUKanLZv3y6bNm2Sp556SmbOnGn6tvhKKzwaglyLVlYAAEDT5VWFJTY21lRIcnJyaj2u9+Pj4y/6fdps1L17d3NbRwnt3bvXVEm++93vur9Pt6GjhGpuU9e9kPDwcLMAAIDmwasKi47yGTx4sKxZs6bWCB29n5aW5vF29HtcfVB0VJCGlprb1DatDRs2eLVNAADQdHlVYVHanDN16lQzt8qwYcPMsObi4mKZNm2aeV6HPGt/Fa2gKP2q63br1s2ElPfff9/Mw7Jo0SJ3u9WMGTPkySeflB49eriHNesQp/Hjx9f37wsAAJpDYJk4caLk5eWZid60U6w226xevdrdaTYzM7PWWGoNM3fffbccO3bMTAqn87G8+uqrZjsuDz74oFnvzjvvlMLCQhkxYoTZpidzsAAAgKbP64njApE2IelQaO2AyyghAACa3vmbawkBAICAR2ABAAABj8ACAAACHoEFAAAEPAILAAAIeAQWAADQ9OZhaU7KKx0y/4N9UulwyG/HXSnhthCrdwkAgGaJCsslOMUpSz/PkFfSj0hphcPq3QEAoNkisFxCaI0ZeyurCCwAAFiFwHIJwcFBEhxUfbvS0egnBAYAoNEisNTBFlJ9iCqosAAAYBkCSx3C3IGFCgsAAFYhsNTBFlLdJkQfFgAArENgqYPtXMdbKiwAAFiHwFKHMFeFxUGFBQAAqxBY6kCnWwAArEdg8bAPC01CAABYh8Di4eRxlQQWAAAsQ2CpQ6jNVWGhSQgAAKsQWDweJURgAQDAKgSWOoS6RwnRJAQAgFUILHWgwgIAgPUILHUItTFxHAAAViOw1CH03OWamZofAADrEFg8nYeFPiwAAFiGwFKH0HMz3VJhAQDAOgQWDwMLnW4BALAOgaUOtnN9WOh0CwCAdQgsHl78kKn5AQCwDoGlDmHuix/SJAQAgFUILB5WWCocBBYAAKxCYPFwWDNNQgAAWIfAUofQc1PzM6wZAADrEFg8HNZcToUFAADLEFg8bhKiwgIAgFUILHUIdQUWpuYHAMAyBJY6MNMtAADWI7B4OqyZwAIAgGUILHUIPTc1P8OaAQCwDoHF44njCCwAAFiFwOJhp9uKSpqEAACwCoHFw063lUzNDwCAZQgsdbCd68NSQR8WAAAsQ2CpAxUWAACsR2DxdB6WSiosAABYhcDi4dT8FVRYAACwDIHF06n56cMCAIBlCCye9mFhplsAACxDYKmDLbj6EJVTYQEAwDIEFo+v1kyFBQAAqxBYPJyanz4sAABYh8DiYYWlnD4sAAA0rsCycOFCSUlJkYiICElNTZWNGzdedN0lS5bIyJEjpU2bNmYZPXr0eevffvvtEhQUVGsZO3asBAI63QIA0AgDy4oVK2TmzJkyd+5c2bp1qwwYMEDGjBkjubm5F1x/3bp1MnnyZFm7dq2kp6dLUlKSXH/99ZKVlVVrPQ0oJ06ccC9vvPGGBNLU/HqxZgdXbAYAoHEElueff16mT58u06ZNk969e8vixYslMjJSli5desH1X3vtNbn77rtl4MCB0qtXL/nTn/4kDodD1qxZU2u98PBwiY+Pdy9ajQmkPiyKyeMAAGgEgaW8vFy2bNlimnXcGwgONve1euKJkpISqaiokLZt255XienQoYP07NlT7rrrLikoKLjoNsrKysRut9daGkpYzcBCx1sAAAI/sOTn50tVVZXExcXVelzvZ2dne7SNhx56SBITE2uFHm0OeuWVV0zV5emnn5ZPP/1UbrjhBvOzLmTevHkSHR3tXrSZqaGn5lf0YwEAwBo2f/6w+fPny/Lly001RTvsukyaNMl9u1+/ftK/f3/p1q2bWe+66647bzuzZs0y/WhctMLSUKHF1YdFUWEBAKARVFhiY2MlJCREcnJyaj2u97XfyaU899xzJrB8+OGHJpBcSteuXc3POnjw4AWf1/4uUVFRtZaGoiOWmDwOAIBGFFjCwsJk8ODBtTrMujrQpqWlXfT7nnnmGXniiSdk9erVMmTIkDp/zrFjx0wfloSEBAmk6fkrKqmwAADQKEYJaVOMzq2ybNky2bt3r+kgW1xcbEYNqSlTppgmGxftkzJ79mwzikjnbtG+LrqcOXPGPK9fH3jgAfnyyy/l8OHDJvzcdNNN0r17dzNcOhC4+rEwSggAgEbSh2XixImSl5cnc+bMMcFDhytr5cTVETczM9OMHHJZtGiRGV10yy231NqOzuPy2GOPmSamHTt2mABUWFhoOuTqPC1akdGmn8CaPI4KCwAAVghyOp2N/iysnW51tFBRUVGD9GdJ/d3HkmMvk1X3jZC+HaPrffsAADRHdi/O31xLyJs+LAxrBgDAEgQWD/x7lFCjL0YBANAoEVi8mJ6fCgsAANYgsHjR6ZaJ4wAAsAaBxZsmISosAABYgsDixfT8VFgAALAGgcWbeViYOA4AAEsQWLzqw0JgAQDACgQWb6bmp0kIAABLEFi8mDiOqfkBALAGgcUDYTZXhYUmIQAArEBg8QBT8wMAYC0Cixd9WJiaHwAAaxBYPBDmGtZMhQUAAEsQWLyosJTT6RYAAEsQWLwaJUSFBQAAKxBYvLmWEH1YAACwBIHFA8x0CwCAtQgsHrARWAAAsBSBxQOh567WzEy3AABYg8DiVYWFwAIAgBUILF51uqVJCAAAKxBYPECnWwAArEVg8WLiOJqEAACwBoHFiwoLE8cBAGANAosXfViosAAAYA0CixdT89OHBQAAaxBYPMDU/AAAWIvA4gH6sAAAYC0CixcTx5XThwUAAEsQWLyamp8KCwAAViCweFFhoQ8LAADWILB4NayZCgsAAFYgsHiAqfkBALAWgcWLqfkr6XQLAIAlCCweoMICAIC1CCweCHXPdEuFBQAAKxBYvGkSclBhAQDACgQWLwKLVlicTqosAAD4G4HFA2Hn+rCoKuZiAQDA7wgsXkwcp+jHAgCA/xFYPGA7NzW/qqAfCwAAfkdg8WJYs2IuFgAA/I/A4oGQ4CBxFVm4ACIAAP5HYPGyH0s5gQUAAL8jsHgo9FyJhSYhAAD8j8DioVBb9aFi8jgAAPyPwOIh27np+csrqbAAAOBvBBYPhTI9PwAAliGw+DA9PwAA8C8Ci5dzsTCsGQAA/yOweCj0XB8WKiwAAPgfgcXbJiH6sAAA0DgCy8KFCyUlJUUiIiIkNTVVNm7ceNF1lyxZIiNHjpQ2bdqYZfTo0eet73Q6Zc6cOZKQkCAtWrQw6xw4cEACceI45mEBAKARBJYVK1bIzJkzZe7cubJ161YZMGCAjBkzRnJzcy+4/rp162Ty5Mmydu1aSU9Pl6SkJLn++uslKyvLvc4zzzwjL7zwgixevFg2bNggLVu2NNssLS2VQBHmGiVEHxYAAPwuyKnlDS9oRWXo0KHy4osvmvsOh8OEkPvuu08efvjhOr+/qqrKVFr0+6dMmWKqK4mJifLrX/9afvOb35h1ioqKJC4uTl5++WWZNGnSedsoKyszi4vdbjf7oN8XFRUlDWHy/34p6d8UyB8mDZSbBnZskJ8BAEBzYrfbJTo62qPzt1cVlvLyctmyZYtpsnFvIDjY3NfqiSdKSkqkoqJC2rZta+5nZGRIdnZ2rW3qzmswutg2582bZ9ZxLRpW/NWHhSYhAAD8z6vAkp+fbyokWv2oSe9r6PDEQw89ZCoqroDi+j5vtjlr1iyTxlzL0aNHpaGFufqw0OkWAAC/s/nzh82fP1+WL19u+rVoh11fhYeHm8WfXBWWciosAAAEdoUlNjZWQkJCJCcnp9bjej8+Pv6S3/vcc8+ZwPLhhx9K//793Y+7vs+XbVozSogKCwAAAR1YwsLCZPDgwbJmzRr3Y9rpVu+npaVd9Pt0FNATTzwhq1evliFDhtR6rkuXLiaY1NymdsLR0UKX2qa/hQbThwUAgEbTJKRDmqdOnWqCx7Bhw2TBggVSXFws06ZNM8/ryJ+OHTuajrHq6aefNnOsvP7662buFle/lFatWpklKChIZsyYIU8++aT06NHDBJjZs2ebfi7jx4+XQJuan4njAABoBIFl4sSJkpeXZ0KIho+BAweayomr02xmZqYZOeSyaNEiM7rolltuqbUdncflscceM7cffPBBE3ruvPNOKSwslBEjRphtXk4/l4ZqEqqopMICAEDAz8PS2Mdx+2rOu7vklfQjct+13eXX1/dskJ8BAEBzYm+oeViaMxsXPwQAwDIEFg+F2piaHwAAqxBYPBTqrrAQWAAA8DcCi5cTx1U4aBICAMDfCCxeDmumSQgAAP8jsHgo1FVhodMtAAB+R2DxepQQFRYAAPyNwOJlhYWp+QEA8D8Ci7d9WJiaHwAAvyOweDk1fzkVFgAA/I7A4nWTEBUWAAD8jcDiZadb+rAAAOB/BBZvhzXThwUAAL8jsHjZ6ZZhzQAA+B+Bxcup+WkSAgDA/wgsHqLCAgCAdQgsHmJqfgAArENg8XqUEBUWAAD8jcDiZR+WCgcVFgAA/I3A4qEw19T8VFgAAPA7AouXU/PThwUAAP8jsHjIFuzqdEuFBQAAfyOweH21ZiosAAD4G4HFy2HNVQ6nOAgtAAD4FYHFyz4siusJAQDgXwQWLyssiun5AQDwLwKLl31YFIEFAAD/IrB4OUpIlTNSCAAAvyKweCgoKMgdWirpwwIAgF8RWHyYnp8mIQAA/IvA4kM/FiaPAwDAvwgsPgUWKiwAAPgTgcULTM8PAIA1CCxeYHp+AACsQWDxYfK4SiosAAD4FYHFh+n5mYcFAAD/IrB4wT0PC51uAQDwKwKLF8Jsrj4sVFgAAPAnAotPo4SosAAA4E8EFh/6sDCsGQAA/yKw+DRKiAoLAAD+RGDxAlPzAwBgDQKLF2zBTM0PAIAVCCy+NAkxSggAAL8isPjU6ZYKCwAA/kRg8QJT8wMAYA0CixdC3X1YCCwAAPgTgcULtnMVFpqEAADwLwKLD8Oa6XQLAIB/EVi8wMRxAABYg8DiwyihcvqwAADgVwQWL4Seu/ghFRYAABpBYFm4cKGkpKRIRESEpKamysaNGy+67u7du2XChAlm/aCgIFmwYMF56zz22GPmuZpLr169JNDQhwUAgEYSWFasWCEzZ86UuXPnytatW2XAgAEyZswYyc3NveD6JSUl0rVrV5k/f77Ex8dfdLt9+vSREydOuJf169dLwDYJVVJhAQAgoAPL888/L9OnT5dp06ZJ7969ZfHixRIZGSlLly694PpDhw6VZ599ViZNmiTh4eEX3a7NZjOBxrXExsZedN2ysjKx2+21Fn9gan4AABpBYCkvL5ctW7bI6NGj/72B4GBzPz09/bJ25MCBA5KYmGiqMbfddptkZmZedN158+ZJdHS0e0lKShJ/sNGHBQCAwA8s+fn5UlVVJXFxcbUe1/vZ2dk+74T2g3n55Zdl9erVsmjRIsnIyJCRI0fK6dOnL7j+rFmzpKioyL0cPXpU/CHUxky3AABYwSYB4IYbbnDf7t+/vwkwycnJsnLlSrnjjjvOW1+bli7VvNRQmJofAIBGUGHRfiUhISGSk5NT63G9f6kOtd6KiYmRK664Qg4ePCiBODV/pYMmIQAAAjawhIWFyeDBg2XNmjXuxxwOh7mflpZWbzt15swZOXTokCQkJEggDmumwgIAQIA3CemQ5qlTp8qQIUNk2LBhZl6V4uJiM2pITZkyRTp27Gg6xro66u7Zs8d9OysrS7Zv3y6tWrWS7t27m8d/85vfyI9+9CPTDHT8+HEzZForOZMnT5ZAwtT8AAA0ksAyceJEycvLkzlz5piOtgMHDjSdZV0dcXV0j44cctEAMmjQIPf95557ziyjRo2SdevWmceOHTtmwklBQYG0b99eRowYIV9++aW5HUhs9GEBAMASQU6ns9GXC3QeFh3erCOGoqKiGuznrNufK7f/eZP0ToiS9+8f2WA/BwCA5sDuxfmbawl5IYyp+QEAsASBxYep+SvowwIAgF8RWHwY1kwfFgAA/IvA4sPEcYwSAgDAvwgsXgi1cfFDAACsQGDxYVhzeSWBBQAAfyKw+DJxHFPzAwDgVwQWH6bmpw8LAAD+RWDxZZSQwyFNYL49AAAaDQKLD6OENKtU0SwEAIDfEFh8qLAo+rEAAOA/BBYf+rAoJo8DAMB/CCw+BxYqLAAA+AuBxQshwUESdK5VqJIKCwAAfkNg8bHKUkEfFgAA/IbA4qXQ4HOTx1FhAQDAbwgsXrK5KiwEFgAA/IbA4uP0/HS6BQDAfwgsXmJ6fgAA/I/AchnT8wMAAP8gsPg4PX9FJYEFAAB/IbD4WGFhan4AAPyHwOLrPCyMEgIAwG8ILD4Pa6bCAgCAvxBYvMTEcQAA+B+BxUtMzQ8AgP8RWHztdEuFBQAAvyGweIlOtwAA+B+BxUu2c31Y6HQLAID/EFi8FGpzTc1PhQUAAH8hsPg6SohOtwAA+A2Bxcd5WMqpsAAA4DcEFi+FukcJUWEBAMBfCCw+jhKiDwsAAP5DYPGS7dzVmsupsAAA4DcEFp+bhKiwAADgLwQWX5uEGCUEAIDfEFh8nJqfmW4BAPAfAouXws5NHFdSXmX1rgAA0GwQWLzUvX0r83VXVpHVuwIAQLNBYPHS4OQ25uuB3DNyqrjc6t0BAKBZILB4qV2rcOnavqW5veXIKat3BwCAZoHA4oOhyW3N180EFgAA/ILA4oMhKdXNQpsPn7R6VwAAaBYILD4YklJdYdlxrEhKKxgtBABAQyOw+CClXaTEtgozV2xmtBAAAA2PwOKDoKAgGXKuH8umw/RjAQCgoRFYLrMfy5Yj9GMBAKChEVgusx+LjhRycF0hAAAaFIHFR30SoyQiNFgKSyrkUN4Zq3cHAIAmjcByGVdtHpgUY24zHwsAAA2LwHIZhp5rFtrEfCwAAAReYFm4cKGkpKRIRESEpKamysaNGy+67u7du2XChAlmfR1ds2DBgsveZqD1Y2GKfgAAGpbXgWXFihUyc+ZMmTt3rmzdulUGDBggY8aMkdzc3AuuX1JSIl27dpX58+dLfHx8vWwzUFzVOUaCg0SOFJRIrr3U6t0BAKDJ8jqwPP/88zJ9+nSZNm2a9O7dWxYvXiyRkZGydOnSC64/dOhQefbZZ2XSpEkSHh5eL9sMFK0jQqVnfJS5TT8WAAACJLCUl5fLli1bZPTo0f/eQHCwuZ+enu7TDviyzbKyMrHb7bUWqwx1X1eIwAIAQEAElvz8fKmqqpK4uLhaj+v97Oxsn3bAl23OmzdPoqOj3UtSUpJYPx8LHW8BAGgojXKU0KxZs6SoqMi9HD161LJ9GZJcXWHZfdwuZ8oqLdsPAACaMq8CS2xsrISEhEhOTk6tx/X+xTrUNsQ2tS9MVFRUrcUqiTEtpEtsS6lyOOXP6zMs2w8AAJoyrwJLWFiYDB48WNasWeN+zOFwmPtpaWk+7UBDbNPfZozuYb6+tO6QZBcxWggAAMubhHT48ZIlS2TZsmWyd+9eueuuu6S4uNiM8FFTpkwxTTY1O9Vu377dLHo7KyvL3D548KDH2wx0Nw5IlMHJbeRsRZU8s3qf1bsDAECTY/P2GyZOnCh5eXkyZ84c0yl24MCBsnr1anen2czMTDPKx+X48eMyaNAg9/3nnnvOLKNGjZJ169Z5tM1ApxPizflhb7lp4efy1rYs+XlasgzqXN23BQAAXL4gp9PZ6C81rMOadbSQdsC1sj/Lr1d+JX/bekwGdY6Rt+4aboIMAAC4/PN3oxwlFKgeHNtTIsNCZFtmoby7/bjVuwMAQJNBYKlHcVERcs/3upvb8z/YJyXlDHMGAKA+EFjq2R0jukinNi0k214qz3/4tdW7AwBAk0BgqWcRoSHy6Lje5vaf1mfIC2sOWL1LAAA0egSWBjC2b7w8fEMvc/v5j74mtAAAcJkILA3kl6O61QotfyS0AADgv3lY4F1o0UHjT6/eJ7//qLo/y73Xdme4MwAAXqLC0sDu+m43M9xZaWj5+f9tlIO5p63eLQAAGhUCix/c/d3uZibcMFuwrD+YL2MXfCbz3t/L1Z0BAPAQM9360ZGCYnli1R75eG+uuR8XFS73fq+73Digo0RHhlq9ewAABOz5m8BigU/25cjjf98jRwpKzP2wkGAZ3buD3Dyok4zq2V5CQyh8AQCaPjuBJfCVVlTJ6xsyZeXmo7Iv+999WmIiQ6V/pxjpnRAlfRKrl+R2LSUkmI66AICmhcDSyOw5bjcXTXx3e5bknyk/73lbcJAkxrQwM+jq0jEmUhJiIiQxuoXER0dIYkyERIYx4AsA0LgQWBqpiiqH7Moqkj0n7LL7ePWy74RdyioddX5vVITNhBoNMAnRLSQxOkKSY1tK19iWkhLbUlqFE2gAAIGFwNKEVDmckmMvlWOnzsqxUyXuryeKSiX73HLag9FG7VuHyxVxrWRYSjtJ7dpWBibFmMsIAABgFQJLM3O6tMIEl+NFpXKi8KwJM1mFZ82opIz84gs2M+kQ60FJMfLD/gkyYXAnmpQAAH5HYEEt9tIKycgrlh1ZRbLhmwLZkHFS8k6X1WpOmpzaWaakpUjHmBaW7isAoPmwE1hwKfon18rL2v158kr6Yffwah2J9IN+CTJ73JXSISrC6t0EADRxdgILvOkjs3Zfriz9PEO+OFRgHmvbMkyentBfvt87zurdAwA0YXYCC3yhI5Qe/OsOM0pJ3ZbaWR4d11tahNE5FwBg7fmbKVXh1rdjtLx9z3CZPrKLuf/ahkz54R8/M/PEAABgJQILagm3hchvx/WWV+9IlQ6tw+VQXrHcuvgLWX8g3+pdAwA0YwQWXNCIHrGyesZ35Jru7aS4vEqmvbxR/v7Vcat3CwDQTBFYcFHa+Xbp7UNlXP8Eqahyyq+Wb5NlXxy2ercAAM0QgQV1NhG9MGmQTElLFu2ePfe93fL7D/ebodEAAPgLgQV10vlZHr+xj8z8/hXm/h8/OSj/vWoPoQUA4DcEFngkKChIfnVdD3lyfF9z/8+fH5bH/05oAQD4B4EFXvnZ1cky/+Z+5vbLXxyWx97bTWgBADQ4Agu8NmlYZ3lmQn8JChJZln5E5rxLaAEANCwCC3zyk6FJZvp+DS1/+fKIzH53F6EFANBgCCzw2U+GJMmztwwwoeXVLzPp0wIAaDAEFlyWWwZ3Ms1Drj4tT/1jL6EFAFDvCCy4bLcOSZLf/bi6I+6f1mfIM/9knhYAQP0isKBe/DS1s/z3TX3M7UXrDsn/+/iA1bsEAGhCCCyoN1PSUuTRcVea2y+sOSDzPtgrDgeVFgDA5SOwoF79x8iu8sgPepnb//PpN+b6Q6UVVVbvFgCgkSOwoN7d+Z1u8vtbB4gtOEhW7TghP/+/DXKquNzq3QIANGIEFjSICYM7ySu/GCatI2yy6fApmbDoC8ksKLF6twAAjRSBBQ1mePdY+dtdw6VjTAv5Jr9Yxr/0uWw6fNLq3QIANEIEFjSoK+Jay9t3D5e+HaPkZHG53LZkg7y19ZjVuwUAaGQILGhwHaIiZOV/psnYPvFSXuWQmSu/kmf/uY8RRAAAjxFY4BeRYTZ56bar5J7vdTP3F649JPe8vlXOljOCCABQNwIL/CY4OEgeGNNLnv/JAAkLCZYPdmXLva9vpdICAKgTgQV+d/NVneTV/0iVMFuwrNmXKy98wqy4AIBLI7DAEsO6tHVff2jBxwdkzd4cq3cJABDACCyw9ErPU9KSze0ZK7ZLRn6x1bsEAAhQBBZY6tFxvWVIchs5XVopd76yWYrLKq3eJQBAACKwwFLaj0VHD3VoHS4Hcs/IA3/9ik64AIDzEFgQEPO0LPrZVRIaEiTv78yW37z5lVRWOazeLQBAACGwICAMTm4rz/9koIQEB8lb27Lkvje2SXkloQUAUI3AgoDxowGJsui2q9xztPznXzZLaQUTywEACCwIMNf3iZclU4dIRGiwrN2fJ794eRMdcQEAvgWWhQsXSkpKikREREhqaqps3Ljxkuu/+eab0qtXL7N+v3795P3336/1/O233y5BQUG1lrFjx/qya2gCRl3RXpZNGyYtw0Lki0MFcu3v18n/rc9gGn8AaMa8DiwrVqyQmTNnyty5c2Xr1q0yYMAAGTNmjOTm5l5w/S+++EImT54sd9xxh2zbtk3Gjx9vll27dtVaTwPKiRMn3Msbb7zh+2+FRi+1azt5bfrVkhgdITn2Mnli1R4Z+cwnsvjTQ3KGigsANDtBTqfTqzGkWlEZOnSovPjii+a+w+GQpKQkue++++Thhx8+b/2JEydKcXGxrFq1yv3Y1VdfLQMHDpTFixe7KyyFhYXyzjvv+PRL2O12iY6OlqKiIomKivJpGwhMZZVV8rctWfLSuoNy7NRZ81ircJtc3bWdXNO9nYzoHivdO7QyVTkAQOPizfnb5s2Gy8vLZcuWLTJr1iz3Y8HBwTJ69GhJT0+/4Pfo41qRqUkrMt8OJ+vWrZMOHTpImzZt5Nprr5Unn3xS2rVrd8FtlpWVmaXmL4ymKdwWIj9N7Sy3Dukk724/LgvXHjQz4n68N8csSudw0an+r+rcRq5KbiO9E6LM/C4AgKbDq8CSn58vVVVVEhcXV+txvb9v374Lfk92dvYF19fHazYH3XzzzdKlSxc5dOiQPPLII3LDDTeYsBMSEnLeNufNmyePP/64N7uORi40JNhM5X/zoI6y63iRfH6wQD4/mC+bDp+U3NNlsmrHCbOocFuw9O0YLX0So+TKhOqlZ1xraRF2/msJANAEA0tDmTRpkvu2dsrt37+/dOvWzVRdrrvuuvPW1wpPzaqNVli0WQpNX3BwkPTvFGOWu77bzQx73pp5SrYeOSVbjpySbUcLpbCkwtzWxf19QSI946Pkmm7tZHj3djKsSzvTtAQAaBy8eseOjY01FY+cnNpX1tX78fHxF/wefdyb9VXXrl3Nzzp48OAFA0t4eLhZgIjQEBneLdYsSrtkfZNfLDuOFcreE6dl7wm77Dlul4LicnNblz+tzzAT1A1MipGJQ5PkpoGJpukJANBEAktYWJgMHjxY1qxZY0b6uDrd6v177733gt+TlpZmnp8xY4b7sY8++sg8fjHHjh2TgoICSUhI8Gb3ANP5tlv7Vmb58SBxhxhtNtqQcVLSD+WbodJHCkrcVZhn/7lfpqYly22pydKmZZjVvwIAoD5GCemw5qlTp8r//M//yLBhw2TBggWycuVK04dF+6ZMmTJFOnbsaPqZuIY1jxo1SubPny/jxo2T5cuXy+9+9zszJLpv375y5swZ0x9lwoQJpuqifVgefPBBOX36tOzcudOjSgqjhOCtY6dK5B87TsjLXxyWE0Wl5jGdrE5DywNjeprKDQCgkY4Scg1TzsvLkzlz5piOszo8efXq1e6OtZmZmWbkkMvw4cPl9ddfl0cffdR0pu3Ro4cZIaRhRWkT044dO2TZsmVmaHNiYqJcf/318sQTT9DsgwbTqU2k/OeobvKLEV3k/Z0nZMln38iuLLuZoG79gXx58aeDpEdca6t3EwDga4UlEFFhweXS/wZr9+fKg3/dKflnyky15fEb+8hPhiQxxwsABMD5m8kqgHN9X67tFSfv3z9CRvaIldIKhzz0t53yq+XbxV5aYfXuAUCzR2ABaujQOsJcx+jhG3qJLThI/v7VcRn7//4lnx3Is3rXAKBZI7AAF5jr5ZejusnKX6ZJcrtIOV5UKj//v43yyNs7uY4RAFiEwAJchE71/8H9I82QZ/X6hkwZu+Bfkn6owOpdA4Bmh8ACXEJkmE0ev6mvvD49VTq1aWEuwHjbn76UNzcftXrXAKBZIbAAHtCZdFfP+I65lpHDKfLAX3fIK+mHrd4tAGg2CCyAh/TaQ7//yQD5xTVdzP057+6Wl9YdtHq3AKBZILAAXg5/nv3DK+VX13Y3959ZvV+e++d+M48LAKDhEFgAH0LLzOt7yqwbepn7L649KI+9t1sc2lYEAGgQBBbARzq1/xPj+4pOhLss/Yjcv2K7lFc6rN4tAGiSCCzAZfj51cnyh0mDJDSkepK5O5ZtYq4WAGgABBbgMt04IFGW3j5UIsNC5LMD+fLTJV9KwZkyq3cLAJoUAgtQD0b2aC9vTL9a2rYMkx3HiuSWxemyK6vI6t0CgCaDwALUkwFJMfLXX6ZJx5gWkpFfLOMXfi4LPv5aKqro1wIAl4vAAtSjru1byXv3XiM/6BcvlQ6nLPj4gPz4pc9lf/Zpq3cNABq1IGcTmEDCbrdLdHS0FBUVSVRUlNW7A5h5Wf6+44TMeXeXFJZUSFhIsPw0tbPcNDBRBibFmKHRANDc2b04fxNYgAaUe7pUHnlrp3y8N9f9WOe2kfKjAQly08COckVca0v3DwCsRGABAoj+F1v3dZ68vTVLPtqTI2crqtzPXdU5Rn52dbL8oF+CRISGWLqfAOBvBBYgQJWUV8qavbny3lfHZe2+XNPPRbWJDJVbhySZeV2S2kZavZsA4BcEFqCRNBet3HRU3th4VLIKz5rHtK/LL0Z0kXu+101aR4RavYsA0KAILEAjUuVwmmrL0s8z5ItDBeax2FZh8pvre5qqS0gwHXQBNE0EFqAR0v+Ka/fnypOr9so3+cXmsSsTomRqWrLc0DdBoiOpuACNnV7CY+Xmo3LXd7vJ8G6x0tzZCSxA46UXUHz1yyNm0jl7afV1ifRaRaOu6GCGRX+vVwdpFW6zejcBeOnd7VkyY8V20bOuFk5/dV0Pue/aHs26imonsACN36nicnljU6a8t/247PvWxHM6m273Dq2kR4dWkhLbUiqrHHK6tNJceFFDTpXDIeG2EAm3BUt4aLBE2EKkd2KUDOvStsH7xuh1lHR/DxcUy5GCEjlSUCynSirklqs6ya1DOjEHTQC+zma/u0vSDxWYEWv/MbJLvb1GHA6n7M22mxCu1cLmPBJu9a5suef1raYJuGdca9mfU/1/Oq1rO1kwaaDERUU0+D7YSyvk6Q/2yZYjp+Q/RnaVHw/qaHlYIrAATczXOadNcNHRRZknS3zejr45DegULdd0j5X+nWJM5SY4yLWItGsVLp3atJCWXlZwThSdNW/IH+zKlk2HT5pPkBcyvFs7mXdzP0lu17LW4xq49p44LUVnK8ywb11KK6rMCW5IchtJjGnh8++sb3HZ9lKxBQebC1S2CA2RYC/fpPXyCpsyTsqGjJPSvnW4CX9XxkdJi7AQdwfqzw/mm4tfbsw4afY7uW2k+T2T20VK1/YtzYSBlxMECkvK5XBBiRSXVcrZ8upjpIv+PjqfT5fYlhJm827yct3nmSu3S4793xfrjIkMlV+O6iZT01LM73f0ZImsN79bnuw+bpfQkGDzMyM0CIeGmOtn6WumU5tI8zW6RahsyyyULw7lm+OlEye6OpTrcbuqcxsZkBRt7peUV0lJRZWUlFWanzU4uY30io+q8ySq/x/+tuWYrN6dLR1ah8vtw7vImD5xYgup/fvra0hfj/p6HlTPEzbq60qbbvVn6P7agoMkJDhYWkfYJLZVeK111+3PlemvbJaKKqfcPKijPHfrAHn3qyz57du7zDFo1zJMZv+wt3yvZ4eLNv06z/2n8vV30H2Y9dZOOVFU6n5MQ+QjP+hlroXm6e9c3x84CCxAE/9EfDDvjBzIOSMHc89I5sliU03RN0pdWoWHii0kyHyqLTNLldjPVsrmIydNxcMTehJKatPCnJx1G/qmbE6Q5VUm3LiqNnrC0k9tesHHmrrGtjSVHz1Z64lbqz8L1x2U0gqHOdH91+gr5JbBncyJ8JN9ubJuf54JKxejJ8LULu0ktUtbiYuOkNDgIAm1BZuTRGSYTRJjImqFAf1kv+3oKfnHjmxZveuEHK/xJq10H6pPutWLVqI0zCTEtDAT++mi+513psxM+qdv9vo71KTnVA0JegL/dgXsQnR9PWEPTWkrw1LammOsJ6vi8kp3CKlyVp8U9FO4jnjPsZeak/PXOWckv44rgOux0GDUo0Nr8zqoeRJtFWGTK+JauYONw+mU5/65X5Z8llH992rfUm4fniLLvjgsh/Kq+0/p3751uM3dn8pXLcOqj3FBcblH6+vPHJLSRoZ2aSvxUREmhGm40b+3hicNKl996/XmqjpOuybFzGmkIeXD3Tnm71ZcXj3vUbf2LWXysM4y4apO0qZlmDnOGsC0w7vOk6SBUENXUtvq10BSm0hzDPTvpEE+KsJmXqP6mv10f558+nWe5J6+8N9E90XDl/4eURGh8tDfdpj/R+P6JcgfJg10B6tDeWfknte2ul8/+hrp1zFahnePNQFLw8W+bLt5/uvs0+YYXNuzg3y/d5x854r2Jojpa12f10CpgbnwbLnZxqCkNjKoc4x0aB0hT72/R1ZuPmZ+hv6f/GH/BHkl/Yj7Na3b+smQTuaDQWJ09f973RcNyDuOFcrOY0Xm/3hpZZW8d+8IqU8EFgAXdOxUiXxxsEA+P5RvLtCoJy6HQ8xXPUnqG/ClgsPF6IcurYSM7ZsgY/vGmzfsb9OmoUfe3imfH6weCfVtekLQN8zwUK2CVAeKk8Xlsuu43exbXfSTvQabhOgI2ZVlN1UVFz15e7KNS9FPwSN6xJqKwZ4Tdsn71smqb8coGdG9vVzTvd2537e6OUy/6gnlcipjLnoC198zwlSKqisc+vfS8KrNgZ7QqpqeRF0B4rbUzvLouN6mwqGVrre3Zckf1hyQY6fOuo+dnjz1U/jQlDbmE7YrwGrg0iClrytdP+vUWbPd3glRktatnVn05KnB6ejJs7I185RZNCjo53T9mS3DbCYs6vdpU4Unv4du77orO8j4gR1lb/Zp0+dLXysXEhcVbk7Muq9KA5A2w+w9Yb9o4LjYcXMFyZrBV/8e+rjOqVRV5TQB9EIvtdFXxsmin11lAm5Neixf/OSgfLDrhDsseiLMFmz+Lvo9lwqz+n9Tz/L6ddrwLvLAmJ7muOsHnz9+clD+8uVhU/mpSf/mEbZgd9irua0dc6+v12ZlAgsAn+kJUE9AeoLRk4C7GqGflG0h4hSnlFVUV130U6O+iekJoIMHbfD6dvPmlmPy5Ko9pq+Nfuq/tlecOfnom++3S/pKT2B6ItuYUSCbD58y36cnVj1BaFONPu9qdqhJOyaPvrKD+cStnyD1U7p+QtQTl6tJxfweldXNT1rl0JOuforXcHHkZIn5Hu3krCcbbdKp2VShzUB64i0trzJ9g/RT+KVkF5XKxsMnTdOSVgC0AhYZHmIqRLqveox1+/ojtMlKK1n66V77KWllpFuHVhftbK3HVatIWo05lHvG/F0qqzSEVh+ngjPl8nVu9ad010lIt/3MhP4yunfcedvTfft4b47ZHw0dGnD8Qf+uGu60KUmDjf1shdkX/TuXVznMMdK/540DEmsdb/37vbMtS/60PsNUHfWYXd8nTq7vHW8Ck4YIbU59fUOm+Zu5aFAa0T3W/I21qqKve/3b62tfb2uI0mNXM0Rp/5NRPdvLd3q0NxWUb/fL0XW/OlpoXqta1dTKhFYGX5g8qM4+PPoa0WY6/UCx57jdBPCe8a2lZ3yU9IpvbUKGzpb90d6cWtVSPS76dxrZI9aEWq1Abcs8ZX62vs5T2kXKs7cOMNW9b9NQvfjTb8xrR3++Bn1XuNdQpOFTm5H7dYoxX7u1b+V1k+qlEFgABDQ9wWhTkpar64OeJPTTvZ5kdBI+LWtrNaQ5d/K8VLDRk1SfhOgmN1Ref7/TZZWXDFjavKH9a1yd0LU51ZPXq4Z3bWqtr9fs5f6eB3PPmADcNbaVXJUcc8HfQwOg+f8Q0+K8ys7FaFjRis3p0grp3Nb7flHeIrAAAIAmdf5u2OgEAABQDwgsAAAg4BFYAABAwCOwAACAgEdgAQAAAY/AAgAAAh6BBQAABDwCCwAACHgEFgAAEPAILAAAIOARWAAAQMAjsAAAgIBHYAEAAAHPJk2A64LTetVHAADQOLjO267zeJMPLKdPnzZfk5KSrN4VAADgw3k8Ojr6kusEOT2JNQHO4XDI8ePHpXXr1hIUFFTv6U+D0NGjRyUqKqpet43aONb+w7H2H461/3CsG9+x1giiYSUxMVGCg4ObfoVFf8lOnTo16M/QPwj/AfyDY+0/HGv/4Vj7D8e6cR3ruiorLnS6BQAAAY/AAgAAAh6BpQ7h4eEyd+5c8xUNi2PtPxxr/+FY+w/Humkf6ybR6RYAADRtVFgAAEDAI7AAAICAR2ABAAABj8ACAAACHoEFAAAEPAJLHRYuXCgpKSkSEREhqampsnHjRqt3qVGbN2+eDB061FxGoUOHDjJ+/HjZv39/rXVKS0vlnnvukXbt2kmrVq1kwoQJkpOTY9k+NxXz5883l66YMWOG+zGOdf3JysqSn/3sZ+ZYtmjRQvr16yebN292P68DMufMmSMJCQnm+dGjR8uBAwcs3efGqqqqSmbPni1dunQxx7Jbt27yxBNP1LqAHsfbN//617/kRz/6kZkqX98v3nnnnVrPe3JcT548KbfddpuZATcmJkbuuOMOOXPmjI97VPuH4yKWL1/uDAsLcy5dutS5e/du5/Tp050xMTHOnJwcq3et0RozZozzz3/+s3PXrl3O7du3O3/wgx84O3fu7Dxz5ox7nV/+8pfOpKQk55o1a5ybN292Xn311c7hw4dbut+N3caNG50pKSnO/v37O++//3734xzr+nHy5ElncnKy8/bbb3du2LDB+c033zj/+c9/Og8ePOheZ/78+c7o6GjnO++84/zqq6+cN954o7NLly7Os2fPWrrvjdFTTz3lbNeunXPVqlXOjIwM55tvvuls1aqV8w9/+IN7HY63b95//33nb3/7W+dbb72l6c/59ttv13rek+M6duxY54ABA5xffvml87PPPnN2797dOXnyZOflIrBcwrBhw5z33HOP+35VVZUzMTHROW/ePEv3qynJzc01/yk+/fRTc7+wsNAZGhpq3oBc9u7da9ZJT0+3cE8br9OnTzt79Ojh/Oijj5yjRo1yBxaOdf156KGHnCNGjLjo8w6HwxkfH+989tln3Y/p8Q8PD3e+8cYbftrLpmPcuHHOX/ziF7Ueu/nmm5233Xabuc3xrh/fDiyeHNc9e/aY79u0aZN7nQ8++MAZFBTkzMrKuqz9oUnoIsrLy2XLli2m3FXzIot6Pz093dJ9a0qKiorM17Zt25qveswrKipqHfdevXpJ586dOe4+0iafcePG1TqmimNdf9577z0ZMmSI3Hrrraapc9CgQbJkyRL38xkZGZKdnV3rWOsF37SZmWPtveHDh8uaNWvk66+/Nve/+uorWb9+vdxwww3mPse7YXhyXPWrNgPp/wcXXV/Pnxs2bLisn98krtbcEPLz8007aVxcXK3H9f6+ffss26+mxOFwmP4U11xzjfTt29c8pv8ZwsLCzAv+28ddn4N3li9fLlu3bpVNmzad9xzHuv588803smjRIpk5c6Y88sgj5nj/6le/Msd36tSp7uN5ofcTjrX3Hn74YbHb7SZgh4SEmPfqp556yvSbUBzvhuHJcdWvGtprstls5kPp5R57Agss/eS/a9cu88kI9e/o0aNy//33y0cffWQ6jaNhw7d+ovzd735n7muFRV/bixcvNoEF9WvlypXy2muvyeuvvy59+vSR7du3mw8/2lGU49100SR0EbGxsSa5f3vEhN6Pj4+3bL+ainvvvVdWrVola9eulU6dOrkf12OrzXGFhYW11ue4e0+bfHJzc+Wqq64yn3B0+fTTT+WFF14wt/VTEce6fuiIid69e9d67Morr5TMzExz23U8eT+pHw888ICpskyaNMmMxvr5z38u//Vf/2VGISqOd8Pw5LjqV33fqamystKMHLrcY09guQgt5Q4ePNi0k9b8FKX309LSLN23xkz7cWlYefvtt+WTTz4xwxJr0mMeGhpa67jrsGd94+e4e+e6666TnTt3mk+frkWrAFo2d93mWNcPbdb89vB87V+RnJxsbuvrXN+sax5rbdLQNn2OtfdKSkpMn4ia9AOmvkcrjnfD8OS46lf9EKQfmFz0vV7/NtrX5bJcVpfdZjCsWXs/v/zyy6bn85133mmGNWdnZ1u9a43WXXfdZYbErVu3znnixAn3UlJSUmuorQ51/uSTT8xQ27S0NLPg8tUcJaQ41vU3bNxms5nhtgcOHHC+9tprzsjISOerr75aaziovn+8++67zh07djhvuukmhtn6aOrUqc6OHTu6hzXrENzY2Fjngw8+6F6H4+37qMJt27aZRSPC888/b24fOXLE4+Oqw5oHDRpkhvivX7/ejFJkWLMf/PGPfzRv6Dofiw5z1nHl8J3+B7jQonOzuOgL/+6773a2adPGvOn/+Mc/NqEG9R9YONb15+9//7uzb9++5kNOr169nP/7v/9b63kdEjp79mxnXFycWee6665z7t+/37L9bczsdrt5Het7c0REhLNr165m7pCysjL3Ohxv36xdu/aC79EaEj09rgUFBSag6Nw4UVFRzmnTppkgdLmC9J/Lq9EAAAA0LPqwAACAgEdgAQAAAY/AAgAAAh6BBQAABDwCCwAACHgEFgAAEPAILAAAIOARWAAAQMAjsAAAgIBHYAEAAAGPwAIAACTQ/X9BFFQQKEBrdwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ae,_=Train_ResNetAE(norm_f,norm_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada5ec7-1095-4881-a98e-8abf869b7023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
